{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ISCC - Codec & Algorithms # iscc-core is a Python library that implements the core algorithms of the ISCC ( International Standard Content Code ) What is an ISCC # The ISCC is a similarity preserving identifier for digital media assets. ISCCs are generated algorithmically from digital content, just like cryptographic hashes. However, instead of using a single cryptographic hash function to identify data only, the ISCC uses various algorithms to create a composite identifier that exhibits similarity-preserving properties (soft hash). The component-based structure of the ISCC identifies content at multiple levels of abstraction. Each component is self-describing, modular, and can be used separately or with others to aid in various content identification tasks. The algorithmic design supports content deduplication, database synchronization, indexing, integrity verification, timestamping, versioning, data provenance, similarity clustering, anomaly detection, usage tracking, allocation of royalties, fact-checking and general digital asset management use-cases. What is iscc-core # iscc-core is the python based library of the core algorithms to create standard-compliant ISCC codes. It also serves as a reference for porting ISCC to other programming languages. Tip This is a low level reference implementation. iscc-core does not support mediatype detection, metadata extraction or file format specific content extraction. For easy generation of ISCC codes see: iscc-cli ISCC Architecture # ISCC MainTypes # Idx Slug Bits Purpose 0 META 0000 Match on metadata similarity 1 SEMANTIC 0001 Match on semantic content similarity 2 CONTENT 0010 Match on perceptual content similarity 3 DATA 0011 Match on data similarity 4 INSTANCE 0100 Match on data identity 5 ISCC 0101 Composite of two or more components with common header 6 ID 0110 Short unique identifier bound to ISCC, timestamp, pubkey 7 FLAKE 0111 Unique time, randomness and counter based distributed ID Installation # Use the package manager pip to install iscc-core . pip install iscc-core Quick Start # import iscc_core as ic meta_code = ic . gen_meta_code ( name = \"ISCC Test Document!\" ) print ( f \"Meta-Code: { meta_code [ 'iscc' ] } \" ) print ( f \"Structure: { ic . iscc_explain ( meta_code [ 'iscc' ]) } \\n \" ) # Extract text from file with open ( \"demo.txt\" , \"rt\" , encoding = \"utf-8\" ) as stream : text = stream . read () text_code = ic . gen_text_code_v0 ( text ) print ( f \"Text-Code: { text_code [ 'iscc' ] } \" ) print ( f \"Structure: { ic . iscc_explain ( text_code [ 'iscc' ]) } \\n \" ) # Process raw bytes of textfile with open ( \"demo.txt\" , \"rb\" ) as stream : data_code = ic . gen_data_code ( stream ) print ( f \"Data-Code: { data_code [ 'iscc' ] } \" ) print ( f \"Structure: { ic . iscc_explain ( data_code [ 'iscc' ]) } \\n \" ) stream . seek ( 0 ) instance_code = ic . gen_instance_code ( stream ) print ( f \"Instance-Code: { instance_code [ 'iscc' ] } \" ) print ( f \"Structure: { ic . iscc_explain ( instance_code [ 'iscc' ]) } \\n \" ) iscc_code = ic . gen_iscc_code ( ( meta_code [ \"iscc\" ], text_code [ \"iscc\" ], data_code [ \"iscc\" ], instance_code [ \"iscc\" ]) ) iscc_obj = ic . Code ( iscc_code [ \"iscc\" ]) print ( f \"ISCC-CODE: { ic . iscc_normalize ( iscc_obj . code ) } \" ) print ( f \"Structure: { iscc_obj . explain } \" ) print ( f \"Multiformat: { iscc_obj . mf_base32 } \\n \" ) iscc_id = ic . gen_iscc_id ( iscc_obj . code , chain_id = 1 , wallet = \"1Bq568oLhi5HvdgC6rcBSGmu4G3FeAntCz\" ) iscc_id_obj = ic . Code ( iscc_id [ \"iscc\" ]) print ( f \"ISCC-ID: { ic . iscc_normalize ( iscc_id_obj . code ) } \" ) print ( f \"Structure: { iscc_id_obj . explain } \" ) print ( f \"Multiformat: { iscc_id_obj . mf_base32 } \" ) The output of this example is as follows: Meta-Code: ISCC:AAAT4EBWK27737D2 Structure: META-NONE-V0-64-3e103656bffdfc7a Text-Code: ISCC:EAAQMBEYQF6457DP Structure: CONTENT-TEXT-V0-64-060498817dcefc6f Data-Code: ISCC:GAA7UJMLDXHPPENG Structure: DATA-NONE-V0-64-fa258b1dcef791a6 Instance-Code: ISCC:IAA3Y7HR2FEZCU4N Structure: INSTANCE-NONE-V0-64-bc7cf1d14991538d ISCC-CODE: ISCC:KACT4EBWK27737D2AYCJRAL5Z36G76RFRMO4554RU26HZ4ORJGIVHDI Structure: ISCC-TEXT-V0-MCDI-3e103656bffdfc7a060498817dcefc6ffa258b1dcef791a6bc7cf1d14991538d Multiformat: bzqavabj6ca3fnp757r5ambeyqf6457dp7isywhoo66i2npd46hiutektru ISCC-ID: ISCC:MEAJU5AXCPOIOYFL Structure: ID-BITCOIN-V0-64-9a741713dc8760ab Multiformat: bzqawcae2oqlrhxehmcvq Documentation # https://core.iscc.codes Project Status # The ISCC has been accepted by ISO as full work item ISO/AWI 24138 - International Standard Content Code and is currently being standardized at TC 46/SC 9/WG 18. https://www.iso.org/standard/77899.html Attention The iscc-core library and the accompanying documentation is under development. API changes and other backward incompatible changes are to be expected until the upcoming v1.5 stable release. Maintainers # @titusz Contributing # Pull requests are welcome. For significant changes, please open an issue first to discuss your plans. Please make sure to update tests as appropriate. You may also want join our developer chat on Telegram at https://t.me/iscc_dev .","title":"Overview"},{"location":"#iscc-codec-algorithms","text":"iscc-core is a Python library that implements the core algorithms of the ISCC ( International Standard Content Code )","title":"ISCC - Codec &amp; Algorithms"},{"location":"#what-is-an-iscc","text":"The ISCC is a similarity preserving identifier for digital media assets. ISCCs are generated algorithmically from digital content, just like cryptographic hashes. However, instead of using a single cryptographic hash function to identify data only, the ISCC uses various algorithms to create a composite identifier that exhibits similarity-preserving properties (soft hash). The component-based structure of the ISCC identifies content at multiple levels of abstraction. Each component is self-describing, modular, and can be used separately or with others to aid in various content identification tasks. The algorithmic design supports content deduplication, database synchronization, indexing, integrity verification, timestamping, versioning, data provenance, similarity clustering, anomaly detection, usage tracking, allocation of royalties, fact-checking and general digital asset management use-cases.","title":"What is an ISCC"},{"location":"#what-is-iscc-core","text":"iscc-core is the python based library of the core algorithms to create standard-compliant ISCC codes. It also serves as a reference for porting ISCC to other programming languages. Tip This is a low level reference implementation. iscc-core does not support mediatype detection, metadata extraction or file format specific content extraction. For easy generation of ISCC codes see: iscc-cli","title":"What is iscc-core"},{"location":"#iscc-architecture","text":"","title":"ISCC Architecture"},{"location":"#iscc-maintypes","text":"Idx Slug Bits Purpose 0 META 0000 Match on metadata similarity 1 SEMANTIC 0001 Match on semantic content similarity 2 CONTENT 0010 Match on perceptual content similarity 3 DATA 0011 Match on data similarity 4 INSTANCE 0100 Match on data identity 5 ISCC 0101 Composite of two or more components with common header 6 ID 0110 Short unique identifier bound to ISCC, timestamp, pubkey 7 FLAKE 0111 Unique time, randomness and counter based distributed ID","title":"ISCC MainTypes"},{"location":"#installation","text":"Use the package manager pip to install iscc-core . pip install iscc-core","title":"Installation"},{"location":"#quick-start","text":"import iscc_core as ic meta_code = ic . gen_meta_code ( name = \"ISCC Test Document!\" ) print ( f \"Meta-Code: { meta_code [ 'iscc' ] } \" ) print ( f \"Structure: { ic . iscc_explain ( meta_code [ 'iscc' ]) } \\n \" ) # Extract text from file with open ( \"demo.txt\" , \"rt\" , encoding = \"utf-8\" ) as stream : text = stream . read () text_code = ic . gen_text_code_v0 ( text ) print ( f \"Text-Code: { text_code [ 'iscc' ] } \" ) print ( f \"Structure: { ic . iscc_explain ( text_code [ 'iscc' ]) } \\n \" ) # Process raw bytes of textfile with open ( \"demo.txt\" , \"rb\" ) as stream : data_code = ic . gen_data_code ( stream ) print ( f \"Data-Code: { data_code [ 'iscc' ] } \" ) print ( f \"Structure: { ic . iscc_explain ( data_code [ 'iscc' ]) } \\n \" ) stream . seek ( 0 ) instance_code = ic . gen_instance_code ( stream ) print ( f \"Instance-Code: { instance_code [ 'iscc' ] } \" ) print ( f \"Structure: { ic . iscc_explain ( instance_code [ 'iscc' ]) } \\n \" ) iscc_code = ic . gen_iscc_code ( ( meta_code [ \"iscc\" ], text_code [ \"iscc\" ], data_code [ \"iscc\" ], instance_code [ \"iscc\" ]) ) iscc_obj = ic . Code ( iscc_code [ \"iscc\" ]) print ( f \"ISCC-CODE: { ic . iscc_normalize ( iscc_obj . code ) } \" ) print ( f \"Structure: { iscc_obj . explain } \" ) print ( f \"Multiformat: { iscc_obj . mf_base32 } \\n \" ) iscc_id = ic . gen_iscc_id ( iscc_obj . code , chain_id = 1 , wallet = \"1Bq568oLhi5HvdgC6rcBSGmu4G3FeAntCz\" ) iscc_id_obj = ic . Code ( iscc_id [ \"iscc\" ]) print ( f \"ISCC-ID: { ic . iscc_normalize ( iscc_id_obj . code ) } \" ) print ( f \"Structure: { iscc_id_obj . explain } \" ) print ( f \"Multiformat: { iscc_id_obj . mf_base32 } \" ) The output of this example is as follows: Meta-Code: ISCC:AAAT4EBWK27737D2 Structure: META-NONE-V0-64-3e103656bffdfc7a Text-Code: ISCC:EAAQMBEYQF6457DP Structure: CONTENT-TEXT-V0-64-060498817dcefc6f Data-Code: ISCC:GAA7UJMLDXHPPENG Structure: DATA-NONE-V0-64-fa258b1dcef791a6 Instance-Code: ISCC:IAA3Y7HR2FEZCU4N Structure: INSTANCE-NONE-V0-64-bc7cf1d14991538d ISCC-CODE: ISCC:KACT4EBWK27737D2AYCJRAL5Z36G76RFRMO4554RU26HZ4ORJGIVHDI Structure: ISCC-TEXT-V0-MCDI-3e103656bffdfc7a060498817dcefc6ffa258b1dcef791a6bc7cf1d14991538d Multiformat: bzqavabj6ca3fnp757r5ambeyqf6457dp7isywhoo66i2npd46hiutektru ISCC-ID: ISCC:MEAJU5AXCPOIOYFL Structure: ID-BITCOIN-V0-64-9a741713dc8760ab Multiformat: bzqawcae2oqlrhxehmcvq","title":"Quick Start"},{"location":"#documentation","text":"https://core.iscc.codes","title":"Documentation"},{"location":"#project-status","text":"The ISCC has been accepted by ISO as full work item ISO/AWI 24138 - International Standard Content Code and is currently being standardized at TC 46/SC 9/WG 18. https://www.iso.org/standard/77899.html Attention The iscc-core library and the accompanying documentation is under development. API changes and other backward incompatible changes are to be expected until the upcoming v1.5 stable release.","title":"Project Status"},{"location":"#maintainers","text":"@titusz","title":"Maintainers"},{"location":"#contributing","text":"Pull requests are welcome. For significant changes, please open an issue first to discuss your plans. Please make sure to update tests as appropriate. You may also want join our developer chat on Telegram at https://t.me/iscc_dev .","title":"Contributing"},{"location":"changelog/","text":"Changelog # [0.2.5] - Unreleased # Fixed missing jcs dependency Added SubType NONE to MT.ISCC to distinquish from SUM Added support for deterministic generation of random ISCC-CODEs Added support for custom bit-sizes for random ISCC-CODEs Moved changelog into separate file Updated dependencies [0.2.4] - 2022-03-19 # Updated dependencies Added Flake.from_int and Flake.from_string Made Flake comparable and hashable Use standard hex encoded multihash for datahash and metahash [0.2.3] - 2022-03-06 # Update to iscc-schema 0.3.3 Change image normalization instructions Fix issue with exporting cdc cython only functions [0.2.1] - 2022-03-03 # Cleanup and update dependencies Fix bitarray api change Fix developer commands [0.2.0] - 2022-02-24 # Complete API refactoring Use Data-URL as input for Meta-Code Use wallet address for ISCC-ID creation Added new Flake-Code (distributed time/random ID) Replaced assertions with exeptions Use secure random functions Retired Python 3.6 support (EOL) Return simple dict objects from generator functions Added ISCC string validation Added multiple helper functions [0.1.9] - 2021-12-17 # Added warning on non-standard options Added multiformats support Added uri representation Removed redundant cdc_avg_chunk_size option Updated codec format documentation [0.1.8] - 2021-12-12 # Added conformance tests for all top level functions Added conformance tests to source dir Added conformance module with selftest function Changed gen_image_code to accept normalized pixels instead of stream Changed opts to core_opts Removed image pre-processing and Pillow dependency Fixed readability of conformance tests Fixed soft_hash_video_v0 to accept non-tuple sequences Updated example code [0.1.7] - 2021-12-09 # Add dotenv for enviroment based configuration Cleanup package toplevel imports Return schema objects for iscc_code and iscc_id Exclude unset and none values from result dicts Add support for multiple code combinations for ISCC-CODE Add support for ISCC-ID based on singular Instance-Code Add initial conformance test system [0.1.6] - 2021-11-29 # Show counter for ISCC-ID in Code.explain [0.1.5] - 2021-11-28 # Fix documentation Change metahash creation logic Refactor models Add Content-Code-Mixed Add ISCC-ID Refactor compose to gen_iscc_code Refactor models to schema [0.1.4] - 2021-11-17 # Simplified options Optimize video WTA-hash for use with 64-bit granular features [0.1.3] - 2021-11-15 # Try to compile Cython/C accelerator modules when installing via pip Simplify soft_hash api return values Add .code() method to InstanceHasher, DataHasher Remove granular fingerprint calculation Add more top-level imports [0.1.2] - 2021-11-14 # Export more functions to toplevel Return schema driven objects from ISCC code generators. [0.1.1] - 2021-11-14 # Fix packaging problems [0.1.0] - 2021-11-13 # Initial release","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#025-unreleased","text":"Fixed missing jcs dependency Added SubType NONE to MT.ISCC to distinquish from SUM Added support for deterministic generation of random ISCC-CODEs Added support for custom bit-sizes for random ISCC-CODEs Moved changelog into separate file Updated dependencies","title":"[0.2.5] - Unreleased"},{"location":"changelog/#024-2022-03-19","text":"Updated dependencies Added Flake.from_int and Flake.from_string Made Flake comparable and hashable Use standard hex encoded multihash for datahash and metahash","title":"[0.2.4] - 2022-03-19"},{"location":"changelog/#023-2022-03-06","text":"Update to iscc-schema 0.3.3 Change image normalization instructions Fix issue with exporting cdc cython only functions","title":"[0.2.3] - 2022-03-06"},{"location":"changelog/#021-2022-03-03","text":"Cleanup and update dependencies Fix bitarray api change Fix developer commands","title":"[0.2.1] - 2022-03-03"},{"location":"changelog/#020-2022-02-24","text":"Complete API refactoring Use Data-URL as input for Meta-Code Use wallet address for ISCC-ID creation Added new Flake-Code (distributed time/random ID) Replaced assertions with exeptions Use secure random functions Retired Python 3.6 support (EOL) Return simple dict objects from generator functions Added ISCC string validation Added multiple helper functions","title":"[0.2.0] - 2022-02-24"},{"location":"changelog/#019-2021-12-17","text":"Added warning on non-standard options Added multiformats support Added uri representation Removed redundant cdc_avg_chunk_size option Updated codec format documentation","title":"[0.1.9] - 2021-12-17"},{"location":"changelog/#018-2021-12-12","text":"Added conformance tests for all top level functions Added conformance tests to source dir Added conformance module with selftest function Changed gen_image_code to accept normalized pixels instead of stream Changed opts to core_opts Removed image pre-processing and Pillow dependency Fixed readability of conformance tests Fixed soft_hash_video_v0 to accept non-tuple sequences Updated example code","title":"[0.1.8] - 2021-12-12"},{"location":"changelog/#017-2021-12-09","text":"Add dotenv for enviroment based configuration Cleanup package toplevel imports Return schema objects for iscc_code and iscc_id Exclude unset and none values from result dicts Add support for multiple code combinations for ISCC-CODE Add support for ISCC-ID based on singular Instance-Code Add initial conformance test system","title":"[0.1.7] - 2021-12-09"},{"location":"changelog/#016-2021-11-29","text":"Show counter for ISCC-ID in Code.explain","title":"[0.1.6] - 2021-11-29"},{"location":"changelog/#015-2021-11-28","text":"Fix documentation Change metahash creation logic Refactor models Add Content-Code-Mixed Add ISCC-ID Refactor compose to gen_iscc_code Refactor models to schema","title":"[0.1.5] - 2021-11-28"},{"location":"changelog/#014-2021-11-17","text":"Simplified options Optimize video WTA-hash for use with 64-bit granular features","title":"[0.1.4] - 2021-11-17"},{"location":"changelog/#013-2021-11-15","text":"Try to compile Cython/C accelerator modules when installing via pip Simplify soft_hash api return values Add .code() method to InstanceHasher, DataHasher Remove granular fingerprint calculation Add more top-level imports","title":"[0.1.3] - 2021-11-15"},{"location":"changelog/#012-2021-11-14","text":"Export more functions to toplevel Return schema driven objects from ISCC code generators.","title":"[0.1.2] - 2021-11-14"},{"location":"changelog/#011-2021-11-14","text":"Fix packaging problems","title":"[0.1.1] - 2021-11-14"},{"location":"changelog/#010-2021-11-13","text":"Initial release","title":"[0.1.0] - 2021-11-13"},{"location":"conformance/","text":"ISCC - Conformance Testing # An application that claims ISCC conformance MUST pass all core functions from the ISCC conformance test suite. The test suite is available as JSON data on Github . Test data is structured as follows: { \"<function_name>\" : { \"<test_name>\" : { \"inputs\" : [ \"<value1>\" , \"<value2>\" ], \"outputs\" : [ \"value1>\" , \"<value2>\" ] } } } Inputs that are expected to be raw bytes or byte-streams are embedded as HEX encoded strings in JSON and prefixed with stream: or bytes to support automated decoding during implementation testing. Example Byte-stream outputs in JSON test data: \"gen_data_code_v0\" : { \"test_0000_two_bytes_64\" : { \"inputs\" : [ \"stream:ff00\" , 64 ], \"outputs\" : { \"iscc\" : \"GAAXL2XYM5BQIAZ3\" } }, ... conformance_testdata () # Yield tuples of test data. Returns: Type Description Union[Generat,[Tuple[str, Callable, List[Any], List[Any]]]] Tuple with testdata (test_name, func_obj, inputs, outputs) conformance_selftest () # Run conformance tests. Returns: Type Description bool whether all tests passed","title":"Conformance"},{"location":"conformance/#iscc-conformance-testing","text":"An application that claims ISCC conformance MUST pass all core functions from the ISCC conformance test suite. The test suite is available as JSON data on Github . Test data is structured as follows: { \"<function_name>\" : { \"<test_name>\" : { \"inputs\" : [ \"<value1>\" , \"<value2>\" ], \"outputs\" : [ \"value1>\" , \"<value2>\" ] } } } Inputs that are expected to be raw bytes or byte-streams are embedded as HEX encoded strings in JSON and prefixed with stream: or bytes to support automated decoding during implementation testing. Example Byte-stream outputs in JSON test data: \"gen_data_code_v0\" : { \"test_0000_two_bytes_64\" : { \"inputs\" : [ \"stream:ff00\" , 64 ], \"outputs\" : { \"iscc\" : \"GAAXL2XYM5BQIAZ3\" } }, ...","title":"ISCC - Conformance Testing"},{"location":"conformance/#iscc_core.conformance.conformance_testdata","text":"Yield tuples of test data. Returns: Type Description Union[Generat,[Tuple[str, Callable, List[Any], List[Any]]]] Tuple with testdata (test_name, func_obj, inputs, outputs)","title":"conformance_testdata()"},{"location":"conformance/#iscc_core.conformance.conformance_selftest","text":"Run conformance tests. Returns: Type Description bool whether all tests passed","title":"conformance_selftest()"},{"location":"constants/","text":"ISCC - Types and Constants # MT # MT - MainTypes # Uint Symbol Bits Purpose 0 META 0000 Match on metadata similarity 1 SEMANTIC 0001 Match on semantic content similarity 2 CONTENT 0010 Match on perceptual content similarity 3 DATA 0011 Match on data similarity 4 INSTANCE 0100 Match on data identity 5 ISCC 0101 Composite of two or more ISCC-UNITs with common header 6 ID 0110 Short unique identifier bound to ISCC, timestamp, pubkey 7 FLAKE 0111 Unique time, randomness and counter based distributed ID ST # ST - SubTypes # Uint Symbol Bits Purpose 0 NONE 0000 For MainTypes that do not specify SubTypes ST_CC # ST_CC # SubTypes for MT.CONTENT Uint Symbol Bits Purpose 0 TEXT 0000 Match on syntactic text similarity 1 IMAGE 0001 Match on perceptual image similarity 2 AUDIO 0010 Match on audio chroma similarity 3 VIDEO 0011 Match on perceptual similarity 4 MIXED 0100 Match on similarity of content codes ST_ISCC # ST_ISCC # SubTypes for MT.ISCC Uint Symbol Bits Purpose 0 TEXT 0000 Composite ISCC inlcuding Text-Code 1 IMAGE 0001 Composite ISCC inlcuding Image-Code 2 AUDIO 0010 Composite ISCC inlcuding Audio-Code 3 VIDEO 0011 Composite ISCC inlcuding Video-Code 4 MIXED 0100 Composite ISCC inlcuding Mixed-Code 5 SUM 0101 Composite ISCC inlcuding only Data- and Instance-Code 6 NONE 0110 Composite ISCC including Meta, Data and Instance-Code ST_ID # ST_ID # SubTypes for MT.ID Uint Symbol Bits Purpose 0 PRIVATE 0000 ISCC-ID minted via private repository (not unique) 1 BITCOIN 0001 ISCC-ID minted via Bitcoin blockchain 2 ETHEREUM 0010 ISCC-ID minted via Ethereum blockchain 3 POLYGON 0011 ISCC-ID minted via Polygon blockchain VS # VS - Version # Code Version Uint Symbol Bits Purpose 0 V0 0000 Initial Version of Code without breaking changes LN # LN - Length # Valid lengths for hash-digests. MULTIBASE # Supported Multibase encodings.","title":"Types"},{"location":"constants/#iscc-types-and-constants","text":"","title":"ISCC - Types and Constants"},{"location":"constants/#iscc_core.constants.MT","text":"","title":"MT"},{"location":"constants/#iscc_core.constants.MT--mt-maintypes","text":"Uint Symbol Bits Purpose 0 META 0000 Match on metadata similarity 1 SEMANTIC 0001 Match on semantic content similarity 2 CONTENT 0010 Match on perceptual content similarity 3 DATA 0011 Match on data similarity 4 INSTANCE 0100 Match on data identity 5 ISCC 0101 Composite of two or more ISCC-UNITs with common header 6 ID 0110 Short unique identifier bound to ISCC, timestamp, pubkey 7 FLAKE 0111 Unique time, randomness and counter based distributed ID","title":"MT - MainTypes"},{"location":"constants/#iscc_core.constants.ST","text":"","title":"ST"},{"location":"constants/#iscc_core.constants.ST--st-subtypes","text":"Uint Symbol Bits Purpose 0 NONE 0000 For MainTypes that do not specify SubTypes","title":"ST - SubTypes"},{"location":"constants/#iscc_core.constants.ST_CC","text":"","title":"ST_CC"},{"location":"constants/#iscc_core.constants.ST_CC--st_cc","text":"SubTypes for MT.CONTENT Uint Symbol Bits Purpose 0 TEXT 0000 Match on syntactic text similarity 1 IMAGE 0001 Match on perceptual image similarity 2 AUDIO 0010 Match on audio chroma similarity 3 VIDEO 0011 Match on perceptual similarity 4 MIXED 0100 Match on similarity of content codes","title":"ST_CC"},{"location":"constants/#iscc_core.constants.ST_ISCC","text":"","title":"ST_ISCC"},{"location":"constants/#iscc_core.constants.ST_ISCC--st_iscc","text":"SubTypes for MT.ISCC Uint Symbol Bits Purpose 0 TEXT 0000 Composite ISCC inlcuding Text-Code 1 IMAGE 0001 Composite ISCC inlcuding Image-Code 2 AUDIO 0010 Composite ISCC inlcuding Audio-Code 3 VIDEO 0011 Composite ISCC inlcuding Video-Code 4 MIXED 0100 Composite ISCC inlcuding Mixed-Code 5 SUM 0101 Composite ISCC inlcuding only Data- and Instance-Code 6 NONE 0110 Composite ISCC including Meta, Data and Instance-Code","title":"ST_ISCC"},{"location":"constants/#iscc_core.constants.ST_ID","text":"","title":"ST_ID"},{"location":"constants/#iscc_core.constants.ST_ID--st_id","text":"SubTypes for MT.ID Uint Symbol Bits Purpose 0 PRIVATE 0000 ISCC-ID minted via private repository (not unique) 1 BITCOIN 0001 ISCC-ID minted via Bitcoin blockchain 2 ETHEREUM 0010 ISCC-ID minted via Ethereum blockchain 3 POLYGON 0011 ISCC-ID minted via Polygon blockchain","title":"ST_ID"},{"location":"constants/#iscc_core.constants.VS","text":"","title":"VS"},{"location":"constants/#iscc_core.constants.VS--vs-version","text":"Code Version Uint Symbol Bits Purpose 0 V0 0000 Initial Version of Code without breaking changes","title":"VS - Version"},{"location":"constants/#iscc_core.constants.LN","text":"","title":"LN"},{"location":"constants/#iscc_core.constants.LN--ln-length","text":"Valid lengths for hash-digests.","title":"LN - Length"},{"location":"constants/#iscc_core.constants.MULTIBASE","text":"Supported Multibase encodings.","title":"MULTIBASE"},{"location":"iscc_code/","text":"ISCC-CODE # A multi-component identifier for digital media assets. An ISCC-CODE can be generated from the concatenation of the digests of the following five ISCC-UNITs together with a single common header: Meta-Code - Encodes metadata similarity Semantic-Code - Encodes semantic content similarity (to be developed) Content-Code - Encodes syntactic/perceptual similarity Data-Code - Encodes raw bitstream similarity Instance-Code - Data checksum The following sequences of ISCC-UNITs are possible: Data, Instance Content, Data, Instance Semantic, Data, Instance Content, Semantic, Data, Instance Meta, Data, Instance Meta, Content, Data, Instance Meta, Semantic, Data, Instance Meta, Semantic, Content, Data, Instance gen_iscc_code_v0 ( codes ) # Combine multiple ISCC-UNITS to an ISCC-CODE with a common header using algorithm v0. Parameters: Name Type Description Default codes Sequence[str] A valid sequence of singluar ISCC-UNITS. required Returns: Type Description dict An ISCC object with ISCC-CODE Source code in iscc_core\\iscc_code.py def gen_iscc_code_v0 ( codes ): # type: (Sequence[str]) -> dict \"\"\" Combine multiple ISCC-UNITS to an ISCC-CODE with a common header using algorithm v0. :param Sequence[str] codes: A valid sequence of singluar ISCC-UNITS. :return: An ISCC object with ISCC-CODE :rtype: dict \"\"\" codes = [ ic . iscc_clean ( code ) for code in codes ] # Check basic constraints if len ( codes ) < 2 : raise ValueError ( \"Minimum two ISCC units required to generate valid ISCC-CODE\" ) for code in codes : if len ( code ) < 16 : raise ValueError ( f \"Cannot build ISCC-CODE from units shorter than 64-bits: { code } \" ) # Decode units and sort by MainType decoded = sorted ( [ ic . decode_header ( ic . decode_base32 ( code )) for code in codes ], key = itemgetter ( 0 ) ) main_types = tuple ( d [ 0 ] for d in decoded ) if main_types [ - 2 :] != ( ic . MT . DATA , ic . MT . INSTANCE ): raise ValueError ( f \"ISCC-CODE requires at least MT.DATA and MT.INSTANCE units.\" ) # Determine SubType (generic mediatype) sub_types = [ t [ 1 ] for t in decoded if t [ 0 ] in { ic . MT . SEMANTIC , ic . MT . CONTENT }] if len ( set ( sub_types )) > 1 : raise ValueError ( f \"Semantic-Code and Content-Code must be of same SubType\" ) st = sub_types . pop () if sub_types else ic . ST_ISCC . SUM if len ( codes ) == 2 else ic . ST_ISCC . NONE # Encode unit combination encoded_length = ic . encode_units ( main_types [: - 2 ]) # Collect and truncate unit digests to 64-bit digest = b \"\" . join ([ t [ - 1 ][: 8 ] for t in decoded ]) header = ic . encode_header ( ic . MT . ISCC , st , ic . VS . V0 , encoded_length ) code = ic . encode_base32 ( header + digest ) iscc = \"ISCC:\" + code return dict ( iscc = iscc )","title":"ISCC-CODE"},{"location":"iscc_code/#iscc-code","text":"A multi-component identifier for digital media assets. An ISCC-CODE can be generated from the concatenation of the digests of the following five ISCC-UNITs together with a single common header: Meta-Code - Encodes metadata similarity Semantic-Code - Encodes semantic content similarity (to be developed) Content-Code - Encodes syntactic/perceptual similarity Data-Code - Encodes raw bitstream similarity Instance-Code - Data checksum The following sequences of ISCC-UNITs are possible: Data, Instance Content, Data, Instance Semantic, Data, Instance Content, Semantic, Data, Instance Meta, Data, Instance Meta, Content, Data, Instance Meta, Semantic, Data, Instance Meta, Semantic, Content, Data, Instance","title":"ISCC-CODE"},{"location":"iscc_code/#iscc_core.iscc_code.gen_iscc_code_v0","text":"Combine multiple ISCC-UNITS to an ISCC-CODE with a common header using algorithm v0. Parameters: Name Type Description Default codes Sequence[str] A valid sequence of singluar ISCC-UNITS. required Returns: Type Description dict An ISCC object with ISCC-CODE Source code in iscc_core\\iscc_code.py def gen_iscc_code_v0 ( codes ): # type: (Sequence[str]) -> dict \"\"\" Combine multiple ISCC-UNITS to an ISCC-CODE with a common header using algorithm v0. :param Sequence[str] codes: A valid sequence of singluar ISCC-UNITS. :return: An ISCC object with ISCC-CODE :rtype: dict \"\"\" codes = [ ic . iscc_clean ( code ) for code in codes ] # Check basic constraints if len ( codes ) < 2 : raise ValueError ( \"Minimum two ISCC units required to generate valid ISCC-CODE\" ) for code in codes : if len ( code ) < 16 : raise ValueError ( f \"Cannot build ISCC-CODE from units shorter than 64-bits: { code } \" ) # Decode units and sort by MainType decoded = sorted ( [ ic . decode_header ( ic . decode_base32 ( code )) for code in codes ], key = itemgetter ( 0 ) ) main_types = tuple ( d [ 0 ] for d in decoded ) if main_types [ - 2 :] != ( ic . MT . DATA , ic . MT . INSTANCE ): raise ValueError ( f \"ISCC-CODE requires at least MT.DATA and MT.INSTANCE units.\" ) # Determine SubType (generic mediatype) sub_types = [ t [ 1 ] for t in decoded if t [ 0 ] in { ic . MT . SEMANTIC , ic . MT . CONTENT }] if len ( set ( sub_types )) > 1 : raise ValueError ( f \"Semantic-Code and Content-Code must be of same SubType\" ) st = sub_types . pop () if sub_types else ic . ST_ISCC . SUM if len ( codes ) == 2 else ic . ST_ISCC . NONE # Encode unit combination encoded_length = ic . encode_units ( main_types [: - 2 ]) # Collect and truncate unit digests to 64-bit digest = b \"\" . join ([ t [ - 1 ][: 8 ] for t in decoded ]) header = ic . encode_header ( ic . MT . ISCC , st , ic . VS . V0 , encoded_length ) code = ic . encode_base32 ( header + digest ) iscc = \"ISCC:\" + code return dict ( iscc = iscc )","title":"gen_iscc_code_v0()"},{"location":"iscc_id/","text":"ISCC-ID # A decentralized, owned, and short identifier for digital assets. The ISCC-ID is generated from a similarity-hash of the units of an ISCC-CODE together with a blockchain wallet address. Its SubType designates the blockchain from which the ISCC-ID was minted. The similarity-hash is always at least 64-bits and optionally suffixed with a uvarint endcoded uniqueness counter . The uniqueness counter is added and incremented only if the mint colides with a pre-existing ISCC-ID minted from the same blockchain from a different ISCC-CODE or from an identical ISCC-CODE registered by a different signatory. gen_iscc_id ( iscc_code , chain_id , wallet , uc = 0 ) # Generate ISCC-ID from ISCC-CODE with the latest standard algorithm. Parameters: Name Type Description Default iscc_code str The ISCC-CODE from which to mint the ISCC-ID. required chain_id int Chain-ID of blockchain from which the ISCC-ID is minted. required wallet str The wallet address that signes the ISCC declaration required uc int Uniqueness counter of ISCC-ID. 0 Returns: Type Description dict ISCC object with an ISCC-ID gen_iscc_id_v0 ( iscc_code , chain_id , wallet , uc = 0 ) # Generate an ISCC-ID from an ISCC-CODE with uniqueness counter 'uc' with algorithm v0. Parameters: Name Type Description Default iscc_code str The ISCC-CODE from which to mint the ISCC-ID. required chain_id int Chain-ID of blockchain from which the ISCC-ID is minted. required wallet str The wallet address that signes the ISCC declaration required uc int Uniqueness counter of ISCC-ID. 0 Returns: Type Description dict ISCC object with an ISCC-ID soft_hash_iscc_id_v0 ( iscc_code , wallet , uc = 0 ) # Calculate ISCC-ID hash digest from ISCC-CODE with algorithm v0. Accepts an ISCC-CODE or any sequence of ISCC-UNITs. Parameters: Name Type Description Default iscc_code str ISCC-CODE required wallet str The wallet address that signes the ISCC declaration required uc int Uniqueness counter for ISCC-ID. 0 Returns: Type Description bytes Digest for ISCC-ID without header but including uniqueness counter. iscc_id_incr ( iscc_id ) # Increment uniqueness counter of an ISCC-ID with latest standard algorithm. Parameters: Name Type Description Default iscc_id str Base32-encoded ISCC-ID. required Returns: Type Description str Base32-encoded ISCC-ID with counter incremented by one. iscc_id_incr_v0 ( iscc_id ) # Increment uniqueness counter of an ISCC-ID with algorithm v0. Parameters: Name Type Description Default iscc_id str Base32-encoded ISCC-ID. required Returns: Type Description str Base32-encoded ISCC-ID with counter incremented by one. alg_simhash_from_iscc_id ( iscc_id , wallet ) # Extract similarity preserving hex-encoded hash digest from ISCC-ID We need to un-xor the ISCC-ID hash digest with the wallet address hash to obtain the similarity preserving bytestring.","title":"ISCC-ID"},{"location":"iscc_id/#iscc-id","text":"A decentralized, owned, and short identifier for digital assets. The ISCC-ID is generated from a similarity-hash of the units of an ISCC-CODE together with a blockchain wallet address. Its SubType designates the blockchain from which the ISCC-ID was minted. The similarity-hash is always at least 64-bits and optionally suffixed with a uvarint endcoded uniqueness counter . The uniqueness counter is added and incremented only if the mint colides with a pre-existing ISCC-ID minted from the same blockchain from a different ISCC-CODE or from an identical ISCC-CODE registered by a different signatory.","title":"ISCC-ID"},{"location":"iscc_id/#iscc_core.iscc_id.gen_iscc_id","text":"Generate ISCC-ID from ISCC-CODE with the latest standard algorithm. Parameters: Name Type Description Default iscc_code str The ISCC-CODE from which to mint the ISCC-ID. required chain_id int Chain-ID of blockchain from which the ISCC-ID is minted. required wallet str The wallet address that signes the ISCC declaration required uc int Uniqueness counter of ISCC-ID. 0 Returns: Type Description dict ISCC object with an ISCC-ID","title":"gen_iscc_id()"},{"location":"iscc_id/#iscc_core.iscc_id.gen_iscc_id_v0","text":"Generate an ISCC-ID from an ISCC-CODE with uniqueness counter 'uc' with algorithm v0. Parameters: Name Type Description Default iscc_code str The ISCC-CODE from which to mint the ISCC-ID. required chain_id int Chain-ID of blockchain from which the ISCC-ID is minted. required wallet str The wallet address that signes the ISCC declaration required uc int Uniqueness counter of ISCC-ID. 0 Returns: Type Description dict ISCC object with an ISCC-ID","title":"gen_iscc_id_v0()"},{"location":"iscc_id/#iscc_core.iscc_id.soft_hash_iscc_id_v0","text":"Calculate ISCC-ID hash digest from ISCC-CODE with algorithm v0. Accepts an ISCC-CODE or any sequence of ISCC-UNITs. Parameters: Name Type Description Default iscc_code str ISCC-CODE required wallet str The wallet address that signes the ISCC declaration required uc int Uniqueness counter for ISCC-ID. 0 Returns: Type Description bytes Digest for ISCC-ID without header but including uniqueness counter.","title":"soft_hash_iscc_id_v0()"},{"location":"iscc_id/#iscc_core.iscc_id.iscc_id_incr","text":"Increment uniqueness counter of an ISCC-ID with latest standard algorithm. Parameters: Name Type Description Default iscc_id str Base32-encoded ISCC-ID. required Returns: Type Description str Base32-encoded ISCC-ID with counter incremented by one.","title":"iscc_id_incr()"},{"location":"iscc_id/#iscc_core.iscc_id.iscc_id_incr_v0","text":"Increment uniqueness counter of an ISCC-ID with algorithm v0. Parameters: Name Type Description Default iscc_id str Base32-encoded ISCC-ID. required Returns: Type Description str Base32-encoded ISCC-ID with counter incremented by one.","title":"iscc_id_incr_v0()"},{"location":"iscc_id/#iscc_core.iscc_id.alg_simhash_from_iscc_id","text":"Extract similarity preserving hex-encoded hash digest from ISCC-ID We need to un-xor the ISCC-ID hash digest with the wallet address hash to obtain the similarity preserving bytestring.","title":"alg_simhash_from_iscc_id()"},{"location":"algorithms/cdc/","text":"ISCC - Content Defined Chunking # Compatible with fastcdc alg_cdc_chunks ( data , utf32 , avg_chunk_size = 1024 ) # A generator that yields data-dependent chunks for data . Usage Example: for chunk in cdc_data_chunks ( data ): hash ( chunk ) Parameters: Name Type Description Default data bytes Raw data for variable sized chunking. required utf32 bool If true assume we are chunking text that is utf32 encoded. required avg_chunk_size int Target chunk size in number of bytes. 1024 Returns: Type Description Union[Generat,[bytes]] A generator that yields data chunks of variable sizes. Source code in iscc_core\\cdc.py def alg_cdc_chunks ( data , utf32 , avg_chunk_size = ic . core_opts . data_avg_chunk_size ): # type: (Data, bool, int) -> Generator[bytes, None, None] \"\"\" A generator that yields data-dependent chunks for `data`. Usage Example: ```python for chunk in cdc_data_chunks(data): hash(chunk) ``` :param bytes data: Raw data for variable sized chunking. :param bool utf32: If true assume we are chunking text that is utf32 encoded. :param int avg_chunk_size: Target chunk size in number of bytes. :return: A generator that yields data chunks of variable sizes. :rtype: Generator[bytes] \"\"\" stream = io . BytesIO ( data ) buffer = stream . read ( ic . core_opts . io_read_size ) if not buffer : yield b \"\" mi , ma , cs , mask_s , mask_l = alg_cdc_params ( avg_chunk_size ) buffer = memoryview ( buffer ) while buffer : if len ( buffer ) <= ma : buffer = memoryview ( bytes ( buffer ) + stream . read ( ic . core_opts . io_read_size )) cut_point = alg_cdc_offset ( buffer , mi , ma , cs , mask_s , mask_l ) # Make sure cut points are at 4-byte aligned for utf32 encoded text if utf32 : cut_point -= cut_point % 4 yield bytes ( buffer [: cut_point ]) buffer = buffer [ cut_point :] alg_cdc_offset ( buffer , mi , ma , cs , mask_s , mask_l ) # Find breakpoint offset for a given buffer. Parameters: Name Type Description Default buffer Data The data to be chunked. required mi int Minimum chunk size. required ma int Maximung chunk size. required cs int Center size. required mask_s int Small mask. required mask_l int Large mask. required Returns: Type Description int Offset of dynamic cutpoint in number of bytes. Source code in iscc_core\\cdc.py def alg_cdc_offset ( buffer , mi , ma , cs , mask_s , mask_l ): # type: (ic.Data, int, int, int, int, int) -> int \"\"\" Find breakpoint offset for a given buffer. :param Data buffer: The data to be chunked. :param int mi: Minimum chunk size. :param int ma: Maximung chunk size. :param int cs: Center size. :param int mask_s: Small mask. :param int mask_l: Large mask. :return: Offset of dynamic cutpoint in number of bytes. :rtype: int \"\"\" pattern = 0 i = mi size = len ( buffer ) barrier = min ( cs , size ) while i < barrier : pattern = ( pattern >> 1 ) + ic . core_opts . cdc_gear [ buffer [ i ]] if not pattern & mask_s : return i + 1 i += 1 barrier = min ( ma , size ) while i < barrier : pattern = ( pattern >> 1 ) + ic . core_opts . cdc_gear [ buffer [ i ]] if not pattern & mask_l : return i + 1 i += 1 return i alg_cdc_params ( avg_size : int ) -> tuple # Calculate CDC parameters Parameters: Name Type Description Default avg_size int Target average size of chunks in number of bytes. required Returns: Type Description tuple Tuple of (min_size, max_size, center_size, mask_s, mask_l). Source code in iscc_core\\cdc.py def alg_cdc_params ( avg_size : int ) -> tuple : \"\"\" Calculate CDC parameters :param int avg_size: Target average size of chunks in number of bytes. :returns: Tuple of (min_size, max_size, center_size, mask_s, mask_l). \"\"\" ceil_div = lambda x , y : ( x + y - 1 ) // y mask = lambda b : 2 ** b - 1 min_size = avg_size // 4 max_size = avg_size * 8 offset = min_size + ceil_div ( min_size , 2 ) center_size = avg_size - offset bits = round ( log2 ( avg_size )) mask_s = mask ( bits + 1 ) mask_l = mask ( bits - 1 ) return min_size , max_size , center_size , mask_s , mask_l","title":"CDC"},{"location":"algorithms/cdc/#iscc-content-defined-chunking","text":"Compatible with fastcdc","title":"ISCC - Content Defined Chunking"},{"location":"algorithms/cdc/#iscc_core.cdc.alg_cdc_chunks","text":"A generator that yields data-dependent chunks for data . Usage Example: for chunk in cdc_data_chunks ( data ): hash ( chunk ) Parameters: Name Type Description Default data bytes Raw data for variable sized chunking. required utf32 bool If true assume we are chunking text that is utf32 encoded. required avg_chunk_size int Target chunk size in number of bytes. 1024 Returns: Type Description Union[Generat,[bytes]] A generator that yields data chunks of variable sizes. Source code in iscc_core\\cdc.py def alg_cdc_chunks ( data , utf32 , avg_chunk_size = ic . core_opts . data_avg_chunk_size ): # type: (Data, bool, int) -> Generator[bytes, None, None] \"\"\" A generator that yields data-dependent chunks for `data`. Usage Example: ```python for chunk in cdc_data_chunks(data): hash(chunk) ``` :param bytes data: Raw data for variable sized chunking. :param bool utf32: If true assume we are chunking text that is utf32 encoded. :param int avg_chunk_size: Target chunk size in number of bytes. :return: A generator that yields data chunks of variable sizes. :rtype: Generator[bytes] \"\"\" stream = io . BytesIO ( data ) buffer = stream . read ( ic . core_opts . io_read_size ) if not buffer : yield b \"\" mi , ma , cs , mask_s , mask_l = alg_cdc_params ( avg_chunk_size ) buffer = memoryview ( buffer ) while buffer : if len ( buffer ) <= ma : buffer = memoryview ( bytes ( buffer ) + stream . read ( ic . core_opts . io_read_size )) cut_point = alg_cdc_offset ( buffer , mi , ma , cs , mask_s , mask_l ) # Make sure cut points are at 4-byte aligned for utf32 encoded text if utf32 : cut_point -= cut_point % 4 yield bytes ( buffer [: cut_point ]) buffer = buffer [ cut_point :]","title":"alg_cdc_chunks()"},{"location":"algorithms/cdc/#iscc_core.cdc.alg_cdc_offset","text":"Find breakpoint offset for a given buffer. Parameters: Name Type Description Default buffer Data The data to be chunked. required mi int Minimum chunk size. required ma int Maximung chunk size. required cs int Center size. required mask_s int Small mask. required mask_l int Large mask. required Returns: Type Description int Offset of dynamic cutpoint in number of bytes. Source code in iscc_core\\cdc.py def alg_cdc_offset ( buffer , mi , ma , cs , mask_s , mask_l ): # type: (ic.Data, int, int, int, int, int) -> int \"\"\" Find breakpoint offset for a given buffer. :param Data buffer: The data to be chunked. :param int mi: Minimum chunk size. :param int ma: Maximung chunk size. :param int cs: Center size. :param int mask_s: Small mask. :param int mask_l: Large mask. :return: Offset of dynamic cutpoint in number of bytes. :rtype: int \"\"\" pattern = 0 i = mi size = len ( buffer ) barrier = min ( cs , size ) while i < barrier : pattern = ( pattern >> 1 ) + ic . core_opts . cdc_gear [ buffer [ i ]] if not pattern & mask_s : return i + 1 i += 1 barrier = min ( ma , size ) while i < barrier : pattern = ( pattern >> 1 ) + ic . core_opts . cdc_gear [ buffer [ i ]] if not pattern & mask_l : return i + 1 i += 1 return i","title":"alg_cdc_offset()"},{"location":"algorithms/cdc/#iscc_core.cdc.alg_cdc_params","text":"Calculate CDC parameters Parameters: Name Type Description Default avg_size int Target average size of chunks in number of bytes. required Returns: Type Description tuple Tuple of (min_size, max_size, center_size, mask_s, mask_l). Source code in iscc_core\\cdc.py def alg_cdc_params ( avg_size : int ) -> tuple : \"\"\" Calculate CDC parameters :param int avg_size: Target average size of chunks in number of bytes. :returns: Tuple of (min_size, max_size, center_size, mask_s, mask_l). \"\"\" ceil_div = lambda x , y : ( x + y - 1 ) // y mask = lambda b : 2 ** b - 1 min_size = avg_size // 4 max_size = avg_size * 8 offset = min_size + ceil_div ( min_size , 2 ) center_size = avg_size - offset bits = round ( log2 ( avg_size )) mask_s = mask ( bits + 1 ) mask_l = mask ( bits - 1 ) return min_size , max_size , center_size , mask_s , mask_l","title":"alg_cdc_params()"},{"location":"algorithms/dct/","text":"ISCC - Discrete Cosine Transform # alg_dct ( v ) # Discrete cosine transform. See: nayuki.io . Parameters: Name Type Description Default v Sequence[float] Input vector for DCT calculation. required Returns: Type Description List DCT Transformed vector. Source code in iscc_core\\dct.py def alg_dct ( v ): # type: (Sequence[float]) -> List \"\"\" Discrete cosine transform. See: [nayuki.io](https://www.nayuki.io/page/fast-discrete-cosine-transform-algorithms). :param Sequence[float] v: Input vector for DCT calculation. :return: DCT Transformed vector. :rtype: List \"\"\" n = len ( v ) if n == 1 : return list ( v ) elif n == 0 or n % 2 != 0 : raise ValueError () else : half = n // 2 alpha = [( v [ i ] + v [ - ( i + 1 )]) for i in range ( half )] beta = [ ( v [ i ] - v [ - ( i + 1 )]) / ( math . cos (( i + 0.5 ) * math . pi / n ) * 2.0 ) for i in range ( half ) ] alpha = alg_dct ( alpha ) beta = alg_dct ( beta ) result = [] for i in range ( half - 1 ): result . append ( alpha [ i ]) result . append ( beta [ i ] + beta [ i + 1 ]) result . append ( alpha [ - 1 ]) result . append ( beta [ - 1 ]) return result","title":"DCT"},{"location":"algorithms/dct/#iscc-discrete-cosine-transform","text":"","title":"ISCC - Discrete Cosine Transform"},{"location":"algorithms/dct/#iscc_core.dct.alg_dct","text":"Discrete cosine transform. See: nayuki.io . Parameters: Name Type Description Default v Sequence[float] Input vector for DCT calculation. required Returns: Type Description List DCT Transformed vector. Source code in iscc_core\\dct.py def alg_dct ( v ): # type: (Sequence[float]) -> List \"\"\" Discrete cosine transform. See: [nayuki.io](https://www.nayuki.io/page/fast-discrete-cosine-transform-algorithms). :param Sequence[float] v: Input vector for DCT calculation. :return: DCT Transformed vector. :rtype: List \"\"\" n = len ( v ) if n == 1 : return list ( v ) elif n == 0 or n % 2 != 0 : raise ValueError () else : half = n // 2 alpha = [( v [ i ] + v [ - ( i + 1 )]) for i in range ( half )] beta = [ ( v [ i ] - v [ - ( i + 1 )]) / ( math . cos (( i + 0.5 ) * math . pi / n ) * 2.0 ) for i in range ( half ) ] alpha = alg_dct ( alpha ) beta = alg_dct ( beta ) result = [] for i in range ( half - 1 ): result . append ( alpha [ i ]) result . append ( beta [ i ] + beta [ i + 1 ]) result . append ( alpha [ - 1 ]) result . append ( beta [ - 1 ]) return result","title":"alg_dct()"},{"location":"algorithms/minhash/","text":"ISCC - Minhash # alg_minhash ( features ) # Calculate a 64 dimensional minhash integer vector. Parameters: Name Type Description Default features List[int] List of integer features required Returns: Type Description List[int] Minhash vector Source code in iscc_core\\minhash.py def alg_minhash ( features ): # type: (List[int]) -> List[int] \"\"\" Calculate a 64 dimensional minhash integer vector. :param List[int] features: List of integer features :return: Minhash vector :rtype: List[int] \"\"\" return [ min ([((( a * f + b ) & MAXI64 ) % MPRIME ) & MAXH for f in features ]) for a , b in zip ( MPA , MPB ) ] alg_minhash_64 ( features ) # Create 64-bit minimum hash digest. Parameters: Name Type Description Default features List[int] List of integer features required Returns: Type Description bytes 64-bit binary from the least significant bits of the minhash values Source code in iscc_core\\minhash.py def alg_minhash_64 ( features ): # type: (List[int]) -> bytes \"\"\" Create 64-bit minimum hash digest. :param List[int] features: List of integer features :return: 64-bit binary from the least significant bits of the minhash values :rtype: bytes \"\"\" return alg_minhash_compress ( alg_minhash ( features ), 1 ) alg_minhash_256 ( features ) # Create 256-bit minimum hash digest. Parameters: Name Type Description Default features List[int] List of integer features required Returns: Type Description bytes 256-bit binary from the least significant bits of the minhash values Source code in iscc_core\\minhash.py def alg_minhash_256 ( features ): # type: (List[int]) -> bytes \"\"\" Create 256-bit minimum hash digest. :param List[int] features: List of integer features :return: 256-bit binary from the least significant bits of the minhash values :rtype: bytes \"\"\" return alg_minhash_compress ( alg_minhash ( features ), 4 ) alg_minhash_compress ( mhash , lsb = 4 ) # Compress minhash vector to byte hash-digest. Concatenates lsb number of least-significant bits from each integer in mhash . For example an mhash with 64 integers and lsb=4 will produce a 256-bit summary of the minhash vector. Parameters: Name Type Description Default mhash List[int] List of minhash integer features required lsb int Number of the least significant bits to retain 4 Returns: Type Description bytes 256-bit binary from the least significant bits of the minhash values Source code in iscc_core\\minhash.py def alg_minhash_compress ( mhash , lsb = 4 ): # type: (List[int], int) -> bytes \"\"\" Compress minhash vector to byte hash-digest. Concatenates `lsb` number of least-significant bits from each integer in `mhash`. For example an `mhash` with 64 integers and `lsb=4` will produce a 256-bit summary of the minhash vector. :param List[int] mhash: List of minhash integer features :param int lsb: Number of the least significant bits to retain :return: 256-bit binary from the least significant bits of the minhash values :rtype: bytes \"\"\" bits : str = \"\" for bitpos in range ( lsb ): for h in mhash : bits += str ( h >> bitpos & 1 ) return int ( bits , 2 ) . to_bytes (( len ( bits ) + 7 ) // 8 , \"big\" )","title":"Minhash"},{"location":"algorithms/minhash/#iscc-minhash","text":"","title":"ISCC - Minhash"},{"location":"algorithms/minhash/#iscc_core.minhash.alg_minhash","text":"Calculate a 64 dimensional minhash integer vector. Parameters: Name Type Description Default features List[int] List of integer features required Returns: Type Description List[int] Minhash vector Source code in iscc_core\\minhash.py def alg_minhash ( features ): # type: (List[int]) -> List[int] \"\"\" Calculate a 64 dimensional minhash integer vector. :param List[int] features: List of integer features :return: Minhash vector :rtype: List[int] \"\"\" return [ min ([((( a * f + b ) & MAXI64 ) % MPRIME ) & MAXH for f in features ]) for a , b in zip ( MPA , MPB ) ]","title":"alg_minhash()"},{"location":"algorithms/minhash/#iscc_core.minhash.alg_minhash_64","text":"Create 64-bit minimum hash digest. Parameters: Name Type Description Default features List[int] List of integer features required Returns: Type Description bytes 64-bit binary from the least significant bits of the minhash values Source code in iscc_core\\minhash.py def alg_minhash_64 ( features ): # type: (List[int]) -> bytes \"\"\" Create 64-bit minimum hash digest. :param List[int] features: List of integer features :return: 64-bit binary from the least significant bits of the minhash values :rtype: bytes \"\"\" return alg_minhash_compress ( alg_minhash ( features ), 1 )","title":"alg_minhash_64()"},{"location":"algorithms/minhash/#iscc_core.minhash.alg_minhash_256","text":"Create 256-bit minimum hash digest. Parameters: Name Type Description Default features List[int] List of integer features required Returns: Type Description bytes 256-bit binary from the least significant bits of the minhash values Source code in iscc_core\\minhash.py def alg_minhash_256 ( features ): # type: (List[int]) -> bytes \"\"\" Create 256-bit minimum hash digest. :param List[int] features: List of integer features :return: 256-bit binary from the least significant bits of the minhash values :rtype: bytes \"\"\" return alg_minhash_compress ( alg_minhash ( features ), 4 )","title":"alg_minhash_256()"},{"location":"algorithms/minhash/#iscc_core.minhash.alg_minhash_compress","text":"Compress minhash vector to byte hash-digest. Concatenates lsb number of least-significant bits from each integer in mhash . For example an mhash with 64 integers and lsb=4 will produce a 256-bit summary of the minhash vector. Parameters: Name Type Description Default mhash List[int] List of minhash integer features required lsb int Number of the least significant bits to retain 4 Returns: Type Description bytes 256-bit binary from the least significant bits of the minhash values Source code in iscc_core\\minhash.py def alg_minhash_compress ( mhash , lsb = 4 ): # type: (List[int], int) -> bytes \"\"\" Compress minhash vector to byte hash-digest. Concatenates `lsb` number of least-significant bits from each integer in `mhash`. For example an `mhash` with 64 integers and `lsb=4` will produce a 256-bit summary of the minhash vector. :param List[int] mhash: List of minhash integer features :param int lsb: Number of the least significant bits to retain :return: 256-bit binary from the least significant bits of the minhash values :rtype: bytes \"\"\" bits : str = \"\" for bitpos in range ( lsb ): for h in mhash : bits += str ( h >> bitpos & 1 ) return int ( bits , 2 ) . to_bytes (( len ( bits ) + 7 ) // 8 , \"big\" )","title":"alg_minhash_compress()"},{"location":"algorithms/simhash/","text":"ISCC - Simhash # alg_simhash ( hash_digests ) # Creates a similarity preserving hash from a sequence of equal sized hash digests. Parameters: Name Type Description Default hash_digests list A sequence of equaly sized byte-hashes. required Returns: Type Description bytes Similarity byte-hash Source code in iscc_core\\simhash.py def alg_simhash ( hash_digests ): # type: (list[bytes]) -> bytes \"\"\" Creates a similarity preserving hash from a sequence of equal sized hash digests. :param list hash_digests: A sequence of equaly sized byte-hashes. :returns: Similarity byte-hash :rtype: bytes \"\"\" n_bytes = len ( hash_digests [ 0 ]) n_bits = n_bytes * 8 vector = [ 0 ] * n_bits for digest in hash_digests : h = int . from_bytes ( digest , \"big\" , signed = False ) for i in range ( n_bits ): vector [ i ] += h & 1 h >>= 1 minfeatures = len ( hash_digests ) * 1.0 / 2 shash = 0 for i in range ( n_bits ): shash |= int ( vector [ i ] >= minfeatures ) << i return shash . to_bytes ( n_bytes , \"big\" , signed = False )","title":"Simhash"},{"location":"algorithms/simhash/#iscc-simhash","text":"","title":"ISCC - Simhash"},{"location":"algorithms/simhash/#iscc_core.simhash.alg_simhash","text":"Creates a similarity preserving hash from a sequence of equal sized hash digests. Parameters: Name Type Description Default hash_digests list A sequence of equaly sized byte-hashes. required Returns: Type Description bytes Similarity byte-hash Source code in iscc_core\\simhash.py def alg_simhash ( hash_digests ): # type: (list[bytes]) -> bytes \"\"\" Creates a similarity preserving hash from a sequence of equal sized hash digests. :param list hash_digests: A sequence of equaly sized byte-hashes. :returns: Similarity byte-hash :rtype: bytes \"\"\" n_bytes = len ( hash_digests [ 0 ]) n_bits = n_bytes * 8 vector = [ 0 ] * n_bits for digest in hash_digests : h = int . from_bytes ( digest , \"big\" , signed = False ) for i in range ( n_bits ): vector [ i ] += h & 1 h >>= 1 minfeatures = len ( hash_digests ) * 1.0 / 2 shash = 0 for i in range ( n_bits ): shash |= int ( vector [ i ] >= minfeatures ) << i return shash . to_bytes ( n_bytes , \"big\" , signed = False )","title":"alg_simhash()"},{"location":"algorithms/wtahash/","text":"ISCC - Winner Takes All Hash # alg_wtahash ( vec : Sequence [ float ], bits ) -> bytes # Calculate WTA Hash for vector with 380 values (MP7 frame signature). Source code in iscc_core\\wtahash.py def alg_wtahash ( vec : Sequence [ float ], bits ) -> bytes : \"\"\"Calculate WTA Hash for vector with 380 values (MP7 frame signature).\"\"\" h = [] for perm in WTA_VIDEO_ID_PERMUTATIONS : v = vec [ perm [ 0 ]], vec [ perm [ 1 ]] h . append ( v . index ( max ( v ))) if len ( h ) == bits : break h = bitarray ( h ) . tobytes () return h","title":"WTAHash"},{"location":"algorithms/wtahash/#iscc-winner-takes-all-hash","text":"","title":"ISCC - Winner Takes All Hash"},{"location":"algorithms/wtahash/#iscc_core.wtahash.alg_wtahash","text":"Calculate WTA Hash for vector with 380 values (MP7 frame signature). Source code in iscc_core\\wtahash.py def alg_wtahash ( vec : Sequence [ float ], bits ) -> bytes : \"\"\"Calculate WTA Hash for vector with 380 values (MP7 frame signature).\"\"\" h = [] for perm in WTA_VIDEO_ID_PERMUTATIONS : v = vec [ perm [ 0 ]], vec [ perm [ 1 ]] h . append ( v . index ( max ( v ))) if len ( h ) == bits : break h = bitarray ( h ) . tobytes () return h","title":"alg_wtahash()"},{"location":"codec/","text":"ISCC - Codec # This module implements encoding, decoding and transcoding functions of ISCC Codec Overview # Codec Functions # encode_component ( mtype , stype , version , bit_length , digest ) # Encode an ISCC unit inlcuding header and body with standard base32 encoding. Note The length value must be the length in number of bits for the component. If digest has more bits than specified by length it wil be truncated. Parameters: Name Type Description Default mtype MainType Maintype of unit (0-6) required stype SubType SubType of unit depending on MainType (0-5) required version Version Version of unit algorithm (0). required bit_length length Length of unit, in number of bits (multiple of 32) required digest bytes The hash digest of the unit. required Returns: Type Description str Base32 encoded ISCC-UNIT. Source code in iscc_core\\codec.py def encode_component ( mtype , stype , version , bit_length , digest ): # type: (MainType, SubType, Version, Length, bytes) -> str \"\"\" Encode an ISCC unit inlcuding header and body with standard base32 encoding. !!! note The `length` value must be the **length in number of bits** for the component. If `digest` has more bits than specified by `length` it wil be truncated. :param MainType mtype: Maintype of unit (0-6) :param SubType stype: SubType of unit depending on MainType (0-5) :param Version version: Version of unit algorithm (0). :param length bit_length: Length of unit, in number of bits (multiple of 32) :param bytes digest: The hash digest of the unit. :return: Base32 encoded ISCC-UNIT. :rtype: str \"\"\" if mtype in ( MT . META , MT . SEMANTIC , MT . CONTENT , MT . DATA , MT . INSTANCE , MT . ID , MT . FLAKE ): encoded_length = encode_length ( mtype , bit_length ) elif mtype == MT . ISCC : raise ValueError ( f \" { mtype } is not a unit\" ) else : raise ValueError ( f \"Illegal MainType { mtype } \" ) nbytes = bit_length // 8 header = encode_header ( mtype , stype , version , encoded_length ) body = digest [: nbytes ] component_code = encode_base32 ( header + body ) return component_code encode_header ( mtype , stype , version = 0 , length = 1 ) # Encodes header values with nibble-sized (4-bit) variable-length encoding. The result is minimum 2 and maximum 8 bytes long. If the final count of nibbles is uneven it is padded with 4-bit 0000 at the end. Warning The length value must be encoded beforhand because its semantics depend on the MainType (see encode_length function). Parameters: Name Type Description Default mtype MainType MainType of unit. required stype SubType SubType of unit. required version Version Version of component algorithm. 0 length Length length value of unit (1 means 64-bits for standard units) 1 Returns: Type Description bytes Varnibble stream encoded ISCC header as bytes. Source code in iscc_core\\codec.py def encode_header ( mtype , stype , version = 0 , length = 1 ): # type: (MainType, SubType, Version, Length) -> bytes \"\"\" Encodes header values with nibble-sized (4-bit) variable-length encoding. The result is minimum 2 and maximum 8 bytes long. If the final count of nibbles is uneven it is padded with 4-bit `0000` at the end. !!! warning The length value must be encoded beforhand because its semantics depend on the MainType (see `encode_length` function). :param MainType mtype: MainType of unit. :param SubType stype: SubType of unit. :param Version version: Version of component algorithm. :param Length length: length value of unit (1 means 64-bits for standard units) :return: Varnibble stream encoded ISCC header as bytes. :rtype: bytes \"\"\" # TODO verify that all header params and there combination is valid header = bitarray () for n in ( mtype , stype , version , length ): header += encode_varnibble ( n ) # Append zero-padding if required (right side, least significant bits). header . fill () return header . tobytes () encode_varnibble ( n ) # Writes integer to variable length sequence of 4-bit chunks. Variable-length encoding scheme: prefix bits nibbles data bits unsigned range 0 1 3 0 - 7 10 2 6 8 - 71 110 3 9 72 - 583 1110 4 12 584 - 4679 Parameters: Name Type Description Default n int Positive integer to be encoded as varnibble (0-4679) required Returns: Type Description bitarray Varnibble encoded integera Source code in iscc_core\\codec.py def encode_varnibble ( n ): # type: (int) -> bitarray \"\"\" Writes integer to variable length sequence of 4-bit chunks. Variable-length encoding scheme: ------------------------------------------------------ | prefix bits | nibbles | data bits | unsigned range | | ----------- | ------- | --------- | -------------- | | 0 | 1 | 3 | 0 - 7 | | 10 | 2 | 6 | 8 - 71 | | 110 | 3 | 9 | 72 - 583 | | 1110 | 4 | 12 | 584 - 4679 | :param int n: Positive integer to be encoded as varnibble (0-4679) :return: Varnibble encoded integera :rtype: bitarray \"\"\" if 0 <= n < 8 : return int2ba ( n , length = 4 ) elif 8 <= n < 72 : return bitarray ( \"10\" ) + int2ba ( n - 8 , length = 6 ) elif 72 <= n < 584 : return bitarray ( \"110\" ) + int2ba ( n - 72 , length = 9 ) elif 584 <= n < 4680 : return bitarray ( \"1110\" ) + int2ba ( n - 584 , length = 12 ) else : raise ValueError ( \"Value must be between 0 and 4679\" ) decode_header ( data ) # Decodes varnibble encoded header and returns it together with tail data . Tail data is included to enable decoding of sequential ISCCs. The returned tail data must be truncated to decode_length(r[0], r[3]) bits to recover the actual hash-bytes. Parameters: Name Type Description Default data bytes ISCC bytes required Returns: Type Description IsccTuple (MainType, SubType, Version, length, TailData) Source code in iscc_core\\codec.py def decode_header ( data ): # type: (bytes) -> IsccTuple \"\"\" Decodes varnibble encoded header and returns it together with `tail data`. Tail data is included to enable decoding of sequential ISCCs. The returned tail data must be truncated to decode_length(r[0], r[3]) bits to recover the actual hash-bytes. :param bytes data: ISCC bytes :return: (MainType, SubType, Version, length, TailData) :rtype: IsccTuple \"\"\" result = [] ba = bitarray () ba . frombytes ( data ) data = ba for _ in range ( 4 ): value , data = decode_varnibble ( data ) result . append ( value ) # TODO: validate correctness of decoded data. # Strip 4-bit padding if required if len ( data ) % 8 and data [: 4 ] == bitarray ( \"0000\" ): data = data [ 4 :] result . append ( data . tobytes ()) return tuple ( result ) decode_varnibble ( b ) # Reads first varnibble, returns its integer value and remaining bits. Parameters: Name Type Description Default b bitarray Array of header bits required Returns: Type Description Tuple[int, bitarray] A tuple of the integer value of first varnible and the remaining bits. Source code in iscc_core\\codec.py def decode_varnibble ( b ): # type: (bitarray) -> Tuple[int, bitarray] \"\"\"Reads first varnibble, returns its integer value and remaining bits. :param bitarray b: Array of header bits :return: A tuple of the integer value of first varnible and the remaining bits. :rtype: Tuple[int, bitarray] \"\"\" bits = len ( b ) if bits >= 4 and b [ 0 ] == 0 : return ba2int ( b [: 4 ]), b [ 4 :] if bits >= 8 and b [ 1 ] == 0 : return ba2int ( b [ 2 : 8 ]) + 8 , b [ 8 :] if bits >= 12 and b [ 2 ] == 0 : return ba2int ( b [ 3 : 12 ]) + 72 , b [ 12 :] if bits >= 16 and b [ 3 ] == 0 : return ba2int ( b [ 4 : 16 ]) + 584 , b [ 16 :] raise ValueError ( \"Invalid bitarray\" ) encode_units ( units ) # Encodes a combination of ISCC units to an integer between 0-7 to be used as length value for the final encoding of MT.ISCC Parameters: Name Type Description Default units Tuple A tuple of a MainType combination (can be empty) required Returns: Type Description int Integer value to be used as length-value for header encoding Source code in iscc_core\\codec.py def encode_units ( units ): # type: (Tuple[MT, ...]) -> int \"\"\" Encodes a combination of ISCC units to an integer between 0-7 to be used as length value for the final encoding of MT.ISCC :param Tuple units: A tuple of a MainType combination (can be empty) :return: Integer value to be used as length-value for header encoding :rtype: int \"\"\" return UNITS . index ( units ) decode_units ( unit_id ) # Decodes an ISCC header length value that has been encoded with a unit_id to an ordered tuple of MainTypes. Source code in iscc_core\\codec.py def decode_units ( unit_id ): # type: (int) -> Tuple[MT, ...] \"\"\" Decodes an ISCC header length value that has been encoded with a unit_id to an ordered tuple of MainTypes. \"\"\" units = sorted ( UNITS [ unit_id ]) return tuple ( MT ( u ) for u in units ) encode_length ( mtype , length ) # Encode length to integer value for header encoding. The length value has MainType-specific semantics: For MainTypes META , SEMANTIC , CONTENT , DATA , INSTANCE : Length means number of bits for the body. Length is encoded as the multiple of 32-bit chunks (0 being 32bits) Examples: 32 -> 0, 64 -> 1, 96 -> 2 ... For MainType ISCC : MainTypes `DATA` and `INSTANCE` are mandatory for ISCC-CODEs, all others are optional. Length means the composition of optional 64-bit units included in the ISCC composite. Examples: No optional units -> 0000 -> 0 CONTENT -> 0001 -> 1 SEMANTIC -> 0010 -> 2 SEMANTIC, CONTENT -> 0011 -> 3 META -> 0100 -> 4 META, CONTENT -> 0101 -> 5 ... For MainType ID : Lengths means number the number of bits for the body including the counter Length is encoded as number of bytes of the counter (64-bit body is implicit) Examples: 64 -> 0 (No counter) 72 -> 1 (One byte counter) 80 -> 2 (Two byte counter) ... Parameters: Name Type Description Default mtype MainType The MainType for which to encode the length value. required length Length The length expressed according to the semantics of the type required Returns: Type Description int The length value encoded as integer for use with write_header. Source code in iscc_core\\codec.py def encode_length ( mtype , length ): # type: (MainType, Length) -> int \"\"\" Encode length to integer value for header encoding. The `length` value has MainType-specific semantics: For MainTypes `META`, `SEMANTIC`, `CONTENT`, `DATA`, `INSTANCE`: Length means number of bits for the body. Length is encoded as the multiple of 32-bit chunks (0 being 32bits) Examples: 32 -> 0, 64 -> 1, 96 -> 2 ... For MainType `ISCC`: MainTypes `DATA` and `INSTANCE` are mandatory for ISCC-CODEs, all others are optional. Length means the composition of optional 64-bit units included in the ISCC composite. Examples: No optional units -> 0000 -> 0 CONTENT -> 0001 -> 1 SEMANTIC -> 0010 -> 2 SEMANTIC, CONTENT -> 0011 -> 3 META -> 0100 -> 4 META, CONTENT -> 0101 -> 5 ... For MainType `ID`: Lengths means number the number of bits for the body including the counter Length is encoded as number of bytes of the counter (64-bit body is implicit) Examples: 64 -> 0 (No counter) 72 -> 1 (One byte counter) 80 -> 2 (Two byte counter) ... :param MainType mtype: The MainType for which to encode the length value. :param Length length: The length expressed according to the semantics of the type :return: The length value encoded as integer for use with write_header. :rtype: int \"\"\" error = f \"Invalid length { length } for MainType { mtype } \" # standard case (length field denotes number of 32-bit chunks, 0 being 32-bits) if mtype in ( MT . META , MT . SEMANTIC , MT . CONTENT , MT . DATA , MT . INSTANCE , MT . FLAKE ): if length >= 32 and not length % 32 : return ( length // 32 ) - 1 raise ValueError ( error ) # flag type encoding of included components (pass through as encoded out-of-band) elif mtype == MT . ISCC : if 0 <= length <= 7 : return length raise ValueError ( error ) # counter byte lenght encoding elif mtype == MT . ID : if 64 <= length <= 96 : return ( length - 64 ) // 8 raise ValueError ( error ) else : raise ValueError ( error ) decode_length ( mtype , length ) # Dedoce raw length value from ISCC header to length of digest in number of bits. Decodes a raw header integer value in to its semantically meaningfull value (eg. number of bits) Source code in iscc_core\\codec.py def decode_length ( mtype , length ): # type: (MainType, Length) -> LN \"\"\" Dedoce raw length value from ISCC header to length of digest in number of bits. Decodes a raw header integer value in to its semantically meaningfull value (eg. number of bits) \"\"\" if mtype in ( MT . META , MT . SEMANTIC , MT . CONTENT , MT . DATA , MT . INSTANCE , MT . FLAKE ): return LN (( length + 1 ) * 32 ) elif mtype == MT . ISCC : return LN ( len ( decode_units ( length )) * 64 + 128 ) elif mtype == MT . ID : return LN ( length * 8 + 64 ) else : raise ValueError ( f \"Invalid length { length } for MainType { mtype } \" ) encode_base32 ( data ) # Standard RFC4648 base32 encoding without padding. Source code in iscc_core\\codec.py def encode_base32 ( data ): # type: (bytes) -> str \"\"\" Standard RFC4648 base32 encoding without padding. \"\"\" return b32encode ( data ) . decode ( \"ascii\" ) . rstrip ( \"=\" ) decode_base32 ( code ) # Standard RFC4648 base32 decoding without padding and with casefolding. Source code in iscc_core\\codec.py def decode_base32 ( code ): # type: (str) -> bytes \"\"\" Standard RFC4648 base32 decoding without padding and with casefolding. \"\"\" # python stdlib does not support base32 without padding, so we have to re-pad. cl = len ( code ) pad_length = math . ceil ( cl / 8 ) * 8 - cl return bytes ( b32decode ( code + \"=\" * pad_length , casefold = True )) encode_base64 ( data : bytes ) -> str # Standard RFC4648 base64url encoding without padding. Source code in iscc_core\\codec.py def encode_base64 ( data : bytes ) -> str : \"\"\" Standard RFC4648 base64url encoding without padding. \"\"\" code = urlsafe_b64encode ( data ) . decode ( \"ascii\" ) return code . rstrip ( \"=\" ) decode_base64 ( code : str ) -> bytes # Standard RFC4648 base64url decoding without padding. Source code in iscc_core\\codec.py def decode_base64 ( code : str ) -> bytes : \"\"\" Standard RFC4648 base64url decoding without padding. \"\"\" padding = 4 - ( len ( code ) % 4 ) string = code + ( \"=\" * padding ) return urlsafe_b64decode ( string ) encode_base32hex ( data ) # RFC4648 Base32hex encoding without padding see: https://tools.ietf.org/html/rfc4648#page-10 Source code in iscc_core\\codec.py def encode_base32hex ( data ): \"\"\" RFC4648 Base32hex encoding without padding see: https://tools.ietf.org/html/rfc4648#page-10 \"\"\" return base32hexnopad . encode ( data ) decode_base32hex ( data ) # RFC4648 Base32hex decoding without padding see: https://tools.ietf.org/html/rfc4648#page-10 Source code in iscc_core\\codec.py def decode_base32hex ( data ): \"\"\" RFC4648 Base32hex decoding without padding see: https://tools.ietf.org/html/rfc4648#page-10 \"\"\" return base32hexnopad . decode ( data ) iscc_decompose ( iscc_code ) # Decompose a normalized ISCC-CODE or any valid ISCC sequence into a list of ISCC-UNITS. A valid ISCC sequence is a string concatenation of ISCC-UNITS optionally seperated by a hyphen. Source code in iscc_core\\codec.py def iscc_decompose ( iscc_code ): # type: (str) -> List[str] \"\"\" Decompose a normalized ISCC-CODE or any valid ISCC sequence into a list of ISCC-UNITS. A valid ISCC sequence is a string concatenation of ISCC-UNITS optionally seperated by a hyphen. \"\"\" iscc_code = iscc_clean ( iscc_code ) components = [] raw_code = decode_base32 ( iscc_code ) while raw_code : mt , st , vs , ln , body = decode_header ( raw_code ) # standard ISCC-UNIT with tail continuation if mt != MT . ISCC : ln_bits = decode_length ( mt , ln ) code = encode_component ( mt , st , vs , ln_bits , body [: ln_bits // 8 ]) components . append ( code ) raw_code = body [ ln_bits // 8 :] continue # ISCC-CODE main_types = decode_units ( ln ) # rebuild dynamic units (META, SEMANTIC, CONTENT) for idx , mtype in enumerate ( main_types ): stype = ST . NONE if mtype == MT . META else st code = encode_component ( mtype , stype , vs , 64 , body [ idx * 8 :]) components . append ( code ) # rebuild static units (DATA, INSTANCE) data_code = encode_component ( MT . DATA , ST . NONE , vs , 64 , body [ - 16 : - 8 ]) instance_code = encode_component ( MT . INSTANCE , ST . NONE , vs , 64 , body [ - 8 :]) components . extend ([ data_code , instance_code ]) break return components iscc_normalize ( iscc_code ) # Normalize an ISCC to its canonical URI form. The canonical form of an ISCC is its shortest base32 encoded representation prefixed with the string ISCC: . Possible valid inputs: MEACB7X7777574L6 ISCC:MEACB7X7777574L6 fcc010001657fe7cafe9791bb iscc:maagztfqttvizpjr Iscc:Maagztfqttvizpjr Info A concatenated sequence of codes will be composed into a single ISCC of MainType MT.ISCC if possible. Example >>> import iscc_core >>> iscc_core . iscc_normalize ( \"GAAW2PRCRS5LNVZV-IAAUVACQKXE3V44W\" ) 'ISCC:KUAG2PRCRS5LNVZVJKAFAVOJXLZZM' Parameters: Name Type Description Default iscc_code str Any valid ISCC string required Returns: Type Description str Normalized ISCC Source code in iscc_core\\codec.py def iscc_normalize ( iscc_code ): # type: (str) -> str \"\"\" Normalize an ISCC to its canonical URI form. The canonical form of an ISCC is its shortest base32 encoded representation prefixed with the string `ISCC:`. Possible valid inputs: MEACB7X7777574L6 ISCC:MEACB7X7777574L6 fcc010001657fe7cafe9791bb iscc:maagztfqttvizpjr Iscc:Maagztfqttvizpjr !!! info A concatenated sequence of codes will be composed into a single ISCC of MainType `MT.ISCC` if possible. !!! example ``` py >>> import iscc_core >>> iscc_core.iscc_normalize(\"GAAW2PRCRS5LNVZV-IAAUVACQKXE3V44W\") 'ISCC:KUAG2PRCRS5LNVZVJKAFAVOJXLZZM' ``` :param str iscc_code: Any valid ISCC string :return: Normalized ISCC :rtype: str \"\"\" from iscc_core.iscc_code import gen_iscc_code_v0 decoders = { MULTIBASE . base16 : bytes . fromhex , # f MULTIBASE . base32 : decode_base32 , # b MULTIBASE . base32hex : decode_base32hex , # v MULTIBASE . base58btc : base58 . b58decode , # z MULTIBASE . base64url : decode_base64 , # u } # Transcode to base32 if <multibase><multicodec> encoded multibase_prefix = iscc_code [ 0 ] if multibase_prefix in decoders . keys (): decoder = decoders [ multibase_prefix ] decoded = decoder ( iscc_code [ 1 :]) if not decoded . startswith ( MC_PREFIX ): raise ValueError ( f \"Malformed multiformat codec: { decoded [: 2 ] } \" ) iscc_code = encode_base32 ( decoded [ 2 :]) decomposed = iscc_decompose ( iscc_code ) recomposed = gen_iscc_code_v0 ( decomposed )[ \"iscc\" ] if len ( decomposed ) >= 2 else decomposed [ 0 ] return f \"ISCC: { recomposed } \" if not recomposed . startswith ( \"ISCC:\" ) else recomposed iscc_decode ( iscc ) # Decode ISCC to an IsccTuple Parameters: Name Type Description Default iscc str ISCC string required Returns: Type Description IsccTuple ISCC decoded to an IsccTuple Source code in iscc_core\\codec.py def iscc_decode ( iscc ): # type (str) -> IsccTuple \"\"\" Decode ISCC to an IsccTuple :param str iscc: ISCC string :return: ISCC decoded to an IsccTuple :rtype: IsccTuple \"\"\" iscc = iscc_clean ( iscc_normalize ( iscc )) data = decode_base32 ( iscc ) return decode_header ( data ) iscc_explain ( iscc ) # Convert ISCC to a human-readable representation Parameters: Name Type Description Default iscc str ISCC string required Returns: Type Description str Human-readable representation of ISCC Source code in iscc_core\\codec.py def iscc_explain ( iscc ): # type (str) -> str: \"\"\" Convert ISCC to a human-readable representation :param str iscc: ISCC string :return: Human-readable representation of ISCC :rtype: str \"\"\" tid = iscc_type_id ( iscc ) fields = iscc_decode ( iscc ) if fields [ 0 ] == MT . ID : counter_bytes = fields [ - 1 ][ 8 :] if counter_bytes : counter = uvarint . decode ( counter_bytes ) hex_hash = fields [ - 1 ][: 8 ] . hex () return f \" { tid } - { hex_hash } - { counter . integer } \" hex_hash = fields [ - 1 ] . hex () return f \" { tid } - { hex_hash } \" iscc_type_id ( iscc ) # Extract and convert ISCC HEADER to a readable Type-ID string. Type-ids can be used as names in databases to index ISCC-UNITs seperatly. Parameters: Name Type Description Default iscc str ISCC string required Returns: Type Description str Unique Type-ID string Source code in iscc_core\\codec.py def iscc_type_id ( iscc ): # type (str) - str: \"\"\" Extract and convert ISCC HEADER to a readable Type-ID string. Type-ids can be used as names in databases to index ISCC-UNITs seperatly. :param str iscc: ISCC string :return: Unique Type-ID string :rtype: str \"\"\" fields = iscc_decode ( iscc ) mtype = MT ( fields [ 0 ]) stype = SUBTYPE_MAP [ fields [ 0 ]]( fields [ 1 ]) if mtype == MT . ISCC : mtypes = decode_units ( fields [ 3 ]) length = \"\" . join ([ t . name [ 0 ] for t in mtypes ]) + \"DI\" else : length = decode_length ( fields [ 0 ], fields [ 3 ]) version = VS ( fields [ 2 ]) return f \" { mtype . name } - { stype . name } - { version . name } - { length } \" iscc_validate ( iscc , strict = True ) # Validate that a given string is a strictly well-formed ISCC. A strictly well-formed ISCC is: an ISCC-CODE or ISCC-UNIT encoded with base32 upper without padding has a valid combination of header values is represented in its canonical URI form Parameters: Name Type Description Default iscc str ISCC string required strict bool Raise an exeption if validation fails (default True) True Returns: Type Description bool True if sting is valid else false. (raises ValueError in strict mode) Source code in iscc_core\\codec.py def iscc_validate ( iscc , strict = True ): # type: (str, bool) -> bool \"\"\" Validate that a given string is a *strictly well-formed* ISCC. A *strictly well-formed* ISCC is: - an ISCC-CODE or ISCC-UNIT - encoded with base32 upper without padding - has a valid combination of header values - is represented in its canonical URI form :param str iscc: ISCC string :param bool strict: Raise an exeption if validation fails (default True) :return: True if sting is valid else false. (raises ValueError in strict mode) :rtype: bool \"\"\" # Basic regex validation match = re . match ( \"^ISCC:[A-Z2-7]{10,60}$\" , iscc ) if not match : if strict : raise ValueError ( \"ISCC string does not match ^ISCC:[A-Z2-7]{10,60}$\" ) else : return False # Header valid valid_prefixes = { \"AA\" , \"CA\" , \"CE\" , \"CI\" , \"CM\" , \"CQ\" , \"EA\" , \"EE\" , \"EI\" , \"EM\" , \"EQ\" , \"GA\" , \"IA\" , \"KA\" , \"KE\" , \"KI\" , \"KM\" , \"KQ\" , \"KU\" , \"MA\" , \"ME\" , \"MI\" , \"OA\" , } cleaned = iscc_clean ( iscc ) prefix = cleaned [: 2 ] if prefix not in valid_prefixes : if strict : raise ValueError ( f \"Header starts with invalid sequence { prefix } \" ) else : return False return True iscc_clean ( iscc ) # Cleanup ISCC string. Removes leading scheme, dashes, leading/trailing whitespace. Parameters: Name Type Description Default iscc str Any valid ISCC string required Returns: Type Description str Cleaned ISCC string. Source code in iscc_core\\codec.py def iscc_clean ( iscc ): # type: (str) -> str \"\"\" Cleanup ISCC string. Removes leading scheme, dashes, leading/trailing whitespace. :param str iscc: Any valid ISCC string :return: Cleaned ISCC string. :rtype: str \"\"\" split = [ part . strip () for part in iscc . strip () . split ( \":\" )] if len ( split ) == 1 : code = split [ 0 ] # remove dashes if not multiformat if code [ 0 ] not in list ( MULTIBASE ): code = code . replace ( \"-\" , \"\" ) return code elif len ( split ) == 2 : scheme , code = split if scheme . lower () != \"iscc\" : raise ValueError ( f \"Invalid scheme: { scheme } \" ) return code . replace ( \"-\" , \"\" ) else : raise ValueError ( f \"Malformed ISCC string: { iscc } \" )","title":"Codec"},{"location":"codec/#iscc-codec","text":"This module implements encoding, decoding and transcoding functions of ISCC","title":"ISCC - Codec"},{"location":"codec/#codec-overview","text":"","title":"Codec Overview"},{"location":"codec/#codec-functions","text":"","title":"Codec Functions"},{"location":"codec/#iscc_core.codec.encode_component","text":"Encode an ISCC unit inlcuding header and body with standard base32 encoding. Note The length value must be the length in number of bits for the component. If digest has more bits than specified by length it wil be truncated. Parameters: Name Type Description Default mtype MainType Maintype of unit (0-6) required stype SubType SubType of unit depending on MainType (0-5) required version Version Version of unit algorithm (0). required bit_length length Length of unit, in number of bits (multiple of 32) required digest bytes The hash digest of the unit. required Returns: Type Description str Base32 encoded ISCC-UNIT. Source code in iscc_core\\codec.py def encode_component ( mtype , stype , version , bit_length , digest ): # type: (MainType, SubType, Version, Length, bytes) -> str \"\"\" Encode an ISCC unit inlcuding header and body with standard base32 encoding. !!! note The `length` value must be the **length in number of bits** for the component. If `digest` has more bits than specified by `length` it wil be truncated. :param MainType mtype: Maintype of unit (0-6) :param SubType stype: SubType of unit depending on MainType (0-5) :param Version version: Version of unit algorithm (0). :param length bit_length: Length of unit, in number of bits (multiple of 32) :param bytes digest: The hash digest of the unit. :return: Base32 encoded ISCC-UNIT. :rtype: str \"\"\" if mtype in ( MT . META , MT . SEMANTIC , MT . CONTENT , MT . DATA , MT . INSTANCE , MT . ID , MT . FLAKE ): encoded_length = encode_length ( mtype , bit_length ) elif mtype == MT . ISCC : raise ValueError ( f \" { mtype } is not a unit\" ) else : raise ValueError ( f \"Illegal MainType { mtype } \" ) nbytes = bit_length // 8 header = encode_header ( mtype , stype , version , encoded_length ) body = digest [: nbytes ] component_code = encode_base32 ( header + body ) return component_code","title":"encode_component()"},{"location":"codec/#iscc_core.codec.encode_header","text":"Encodes header values with nibble-sized (4-bit) variable-length encoding. The result is minimum 2 and maximum 8 bytes long. If the final count of nibbles is uneven it is padded with 4-bit 0000 at the end. Warning The length value must be encoded beforhand because its semantics depend on the MainType (see encode_length function). Parameters: Name Type Description Default mtype MainType MainType of unit. required stype SubType SubType of unit. required version Version Version of component algorithm. 0 length Length length value of unit (1 means 64-bits for standard units) 1 Returns: Type Description bytes Varnibble stream encoded ISCC header as bytes. Source code in iscc_core\\codec.py def encode_header ( mtype , stype , version = 0 , length = 1 ): # type: (MainType, SubType, Version, Length) -> bytes \"\"\" Encodes header values with nibble-sized (4-bit) variable-length encoding. The result is minimum 2 and maximum 8 bytes long. If the final count of nibbles is uneven it is padded with 4-bit `0000` at the end. !!! warning The length value must be encoded beforhand because its semantics depend on the MainType (see `encode_length` function). :param MainType mtype: MainType of unit. :param SubType stype: SubType of unit. :param Version version: Version of component algorithm. :param Length length: length value of unit (1 means 64-bits for standard units) :return: Varnibble stream encoded ISCC header as bytes. :rtype: bytes \"\"\" # TODO verify that all header params and there combination is valid header = bitarray () for n in ( mtype , stype , version , length ): header += encode_varnibble ( n ) # Append zero-padding if required (right side, least significant bits). header . fill () return header . tobytes ()","title":"encode_header()"},{"location":"codec/#iscc_core.codec.encode_varnibble","text":"Writes integer to variable length sequence of 4-bit chunks. Variable-length encoding scheme: prefix bits nibbles data bits unsigned range 0 1 3 0 - 7 10 2 6 8 - 71 110 3 9 72 - 583 1110 4 12 584 - 4679 Parameters: Name Type Description Default n int Positive integer to be encoded as varnibble (0-4679) required Returns: Type Description bitarray Varnibble encoded integera Source code in iscc_core\\codec.py def encode_varnibble ( n ): # type: (int) -> bitarray \"\"\" Writes integer to variable length sequence of 4-bit chunks. Variable-length encoding scheme: ------------------------------------------------------ | prefix bits | nibbles | data bits | unsigned range | | ----------- | ------- | --------- | -------------- | | 0 | 1 | 3 | 0 - 7 | | 10 | 2 | 6 | 8 - 71 | | 110 | 3 | 9 | 72 - 583 | | 1110 | 4 | 12 | 584 - 4679 | :param int n: Positive integer to be encoded as varnibble (0-4679) :return: Varnibble encoded integera :rtype: bitarray \"\"\" if 0 <= n < 8 : return int2ba ( n , length = 4 ) elif 8 <= n < 72 : return bitarray ( \"10\" ) + int2ba ( n - 8 , length = 6 ) elif 72 <= n < 584 : return bitarray ( \"110\" ) + int2ba ( n - 72 , length = 9 ) elif 584 <= n < 4680 : return bitarray ( \"1110\" ) + int2ba ( n - 584 , length = 12 ) else : raise ValueError ( \"Value must be between 0 and 4679\" )","title":"encode_varnibble()"},{"location":"codec/#iscc_core.codec.decode_header","text":"Decodes varnibble encoded header and returns it together with tail data . Tail data is included to enable decoding of sequential ISCCs. The returned tail data must be truncated to decode_length(r[0], r[3]) bits to recover the actual hash-bytes. Parameters: Name Type Description Default data bytes ISCC bytes required Returns: Type Description IsccTuple (MainType, SubType, Version, length, TailData) Source code in iscc_core\\codec.py def decode_header ( data ): # type: (bytes) -> IsccTuple \"\"\" Decodes varnibble encoded header and returns it together with `tail data`. Tail data is included to enable decoding of sequential ISCCs. The returned tail data must be truncated to decode_length(r[0], r[3]) bits to recover the actual hash-bytes. :param bytes data: ISCC bytes :return: (MainType, SubType, Version, length, TailData) :rtype: IsccTuple \"\"\" result = [] ba = bitarray () ba . frombytes ( data ) data = ba for _ in range ( 4 ): value , data = decode_varnibble ( data ) result . append ( value ) # TODO: validate correctness of decoded data. # Strip 4-bit padding if required if len ( data ) % 8 and data [: 4 ] == bitarray ( \"0000\" ): data = data [ 4 :] result . append ( data . tobytes ()) return tuple ( result )","title":"decode_header()"},{"location":"codec/#iscc_core.codec.decode_varnibble","text":"Reads first varnibble, returns its integer value and remaining bits. Parameters: Name Type Description Default b bitarray Array of header bits required Returns: Type Description Tuple[int, bitarray] A tuple of the integer value of first varnible and the remaining bits. Source code in iscc_core\\codec.py def decode_varnibble ( b ): # type: (bitarray) -> Tuple[int, bitarray] \"\"\"Reads first varnibble, returns its integer value and remaining bits. :param bitarray b: Array of header bits :return: A tuple of the integer value of first varnible and the remaining bits. :rtype: Tuple[int, bitarray] \"\"\" bits = len ( b ) if bits >= 4 and b [ 0 ] == 0 : return ba2int ( b [: 4 ]), b [ 4 :] if bits >= 8 and b [ 1 ] == 0 : return ba2int ( b [ 2 : 8 ]) + 8 , b [ 8 :] if bits >= 12 and b [ 2 ] == 0 : return ba2int ( b [ 3 : 12 ]) + 72 , b [ 12 :] if bits >= 16 and b [ 3 ] == 0 : return ba2int ( b [ 4 : 16 ]) + 584 , b [ 16 :] raise ValueError ( \"Invalid bitarray\" )","title":"decode_varnibble()"},{"location":"codec/#iscc_core.codec.encode_units","text":"Encodes a combination of ISCC units to an integer between 0-7 to be used as length value for the final encoding of MT.ISCC Parameters: Name Type Description Default units Tuple A tuple of a MainType combination (can be empty) required Returns: Type Description int Integer value to be used as length-value for header encoding Source code in iscc_core\\codec.py def encode_units ( units ): # type: (Tuple[MT, ...]) -> int \"\"\" Encodes a combination of ISCC units to an integer between 0-7 to be used as length value for the final encoding of MT.ISCC :param Tuple units: A tuple of a MainType combination (can be empty) :return: Integer value to be used as length-value for header encoding :rtype: int \"\"\" return UNITS . index ( units )","title":"encode_units()"},{"location":"codec/#iscc_core.codec.decode_units","text":"Decodes an ISCC header length value that has been encoded with a unit_id to an ordered tuple of MainTypes. Source code in iscc_core\\codec.py def decode_units ( unit_id ): # type: (int) -> Tuple[MT, ...] \"\"\" Decodes an ISCC header length value that has been encoded with a unit_id to an ordered tuple of MainTypes. \"\"\" units = sorted ( UNITS [ unit_id ]) return tuple ( MT ( u ) for u in units )","title":"decode_units()"},{"location":"codec/#iscc_core.codec.encode_length","text":"Encode length to integer value for header encoding. The length value has MainType-specific semantics: For MainTypes META , SEMANTIC , CONTENT , DATA , INSTANCE : Length means number of bits for the body. Length is encoded as the multiple of 32-bit chunks (0 being 32bits) Examples: 32 -> 0, 64 -> 1, 96 -> 2 ... For MainType ISCC : MainTypes `DATA` and `INSTANCE` are mandatory for ISCC-CODEs, all others are optional. Length means the composition of optional 64-bit units included in the ISCC composite. Examples: No optional units -> 0000 -> 0 CONTENT -> 0001 -> 1 SEMANTIC -> 0010 -> 2 SEMANTIC, CONTENT -> 0011 -> 3 META -> 0100 -> 4 META, CONTENT -> 0101 -> 5 ... For MainType ID : Lengths means number the number of bits for the body including the counter Length is encoded as number of bytes of the counter (64-bit body is implicit) Examples: 64 -> 0 (No counter) 72 -> 1 (One byte counter) 80 -> 2 (Two byte counter) ... Parameters: Name Type Description Default mtype MainType The MainType for which to encode the length value. required length Length The length expressed according to the semantics of the type required Returns: Type Description int The length value encoded as integer for use with write_header. Source code in iscc_core\\codec.py def encode_length ( mtype , length ): # type: (MainType, Length) -> int \"\"\" Encode length to integer value for header encoding. The `length` value has MainType-specific semantics: For MainTypes `META`, `SEMANTIC`, `CONTENT`, `DATA`, `INSTANCE`: Length means number of bits for the body. Length is encoded as the multiple of 32-bit chunks (0 being 32bits) Examples: 32 -> 0, 64 -> 1, 96 -> 2 ... For MainType `ISCC`: MainTypes `DATA` and `INSTANCE` are mandatory for ISCC-CODEs, all others are optional. Length means the composition of optional 64-bit units included in the ISCC composite. Examples: No optional units -> 0000 -> 0 CONTENT -> 0001 -> 1 SEMANTIC -> 0010 -> 2 SEMANTIC, CONTENT -> 0011 -> 3 META -> 0100 -> 4 META, CONTENT -> 0101 -> 5 ... For MainType `ID`: Lengths means number the number of bits for the body including the counter Length is encoded as number of bytes of the counter (64-bit body is implicit) Examples: 64 -> 0 (No counter) 72 -> 1 (One byte counter) 80 -> 2 (Two byte counter) ... :param MainType mtype: The MainType for which to encode the length value. :param Length length: The length expressed according to the semantics of the type :return: The length value encoded as integer for use with write_header. :rtype: int \"\"\" error = f \"Invalid length { length } for MainType { mtype } \" # standard case (length field denotes number of 32-bit chunks, 0 being 32-bits) if mtype in ( MT . META , MT . SEMANTIC , MT . CONTENT , MT . DATA , MT . INSTANCE , MT . FLAKE ): if length >= 32 and not length % 32 : return ( length // 32 ) - 1 raise ValueError ( error ) # flag type encoding of included components (pass through as encoded out-of-band) elif mtype == MT . ISCC : if 0 <= length <= 7 : return length raise ValueError ( error ) # counter byte lenght encoding elif mtype == MT . ID : if 64 <= length <= 96 : return ( length - 64 ) // 8 raise ValueError ( error ) else : raise ValueError ( error )","title":"encode_length()"},{"location":"codec/#iscc_core.codec.decode_length","text":"Dedoce raw length value from ISCC header to length of digest in number of bits. Decodes a raw header integer value in to its semantically meaningfull value (eg. number of bits) Source code in iscc_core\\codec.py def decode_length ( mtype , length ): # type: (MainType, Length) -> LN \"\"\" Dedoce raw length value from ISCC header to length of digest in number of bits. Decodes a raw header integer value in to its semantically meaningfull value (eg. number of bits) \"\"\" if mtype in ( MT . META , MT . SEMANTIC , MT . CONTENT , MT . DATA , MT . INSTANCE , MT . FLAKE ): return LN (( length + 1 ) * 32 ) elif mtype == MT . ISCC : return LN ( len ( decode_units ( length )) * 64 + 128 ) elif mtype == MT . ID : return LN ( length * 8 + 64 ) else : raise ValueError ( f \"Invalid length { length } for MainType { mtype } \" )","title":"decode_length()"},{"location":"codec/#iscc_core.codec.encode_base32","text":"Standard RFC4648 base32 encoding without padding. Source code in iscc_core\\codec.py def encode_base32 ( data ): # type: (bytes) -> str \"\"\" Standard RFC4648 base32 encoding without padding. \"\"\" return b32encode ( data ) . decode ( \"ascii\" ) . rstrip ( \"=\" )","title":"encode_base32()"},{"location":"codec/#iscc_core.codec.decode_base32","text":"Standard RFC4648 base32 decoding without padding and with casefolding. Source code in iscc_core\\codec.py def decode_base32 ( code ): # type: (str) -> bytes \"\"\" Standard RFC4648 base32 decoding without padding and with casefolding. \"\"\" # python stdlib does not support base32 without padding, so we have to re-pad. cl = len ( code ) pad_length = math . ceil ( cl / 8 ) * 8 - cl return bytes ( b32decode ( code + \"=\" * pad_length , casefold = True ))","title":"decode_base32()"},{"location":"codec/#iscc_core.codec.encode_base64","text":"Standard RFC4648 base64url encoding without padding. Source code in iscc_core\\codec.py def encode_base64 ( data : bytes ) -> str : \"\"\" Standard RFC4648 base64url encoding without padding. \"\"\" code = urlsafe_b64encode ( data ) . decode ( \"ascii\" ) return code . rstrip ( \"=\" )","title":"encode_base64()"},{"location":"codec/#iscc_core.codec.decode_base64","text":"Standard RFC4648 base64url decoding without padding. Source code in iscc_core\\codec.py def decode_base64 ( code : str ) -> bytes : \"\"\" Standard RFC4648 base64url decoding without padding. \"\"\" padding = 4 - ( len ( code ) % 4 ) string = code + ( \"=\" * padding ) return urlsafe_b64decode ( string )","title":"decode_base64()"},{"location":"codec/#iscc_core.codec.encode_base32hex","text":"RFC4648 Base32hex encoding without padding see: https://tools.ietf.org/html/rfc4648#page-10 Source code in iscc_core\\codec.py def encode_base32hex ( data ): \"\"\" RFC4648 Base32hex encoding without padding see: https://tools.ietf.org/html/rfc4648#page-10 \"\"\" return base32hexnopad . encode ( data )","title":"encode_base32hex()"},{"location":"codec/#iscc_core.codec.decode_base32hex","text":"RFC4648 Base32hex decoding without padding see: https://tools.ietf.org/html/rfc4648#page-10 Source code in iscc_core\\codec.py def decode_base32hex ( data ): \"\"\" RFC4648 Base32hex decoding without padding see: https://tools.ietf.org/html/rfc4648#page-10 \"\"\" return base32hexnopad . decode ( data )","title":"decode_base32hex()"},{"location":"codec/#iscc_core.codec.iscc_decompose","text":"Decompose a normalized ISCC-CODE or any valid ISCC sequence into a list of ISCC-UNITS. A valid ISCC sequence is a string concatenation of ISCC-UNITS optionally seperated by a hyphen. Source code in iscc_core\\codec.py def iscc_decompose ( iscc_code ): # type: (str) -> List[str] \"\"\" Decompose a normalized ISCC-CODE or any valid ISCC sequence into a list of ISCC-UNITS. A valid ISCC sequence is a string concatenation of ISCC-UNITS optionally seperated by a hyphen. \"\"\" iscc_code = iscc_clean ( iscc_code ) components = [] raw_code = decode_base32 ( iscc_code ) while raw_code : mt , st , vs , ln , body = decode_header ( raw_code ) # standard ISCC-UNIT with tail continuation if mt != MT . ISCC : ln_bits = decode_length ( mt , ln ) code = encode_component ( mt , st , vs , ln_bits , body [: ln_bits // 8 ]) components . append ( code ) raw_code = body [ ln_bits // 8 :] continue # ISCC-CODE main_types = decode_units ( ln ) # rebuild dynamic units (META, SEMANTIC, CONTENT) for idx , mtype in enumerate ( main_types ): stype = ST . NONE if mtype == MT . META else st code = encode_component ( mtype , stype , vs , 64 , body [ idx * 8 :]) components . append ( code ) # rebuild static units (DATA, INSTANCE) data_code = encode_component ( MT . DATA , ST . NONE , vs , 64 , body [ - 16 : - 8 ]) instance_code = encode_component ( MT . INSTANCE , ST . NONE , vs , 64 , body [ - 8 :]) components . extend ([ data_code , instance_code ]) break return components","title":"iscc_decompose()"},{"location":"codec/#iscc_core.codec.iscc_normalize","text":"Normalize an ISCC to its canonical URI form. The canonical form of an ISCC is its shortest base32 encoded representation prefixed with the string ISCC: . Possible valid inputs: MEACB7X7777574L6 ISCC:MEACB7X7777574L6 fcc010001657fe7cafe9791bb iscc:maagztfqttvizpjr Iscc:Maagztfqttvizpjr Info A concatenated sequence of codes will be composed into a single ISCC of MainType MT.ISCC if possible. Example >>> import iscc_core >>> iscc_core . iscc_normalize ( \"GAAW2PRCRS5LNVZV-IAAUVACQKXE3V44W\" ) 'ISCC:KUAG2PRCRS5LNVZVJKAFAVOJXLZZM' Parameters: Name Type Description Default iscc_code str Any valid ISCC string required Returns: Type Description str Normalized ISCC Source code in iscc_core\\codec.py def iscc_normalize ( iscc_code ): # type: (str) -> str \"\"\" Normalize an ISCC to its canonical URI form. The canonical form of an ISCC is its shortest base32 encoded representation prefixed with the string `ISCC:`. Possible valid inputs: MEACB7X7777574L6 ISCC:MEACB7X7777574L6 fcc010001657fe7cafe9791bb iscc:maagztfqttvizpjr Iscc:Maagztfqttvizpjr !!! info A concatenated sequence of codes will be composed into a single ISCC of MainType `MT.ISCC` if possible. !!! example ``` py >>> import iscc_core >>> iscc_core.iscc_normalize(\"GAAW2PRCRS5LNVZV-IAAUVACQKXE3V44W\") 'ISCC:KUAG2PRCRS5LNVZVJKAFAVOJXLZZM' ``` :param str iscc_code: Any valid ISCC string :return: Normalized ISCC :rtype: str \"\"\" from iscc_core.iscc_code import gen_iscc_code_v0 decoders = { MULTIBASE . base16 : bytes . fromhex , # f MULTIBASE . base32 : decode_base32 , # b MULTIBASE . base32hex : decode_base32hex , # v MULTIBASE . base58btc : base58 . b58decode , # z MULTIBASE . base64url : decode_base64 , # u } # Transcode to base32 if <multibase><multicodec> encoded multibase_prefix = iscc_code [ 0 ] if multibase_prefix in decoders . keys (): decoder = decoders [ multibase_prefix ] decoded = decoder ( iscc_code [ 1 :]) if not decoded . startswith ( MC_PREFIX ): raise ValueError ( f \"Malformed multiformat codec: { decoded [: 2 ] } \" ) iscc_code = encode_base32 ( decoded [ 2 :]) decomposed = iscc_decompose ( iscc_code ) recomposed = gen_iscc_code_v0 ( decomposed )[ \"iscc\" ] if len ( decomposed ) >= 2 else decomposed [ 0 ] return f \"ISCC: { recomposed } \" if not recomposed . startswith ( \"ISCC:\" ) else recomposed","title":"iscc_normalize()"},{"location":"codec/#iscc_core.codec.iscc_decode","text":"Decode ISCC to an IsccTuple Parameters: Name Type Description Default iscc str ISCC string required Returns: Type Description IsccTuple ISCC decoded to an IsccTuple Source code in iscc_core\\codec.py def iscc_decode ( iscc ): # type (str) -> IsccTuple \"\"\" Decode ISCC to an IsccTuple :param str iscc: ISCC string :return: ISCC decoded to an IsccTuple :rtype: IsccTuple \"\"\" iscc = iscc_clean ( iscc_normalize ( iscc )) data = decode_base32 ( iscc ) return decode_header ( data )","title":"iscc_decode()"},{"location":"codec/#iscc_core.codec.iscc_explain","text":"Convert ISCC to a human-readable representation Parameters: Name Type Description Default iscc str ISCC string required Returns: Type Description str Human-readable representation of ISCC Source code in iscc_core\\codec.py def iscc_explain ( iscc ): # type (str) -> str: \"\"\" Convert ISCC to a human-readable representation :param str iscc: ISCC string :return: Human-readable representation of ISCC :rtype: str \"\"\" tid = iscc_type_id ( iscc ) fields = iscc_decode ( iscc ) if fields [ 0 ] == MT . ID : counter_bytes = fields [ - 1 ][ 8 :] if counter_bytes : counter = uvarint . decode ( counter_bytes ) hex_hash = fields [ - 1 ][: 8 ] . hex () return f \" { tid } - { hex_hash } - { counter . integer } \" hex_hash = fields [ - 1 ] . hex () return f \" { tid } - { hex_hash } \"","title":"iscc_explain()"},{"location":"codec/#iscc_core.codec.iscc_type_id","text":"Extract and convert ISCC HEADER to a readable Type-ID string. Type-ids can be used as names in databases to index ISCC-UNITs seperatly. Parameters: Name Type Description Default iscc str ISCC string required Returns: Type Description str Unique Type-ID string Source code in iscc_core\\codec.py def iscc_type_id ( iscc ): # type (str) - str: \"\"\" Extract and convert ISCC HEADER to a readable Type-ID string. Type-ids can be used as names in databases to index ISCC-UNITs seperatly. :param str iscc: ISCC string :return: Unique Type-ID string :rtype: str \"\"\" fields = iscc_decode ( iscc ) mtype = MT ( fields [ 0 ]) stype = SUBTYPE_MAP [ fields [ 0 ]]( fields [ 1 ]) if mtype == MT . ISCC : mtypes = decode_units ( fields [ 3 ]) length = \"\" . join ([ t . name [ 0 ] for t in mtypes ]) + \"DI\" else : length = decode_length ( fields [ 0 ], fields [ 3 ]) version = VS ( fields [ 2 ]) return f \" { mtype . name } - { stype . name } - { version . name } - { length } \"","title":"iscc_type_id()"},{"location":"codec/#iscc_core.codec.iscc_validate","text":"Validate that a given string is a strictly well-formed ISCC. A strictly well-formed ISCC is: an ISCC-CODE or ISCC-UNIT encoded with base32 upper without padding has a valid combination of header values is represented in its canonical URI form Parameters: Name Type Description Default iscc str ISCC string required strict bool Raise an exeption if validation fails (default True) True Returns: Type Description bool True if sting is valid else false. (raises ValueError in strict mode) Source code in iscc_core\\codec.py def iscc_validate ( iscc , strict = True ): # type: (str, bool) -> bool \"\"\" Validate that a given string is a *strictly well-formed* ISCC. A *strictly well-formed* ISCC is: - an ISCC-CODE or ISCC-UNIT - encoded with base32 upper without padding - has a valid combination of header values - is represented in its canonical URI form :param str iscc: ISCC string :param bool strict: Raise an exeption if validation fails (default True) :return: True if sting is valid else false. (raises ValueError in strict mode) :rtype: bool \"\"\" # Basic regex validation match = re . match ( \"^ISCC:[A-Z2-7]{10,60}$\" , iscc ) if not match : if strict : raise ValueError ( \"ISCC string does not match ^ISCC:[A-Z2-7]{10,60}$\" ) else : return False # Header valid valid_prefixes = { \"AA\" , \"CA\" , \"CE\" , \"CI\" , \"CM\" , \"CQ\" , \"EA\" , \"EE\" , \"EI\" , \"EM\" , \"EQ\" , \"GA\" , \"IA\" , \"KA\" , \"KE\" , \"KI\" , \"KM\" , \"KQ\" , \"KU\" , \"MA\" , \"ME\" , \"MI\" , \"OA\" , } cleaned = iscc_clean ( iscc ) prefix = cleaned [: 2 ] if prefix not in valid_prefixes : if strict : raise ValueError ( f \"Header starts with invalid sequence { prefix } \" ) else : return False return True","title":"iscc_validate()"},{"location":"codec/#iscc_core.codec.iscc_clean","text":"Cleanup ISCC string. Removes leading scheme, dashes, leading/trailing whitespace. Parameters: Name Type Description Default iscc str Any valid ISCC string required Returns: Type Description str Cleaned ISCC string. Source code in iscc_core\\codec.py def iscc_clean ( iscc ): # type: (str) -> str \"\"\" Cleanup ISCC string. Removes leading scheme, dashes, leading/trailing whitespace. :param str iscc: Any valid ISCC string :return: Cleaned ISCC string. :rtype: str \"\"\" split = [ part . strip () for part in iscc . strip () . split ( \":\" )] if len ( split ) == 1 : code = split [ 0 ] # remove dashes if not multiformat if code [ 0 ] not in list ( MULTIBASE ): code = code . replace ( \"-\" , \"\" ) return code elif len ( split ) == 2 : scheme , code = split if scheme . lower () != \"iscc\" : raise ValueError ( f \"Invalid scheme: { scheme } \" ) return code . replace ( \"-\" , \"\" ) else : raise ValueError ( f \"Malformed ISCC string: { iscc } \" )","title":"iscc_clean()"},{"location":"context/0.2.0/","text":"ISCC - Metadata Vocabulary (v0.2.0) # @context # JSON-LD Context URI type # JSON Schema URI iscc # ISCC in canonical encoding. name # The name or title of the intangible creation manifested by the identified digital asset description # Description of the digital asset identified by the ISCC (used as input for Meta-Code generation). Any user presentable text string (including Markdown text) indicative of the identity of the referent may be used. image # URI for a user presentable image that serves as a preview of identified digital content or, in case of an NFT, the digital content itself. keywords # List of keywords relevant to the identified digital content. identifier # Other identifier(s) such as those defined by ISO/TC 46/SC 9 referencing the work, product or other abstraction of which the referenced digital asset is a full or partial manifestation. filename # Filename of the referenced digital asset (automatically used as fallback if no seed_title element is specified) filesize # File size of media asset in bytes. mediatype # IANA Media Type (MIME type) tophash # Multihash hash over concatenation of metahash and datahash metahash # Multihash hash of metadata. datahash # Multihash hash of media file. duration # Duration of audio-visual media in secondes. fps # Frames per second of video assets. width # Width of visual media in pixels. height # Height of visual media in pixels. characters # Number of text characters (code points after Unicode normalization) language # Language(s) of content (BCP-47) in weighted order. parts # Included Content-Codes. license # URI of license for the identified digital content. redirect # URL to which a resolver should redirect an ISCC-ID that has been minted from a declartion that includes the IPFS-hash of this metadata instance.","title":"ISCC - Metadata Vocabulary (v0.2.0)"},{"location":"context/0.2.0/#iscc-metadata-vocabulary-v020","text":"","title":"ISCC - Metadata Vocabulary (v0.2.0)"},{"location":"context/0.2.0/#context","text":"JSON-LD Context URI","title":"@context"},{"location":"context/0.2.0/#type","text":"JSON Schema URI","title":"type"},{"location":"context/0.2.0/#iscc","text":"ISCC in canonical encoding.","title":"iscc"},{"location":"context/0.2.0/#name","text":"The name or title of the intangible creation manifested by the identified digital asset","title":"name"},{"location":"context/0.2.0/#description","text":"Description of the digital asset identified by the ISCC (used as input for Meta-Code generation). Any user presentable text string (including Markdown text) indicative of the identity of the referent may be used.","title":"description"},{"location":"context/0.2.0/#image","text":"URI for a user presentable image that serves as a preview of identified digital content or, in case of an NFT, the digital content itself.","title":"image"},{"location":"context/0.2.0/#keywords","text":"List of keywords relevant to the identified digital content.","title":"keywords"},{"location":"context/0.2.0/#identifier","text":"Other identifier(s) such as those defined by ISO/TC 46/SC 9 referencing the work, product or other abstraction of which the referenced digital asset is a full or partial manifestation.","title":"identifier"},{"location":"context/0.2.0/#filename","text":"Filename of the referenced digital asset (automatically used as fallback if no seed_title element is specified)","title":"filename"},{"location":"context/0.2.0/#filesize","text":"File size of media asset in bytes.","title":"filesize"},{"location":"context/0.2.0/#mediatype","text":"IANA Media Type (MIME type)","title":"mediatype"},{"location":"context/0.2.0/#tophash","text":"Multihash hash over concatenation of metahash and datahash","title":"tophash"},{"location":"context/0.2.0/#metahash","text":"Multihash hash of metadata.","title":"metahash"},{"location":"context/0.2.0/#datahash","text":"Multihash hash of media file.","title":"datahash"},{"location":"context/0.2.0/#duration","text":"Duration of audio-visual media in secondes.","title":"duration"},{"location":"context/0.2.0/#fps","text":"Frames per second of video assets.","title":"fps"},{"location":"context/0.2.0/#width","text":"Width of visual media in pixels.","title":"width"},{"location":"context/0.2.0/#height","text":"Height of visual media in pixels.","title":"height"},{"location":"context/0.2.0/#characters","text":"Number of text characters (code points after Unicode normalization)","title":"characters"},{"location":"context/0.2.0/#language","text":"Language(s) of content (BCP-47) in weighted order.","title":"language"},{"location":"context/0.2.0/#parts","text":"Included Content-Codes.","title":"parts"},{"location":"context/0.2.0/#license","text":"URI of license for the identified digital content.","title":"license"},{"location":"context/0.2.0/#redirect","text":"URL to which a resolver should redirect an ISCC-ID that has been minted from a declartion that includes the IPFS-hash of this metadata instance.","title":"redirect"},{"location":"includes/abbr/","text":"","title":"Abbr"},{"location":"options/options/","text":"CoreOptions pydantic-model # Parameters with defaults for ISCC calculations. meta_bits : int pydantic-field # Default length of generated Meta-Code in bits meta_trim_name : int pydantic-field # Trim name to this mumber of bytes meta_trim_description : int pydantic-field # Trim description to this number of bytes meta_ngram_size_text : int pydantic-field # Sliding window width (characters) for metadata meta_ngram_size_bytes : int pydantic-field # Sliding window width (bytes) for metadata text_bits : int pydantic-field # Default length of generated Content-Code Text in bits text_ngram_size : int pydantic-field # Number of characters per feature hash (size of sliding window) text_unicode_filter : frozenset pydantic-field # Unicode categories to remove during text normalization text_newlines : frozenset pydantic-field # Characters regarded as newline characters for normalization purposes image_bits : int pydantic-field # Default length of generated Content-Code Image in bits audio_bits : int pydantic-field # Default length of generated Content-Code Audio in bits video_bits : int pydantic-field # Default length of generated Content-Code Video in bits data_bits : int pydantic-field # Default length of generated Data-Code in bits flake_bits : int pydantic-field # Default length of generated Flake-Code in bits data_avg_chunk_size : int pydantic-field # Target chunk size for data chunking in number of bytes. instance_bits : int pydantic-field # Default length of generated Instance-Code in bits mixed_bits : int pydantic-field # Default length of generated Mixed-Code in bits io_read_size : int pydantic-field # File read buffer size in bytes for hashing operations cdc_gear : Tuple pydantic-field # Random gear vector conformance_check_options ( opts ) # Check and log if options have non-default conformance critical values","title":"Options"},{"location":"options/options/#iscc_core.options.CoreOptions","text":"Parameters with defaults for ISCC calculations.","title":"CoreOptions"},{"location":"options/options/#iscc_core.options.CoreOptions.meta_bits","text":"Default length of generated Meta-Code in bits","title":"meta_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.meta_trim_name","text":"Trim name to this mumber of bytes","title":"meta_trim_name"},{"location":"options/options/#iscc_core.options.CoreOptions.meta_trim_description","text":"Trim description to this number of bytes","title":"meta_trim_description"},{"location":"options/options/#iscc_core.options.CoreOptions.meta_ngram_size_text","text":"Sliding window width (characters) for metadata","title":"meta_ngram_size_text"},{"location":"options/options/#iscc_core.options.CoreOptions.meta_ngram_size_bytes","text":"Sliding window width (bytes) for metadata","title":"meta_ngram_size_bytes"},{"location":"options/options/#iscc_core.options.CoreOptions.text_bits","text":"Default length of generated Content-Code Text in bits","title":"text_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.text_ngram_size","text":"Number of characters per feature hash (size of sliding window)","title":"text_ngram_size"},{"location":"options/options/#iscc_core.options.CoreOptions.text_unicode_filter","text":"Unicode categories to remove during text normalization","title":"text_unicode_filter"},{"location":"options/options/#iscc_core.options.CoreOptions.text_newlines","text":"Characters regarded as newline characters for normalization purposes","title":"text_newlines"},{"location":"options/options/#iscc_core.options.CoreOptions.image_bits","text":"Default length of generated Content-Code Image in bits","title":"image_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.audio_bits","text":"Default length of generated Content-Code Audio in bits","title":"audio_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.video_bits","text":"Default length of generated Content-Code Video in bits","title":"video_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.data_bits","text":"Default length of generated Data-Code in bits","title":"data_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.flake_bits","text":"Default length of generated Flake-Code in bits","title":"flake_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.data_avg_chunk_size","text":"Target chunk size for data chunking in number of bytes.","title":"data_avg_chunk_size"},{"location":"options/options/#iscc_core.options.CoreOptions.instance_bits","text":"Default length of generated Instance-Code in bits","title":"instance_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.mixed_bits","text":"Default length of generated Mixed-Code in bits","title":"mixed_bits"},{"location":"options/options/#iscc_core.options.CoreOptions.io_read_size","text":"File read buffer size in bytes for hashing operations","title":"io_read_size"},{"location":"options/options/#iscc_core.options.CoreOptions.cdc_gear","text":"Random gear vector","title":"cdc_gear"},{"location":"options/options/#iscc_core.options.conformance_check_options","text":"Check and log if options have non-default conformance critical values","title":"conformance_check_options()"},{"location":"units/","text":"ISCC - UNITs # A standard ISCC-CODE is build from multiple ISCC-UNITs. Each unit serve a different purpose.","title":"ISCC - UNITs"},{"location":"units/#iscc-units","text":"A standard ISCC-CODE is build from multiple ISCC-UNITs. Each unit serve a different purpose.","title":"ISCC - UNITs"},{"location":"units/code_data/","text":"ISCC - Data-Code # A similarity perserving hash for binary data (soft hash). gen_data_code ( stream , bits = 64 ) # Create a similarity preserving ISCC Data-Code with the latest standard algorithm. Parameters: Name Type Description Default stream Stream Input data stream. required bits int Bit-length of ISCC Data-Code (default 64). 64 Returns: Type Description dict ISCC Data-Code gen_data_code_v0 ( stream , bits = 64 ) # Create an ISCC Data-Code with algorithm v0. Parameters: Name Type Description Default stream Stream Input data stream. required bits int Bit-length of ISCC Data-Code (default 64). 64 Returns: Type Description dict ISCC object with Data-Code soft_hash_data_v0 ( stream ) # Create a similarity preserving Data-Hash digest Parameters: Name Type Description Default stream Stream Input data stream. required Returns: Type Description bytes 256-bit Data-Hash (soft-hash) digest used as body for Data-Code DataHasher # Incremental Data-Hash generator. __init__ ( self , data = None ) special # Create a DataHasher Parameters: Name Type Description Default data Optional[Data] initial payload for hashing. None push ( self , data ) # Push data to the Data-Hash generator. digest ( self ) # Calculate 256-bit minhash digest from feature hashes. code ( self , bits = 64 ) # Encode digest as an ISCC Data-Code unit. Parameters: Name Type Description Default bits int Number of bits for the ISCC Data-Code 64 Returns: Type Description str ISCC Data-Code DataHasherV0 # Incremental Data-Hash generator. __init__ ( self , data = None ) special # Create a DataHasher Parameters: Name Type Description Default data Optional[Data] initial payload for hashing. None push ( self , data ) # Push data to the Data-Hash generator. digest ( self ) # Calculate 256-bit minhash digest from feature hashes. code ( self , bits = 64 ) # Encode digest as an ISCC Data-Code unit. Parameters: Name Type Description Default bits int Number of bits for the ISCC Data-Code 64 Returns: Type Description str ISCC Data-Code","title":"Data-Code"},{"location":"units/code_data/#iscc-data-code","text":"A similarity perserving hash for binary data (soft hash).","title":"ISCC - Data-Code"},{"location":"units/code_data/#iscc_core.code_data.gen_data_code","text":"Create a similarity preserving ISCC Data-Code with the latest standard algorithm. Parameters: Name Type Description Default stream Stream Input data stream. required bits int Bit-length of ISCC Data-Code (default 64). 64 Returns: Type Description dict ISCC Data-Code","title":"gen_data_code()"},{"location":"units/code_data/#iscc_core.code_data.gen_data_code_v0","text":"Create an ISCC Data-Code with algorithm v0. Parameters: Name Type Description Default stream Stream Input data stream. required bits int Bit-length of ISCC Data-Code (default 64). 64 Returns: Type Description dict ISCC object with Data-Code","title":"gen_data_code_v0()"},{"location":"units/code_data/#iscc_core.code_data.soft_hash_data_v0","text":"Create a similarity preserving Data-Hash digest Parameters: Name Type Description Default stream Stream Input data stream. required Returns: Type Description bytes 256-bit Data-Hash (soft-hash) digest used as body for Data-Code","title":"soft_hash_data_v0()"},{"location":"units/code_data/#iscc_core.code_data.DataHasher","text":"Incremental Data-Hash generator.","title":"DataHasher"},{"location":"units/code_data/#iscc_core.code_data.DataHasher.__init__","text":"Create a DataHasher Parameters: Name Type Description Default data Optional[Data] initial payload for hashing. None","title":"__init__()"},{"location":"units/code_data/#iscc_core.code_data.DataHasher.push","text":"Push data to the Data-Hash generator.","title":"push()"},{"location":"units/code_data/#iscc_core.code_data.DataHasher.digest","text":"Calculate 256-bit minhash digest from feature hashes.","title":"digest()"},{"location":"units/code_data/#iscc_core.code_data.DataHasher.code","text":"Encode digest as an ISCC Data-Code unit. Parameters: Name Type Description Default bits int Number of bits for the ISCC Data-Code 64 Returns: Type Description str ISCC Data-Code","title":"code()"},{"location":"units/code_data/#iscc_core.code_data.DataHasherV0","text":"Incremental Data-Hash generator.","title":"DataHasherV0"},{"location":"units/code_data/#iscc_core.code_data.DataHasherV0.__init__","text":"Create a DataHasher Parameters: Name Type Description Default data Optional[Data] initial payload for hashing. None","title":"__init__()"},{"location":"units/code_data/#iscc_core.code_data.DataHasherV0.push","text":"Push data to the Data-Hash generator.","title":"push()"},{"location":"units/code_data/#iscc_core.code_data.DataHasherV0.digest","text":"Calculate 256-bit minhash digest from feature hashes.","title":"digest()"},{"location":"units/code_data/#iscc_core.code_data.DataHasherV0.code","text":"Encode digest as an ISCC Data-Code unit. Parameters: Name Type Description Default bits int Number of bits for the ISCC Data-Code 64 Returns: Type Description str ISCC Data-Code","title":"code()"},{"location":"units/code_flake/","text":"ISCC - Flake-Code # A unique, time-sorted identifier composed of an 48-bit timestamp and 16 to 208 bit randomness. The ISCC Flake-Code is a unique identifier for distributed ID generation. The 64-bit version can be used as efficient surrogate key in database systems. It has guaranteed uniqueness if generated from a singele process and is time sortable in integer and base32hex representation. The 128-bit version is a K-sortable, globally unique identifier for use in distributed systems and is compatible with UUID. Example >>> import iscc_core as ic >>> ic . gen_flake_code ( bits = 64 ) { 'iscc' : 'ISCC:OAAQC7YN7PG2XOR4' } >>> ic . gen_flake_code ( bits = 128 ) { 'iscc' : 'ISCC:OABQC7YN7RJGUUTLKDSKBXO25MA5E' } # Or use the convenience Flake class for easy access to different representations >>> flake = ic . Flake ( bits = 64 ) >>> flake . iscc 'ISCC:OAAQC7YOADBZYNF7' >>> flake . time '2022-02-18T18:03:25.468' >>> flake . int 107820312524764351 >>> flake . string '05VGS063JGQBU' gen_flake_code ( bits = 64 ) # Create an ISCC Flake-Code with the latest standard algorithm Parameters: Name Type Description Default bits int Target bit-length of generated Flake-Code 64 Returns: Type Description dict ISCC object with Flake-Code gen_flake_code_v0 ( bits = 64 ) # Create an ISCC Flake-Code with the latest algorithm v0 Parameters: Name Type Description Default bits int Target bit-length of generated Flake-Code 64 Returns: Type Description dict ISCC object with Flake-Code uid_flake_v0 ( ts = None , bits = 64 ) # Generate time and randomness based Flake-Hash Parameters: Name Type Description Default ts Optional[float] Unix timestamp (defaults to current time) None bits int Bit-length resulting Flake-Code (multiple of 32) 64 Returns: Type Description bytes Flake-Hash digest","title":"Flake-Code"},{"location":"units/code_flake/#iscc-flake-code","text":"A unique, time-sorted identifier composed of an 48-bit timestamp and 16 to 208 bit randomness. The ISCC Flake-Code is a unique identifier for distributed ID generation. The 64-bit version can be used as efficient surrogate key in database systems. It has guaranteed uniqueness if generated from a singele process and is time sortable in integer and base32hex representation. The 128-bit version is a K-sortable, globally unique identifier for use in distributed systems and is compatible with UUID. Example >>> import iscc_core as ic >>> ic . gen_flake_code ( bits = 64 ) { 'iscc' : 'ISCC:OAAQC7YN7PG2XOR4' } >>> ic . gen_flake_code ( bits = 128 ) { 'iscc' : 'ISCC:OABQC7YN7RJGUUTLKDSKBXO25MA5E' } # Or use the convenience Flake class for easy access to different representations >>> flake = ic . Flake ( bits = 64 ) >>> flake . iscc 'ISCC:OAAQC7YOADBZYNF7' >>> flake . time '2022-02-18T18:03:25.468' >>> flake . int 107820312524764351 >>> flake . string '05VGS063JGQBU'","title":"ISCC - Flake-Code"},{"location":"units/code_flake/#iscc_core.code_flake.gen_flake_code","text":"Create an ISCC Flake-Code with the latest standard algorithm Parameters: Name Type Description Default bits int Target bit-length of generated Flake-Code 64 Returns: Type Description dict ISCC object with Flake-Code","title":"gen_flake_code()"},{"location":"units/code_flake/#iscc_core.code_flake.gen_flake_code_v0","text":"Create an ISCC Flake-Code with the latest algorithm v0 Parameters: Name Type Description Default bits int Target bit-length of generated Flake-Code 64 Returns: Type Description dict ISCC object with Flake-Code","title":"gen_flake_code_v0()"},{"location":"units/code_flake/#iscc_core.code_flake.uid_flake_v0","text":"Generate time and randomness based Flake-Hash Parameters: Name Type Description Default ts Optional[float] Unix timestamp (defaults to current time) None bits int Bit-length resulting Flake-Code (multiple of 32) 64 Returns: Type Description bytes Flake-Hash digest","title":"uid_flake_v0()"},{"location":"units/code_instance/","text":"ISCC - Instance-Code # A data checksum. gen_instance_code ( stream , bits = 64 ) # Create an ISCC Instance-Code with the latest standard algorithm. Parameters: Name Type Description Default stream Stream Binary data stream for Instance-Code generation required bits int Bit-length resulting Instance-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with properties: iscc, datahash, filesize gen_instance_code_v0 ( stream , bits = 64 ) # Create an ISCC Instance-Code with algorithm v0. Parameters: Name Type Description Default stream Stream Binary data stream for Instance-Code generation required bits int Bit-length of resulting Instance-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with Instance-Code and properties: datahash, filesize hash_instance_v0 ( stream ) # Create 256-bit hash digest for the Instance-Code body Parameters: Name Type Description Default stream Stream Binary data stream for hash generation. required Returns: Type Description bytes 256-bit Instance-Hash digest used as body of Instance-Code InstanceHasher # Incremental Instance-Hash generator. push ( self , data ) # Push data to the Instance-Hash generator. Parameters: Name Type Description Default data Data Data to be hashed required digest ( self ) # Return Instance-Hash Returns: Type Description bytes Instance-Hash digest multihash ( self ) # Return blake3 multihash Returns: Type Description str Blake3 hash as 256-bit multihash code ( self , bits = 64 ) # Encode digest as an ISCC Instance-Code unit. Parameters: Name Type Description Default bits int Number of bits for the ISCC Instance-Code 64 Returns: Type Description str ISCC Instance-Code InstanceHasherV0 # Incremental Instance-Hash generator. push ( self , data ) # Push data to the Instance-Hash generator. Parameters: Name Type Description Default data Data Data to be hashed required digest ( self ) # Return Instance-Hash Returns: Type Description bytes Instance-Hash digest multihash ( self ) # Return blake3 multihash Returns: Type Description str Blake3 hash as 256-bit multihash code ( self , bits = 64 ) # Encode digest as an ISCC Instance-Code unit. Parameters: Name Type Description Default bits int Number of bits for the ISCC Instance-Code 64 Returns: Type Description str ISCC Instance-Code","title":"Instance-Code"},{"location":"units/code_instance/#iscc-instance-code","text":"A data checksum.","title":"ISCC - Instance-Code"},{"location":"units/code_instance/#iscc_core.code_instance.gen_instance_code","text":"Create an ISCC Instance-Code with the latest standard algorithm. Parameters: Name Type Description Default stream Stream Binary data stream for Instance-Code generation required bits int Bit-length resulting Instance-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with properties: iscc, datahash, filesize","title":"gen_instance_code()"},{"location":"units/code_instance/#iscc_core.code_instance.gen_instance_code_v0","text":"Create an ISCC Instance-Code with algorithm v0. Parameters: Name Type Description Default stream Stream Binary data stream for Instance-Code generation required bits int Bit-length of resulting Instance-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with Instance-Code and properties: datahash, filesize","title":"gen_instance_code_v0()"},{"location":"units/code_instance/#iscc_core.code_instance.hash_instance_v0","text":"Create 256-bit hash digest for the Instance-Code body Parameters: Name Type Description Default stream Stream Binary data stream for hash generation. required Returns: Type Description bytes 256-bit Instance-Hash digest used as body of Instance-Code","title":"hash_instance_v0()"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasher","text":"Incremental Instance-Hash generator.","title":"InstanceHasher"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasher.push","text":"Push data to the Instance-Hash generator. Parameters: Name Type Description Default data Data Data to be hashed required","title":"push()"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasher.digest","text":"Return Instance-Hash Returns: Type Description bytes Instance-Hash digest","title":"digest()"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasher.multihash","text":"Return blake3 multihash Returns: Type Description str Blake3 hash as 256-bit multihash","title":"multihash()"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasher.code","text":"Encode digest as an ISCC Instance-Code unit. Parameters: Name Type Description Default bits int Number of bits for the ISCC Instance-Code 64 Returns: Type Description str ISCC Instance-Code","title":"code()"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasherV0","text":"Incremental Instance-Hash generator.","title":"InstanceHasherV0"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasherV0.push","text":"Push data to the Instance-Hash generator. Parameters: Name Type Description Default data Data Data to be hashed required","title":"push()"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasherV0.digest","text":"Return Instance-Hash Returns: Type Description bytes Instance-Hash digest","title":"digest()"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasherV0.multihash","text":"Return blake3 multihash Returns: Type Description str Blake3 hash as 256-bit multihash","title":"multihash()"},{"location":"units/code_instance/#iscc_core.code_instance.InstanceHasherV0.code","text":"Encode digest as an ISCC Instance-Code unit. Parameters: Name Type Description Default bits int Number of bits for the ISCC Instance-Code 64 Returns: Type Description str ISCC Instance-Code","title":"code()"},{"location":"units/code_meta/","text":"ISCC - Meta-Code # A similarity preserving hash for digital asset metadata . Purpose # The Meta-Code is the first possible (optional) unit of an ISCC-CODE. It is calculated from the metadata of a digital asset. The primary purpose of the Meta-Code is to aid the discovery of digital assets with similar metadata and the detection of metadata anomalies. As a secondary function, Meta-Code processing also creates a secure Meta-Hash for cryptogrpahic binding purposes. Inputs # The metadata supplied for Meta-Code calculation is called Seed-Metadata . Seed-Metadata has 3 possible elements: name (required): The name or title of the work manifested by the digital asset. description (optional): A disambiguating textual description of the digital asset. meta (optional): Industry-sector or use-case specific metadata, encoded as Data-URL ( RFC-2397 ). Note Due to the broad applicability of the ISCC we do not prescribe a particular schema for the supplied metadata . But we use the Data-URL format because it can encode and self-describe any conceivable metadata in a sufficently machine-interpretable form at any desired specificity. Data-URL Examples : Metadata is \"some\" JSON: data:application/json;base64,<data> Metadata is JSON-LD: data:application/ld+json;base64,<data> Metadata is \"some\" XML: data:application/xml;base64,<data> Metadata is MARC21 XML: data:application/marcxml+xml;base64,<data> Metadata is IPTC NewsML: data:application/vnd.iptc.g2.newsitem+xml;base64,<data> Data-URLs are also supported by all major internet browsers. Processing # Meta-Code # The first 32-bits of a Meta-Code are calculated as a simliarity hash from the name field. The second 32-bits are also calculated from the name field if no other input was supplied. If description is suplied but no metadata , the description will be used for the second 32-bits. If metadata is supplied it will be used in favour of description for the second 32-bits. flowchart LR B{name?} B -->|Yes| J[\"P1 = SH(name)\"] J --> D{meta?} D -->|Yes| F[\"Meta-Code = P1 + SH(meta)\"] D -->|No| G{description?} G -->|Yes| H[\"Meta-Code = P1 + SH(description)\"] G -->|No| I[\"Meta-Code = P1\"] B -->|No| E[Skip Meta-Code] Note To support automation and reproducibility, applications that generate ISCCs, should prioritize metadata that is automatically extracted from the digital asset. If embedded metadata is not available or known to be unreliable an application should rely on external metadata or explicitly ask users to supply at least the name -field. Applications should then first embed metadata into the asset before calculating the ISCC-CODE . This ensures that the embedded metadata is bound to the asset by the Instance-Code. If neither embedded nor external metadata is available, the application may resort to use the filename of the digital asset as value for the name -field. If no value can be determined for the name -field, an application shall skip generation of a Meta-Code and create an ISCC-CODE without a Meta-Code. Meta-Hash # In addition to the Meta-Code we also create a cryptographic hash (the Meta-Hash) of the supplied Seed-Metadata. It is used to securely bind metadata to the digital asset. flowchart LR N{name?} N -->|Yes| A{meta?} N -->|No| E[Skip Meta-Hash] A -->|Yes| H[\"Meta-Hash = H(meta)\"] A -->|No| B{description?} B -->|Yes| HND[\"Meta-Hash = H(name + description)\"] B -->|No| HN[\"Meta-Hash = H(name)\"] Functions # gen_meta_code_v0 ( name , description = None , meta = None , bits = 64 ) # Create an ISCC Meta-Code with the algorithm version 0. Note The input for the metadata field can be: Structured (JSON/JCS serializable) metadata Raw bytes from a file header Parameters: Name Type Description Default name str Name or title of the work manifested by the digital asset required description Optional[str] Optional description for disambiguation None meta Optional[Union[dict,str] Dict or Data-URL string with extended metadata None bits int Bit-length of resulting Meta-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with possible fields: iscc, name, description, metadata, metahash Source code in iscc_core\\code_meta.py def gen_meta_code_v0 ( name , description = None , meta = None , bits = ic . core_opts . meta_bits ): # type: (str, Optional[str], Optional[ic.Meta], int) -> dict \"\"\" Create an ISCC Meta-Code with the algorithm version 0. !!! note The input for the `metadata` field can be: - Structured (JSON/JCS serializable) metadata - Raw bytes from a file header :param str name: Name or title of the work manifested by the digital asset :param Optional[str] description: Optional description for disambiguation :param Optional[Union[dict,str] meta: Dict or Data-URL string with extended metadata :param int bits: Bit-length of resulting Meta-Code (multiple of 64) :return: ISCC object with possible fields: iscc, name, description, metadata, metahash :rtype: dict \"\"\" # 1. Normalize `name` name = \"\" if name is None else name name = text_clean ( name ) name = text_remove_newlines ( name ) name = text_trim ( name , ic . core_opts . meta_trim_name ) if not name : raise ValueError ( \"Meta-Code requires non-empty name element (after normalization)\" ) # 2. Normalize `description` description = \"\" if description is None else description description = text_clean ( description ) description = text_trim ( description , ic . core_opts . meta_trim_description ) # Calculate meta_code, metahash, and output metadata values for the different input cases if meta : if isinstance ( meta , str ): # Data-URL expected durl = meta payload = DataURL . from_url ( durl ) . data meta_code_digest = soft_hash_meta_v0 ( name , payload ) metahash = ic . multi_hash_blake3 ( payload ) metadata_value = durl elif isinstance ( meta , dict ): payload = jcs . canonicalize ( meta ) meta_code_digest = soft_hash_meta_v0 ( name , payload ) metahash = ic . multi_hash_blake3 ( payload ) media_type = \"application/ld+json\" if \"@context\" in meta else \"application/json\" durl_obj = DataURL . from_data ( media_type , base64_encode = True , data = payload ) metadata_value = durl_obj . url else : raise TypeError ( f \"metadata must be Data-URL string or dict not { type ( meta ) } \" ) else : payload = \" \" . join (( name , description )) . strip () . encode ( \"utf-8\" ) meta_code_digest = soft_hash_meta_v0 ( name , description ) metahash = ic . multi_hash_blake3 ( payload ) metadata_value = None meta_code = ic . encode_component ( mtype = ic . MT . META , stype = ic . ST . NONE , version = ic . VS . V0 , bit_length = bits , digest = meta_code_digest , ) iscc = \"ISCC:\" + meta_code # Build result result = { \"iscc\" : iscc } if name : result [ \"name\" ] = name if description : result [ \"description\" ] = description if metadata_value : result [ \"meta\" ] = metadata_value result [ \"metahash\" ] = metahash return result soft_hash_meta_v0 ( name , extra = None ) # Calculate simmilarity preserving 256-bit hash digest from asset metadata. Textual input should be stripped of markup, normalized and trimmed before hashing. Bytes input can be any serialized metadata (JSON, XML, Image...). Metadata should be serialized in a canonical form (for example JCS for JSON) Note The processing algorithm depends on the type of the extra input. If the extra field is supplied and non-empty, we create separate hashes for name and extra and interleave them in 32-bit chunks: If the extra input is None or an empty str / bytes object the Meta-Hash will be generated from the name -field only. If the extra -input is a non-empty text string (str) the string is lower-cased and the processing units are utf-8 endoded characters (possibly multibyte). If the extra -input is a non-empty bytes object the processing is done bytewise. Parameters: Name Type Description Default name str Title of the work manifested in the digital asset required extra Union[str,bytes,None] Additional metadata for disambiguation None Returns: Type Description bytes 256-bit simhash digest for Meta-Code Source code in iscc_core\\code_meta.py def soft_hash_meta_v0 ( name , extra = None ): # type: (str, Union[str,bytes,None]) -> bytes \"\"\" Calculate simmilarity preserving 256-bit hash digest from asset metadata. Textual input should be stripped of markup, normalized and trimmed before hashing. Bytes input can be any serialized metadata (JSON, XML, Image...). Metadata should be serialized in a canonical form (for example [JCS](https://tools.ietf.org/id/draft-rundgren-json-canonicalization-scheme-00.html) for JSON) !!! note The processing algorithm depends on the type of the `extra` input. If the `extra` field is supplied and non-empty, we create separate hashes for `name` and `extra` and interleave them in 32-bit chunks: - If the `extra` input is `None` or an empty `str`/`bytes` object the Meta-Hash will be generated from the `name`-field only. - If the `extra`-input is a non-empty **text** string (str) the string is lower-cased and the processing units are utf-8 endoded characters (possibly multibyte). - If the `extra`-input is a non-empty **bytes** object the processing is done bytewise. :param str name: Title of the work manifested in the digital asset :param Union[str,bytes,None] extra: Additional metadata for disambiguation :return: 256-bit simhash digest for Meta-Code :rtype: bytes \"\"\" name = ic . text_collapse ( name ) name_n_grams = ic . sliding_window ( name , width = ic . core_opts . meta_ngram_size_text ) name_hash_digests = [ blake3 ( s . encode ( \"utf-8\" )) . digest () for s in name_n_grams ] simhash_digest = ic . alg_simhash ( name_hash_digests ) if extra in { None , \"\" , b \"\" }: return simhash_digest else : # Augment with interleaved hash for extra metadata if isinstance ( extra , bytes ): # Raw bytes are handled per byte extra_n_grams = ic . sliding_window ( extra , width = ic . core_opts . meta_ngram_size_bytes ) extra_hash_digests = [ blake3 ( ngram ) . digest () for ngram in extra_n_grams ] elif isinstance ( extra , str ): # Text is collapsed and handled per character (multibyte) extra = ic . text_collapse ( extra ) extra_n_grams = ic . sliding_window ( extra , width = ic . core_opts . meta_ngram_size_text ) extra_hash_digests = [ blake3 ( s . encode ( \"utf-8\" )) . digest () for s in extra_n_grams ] else : raise ValueError ( \"parameter `extra` must be of type str or bytes!\" ) extra_simhash_digest = ic . alg_simhash ( extra_hash_digests ) # Interleave first half of name and extra simhashes in 32-bit chunks chunks_simhash_digest = sliced ( simhash_digest [: 16 ], 4 ) chunks_extra_simhash_digest = sliced ( extra_simhash_digest [: 16 ], 4 ) interleaved = interleave ( chunks_simhash_digest , chunks_extra_simhash_digest ) simhash_digest = bytearray () for chunk in interleaved : simhash_digest += chunk simhash_digest = bytes ( simhash_digest ) return simhash_digest text_trim ( text , nbytes ) # Trim text such that its utf-8 encoded size does not exceed nbytes . Source code in iscc_core\\code_meta.py def text_trim ( text , nbytes ): # type: (str, int) -> str \"\"\"Trim text such that its utf-8 encoded size does not exceed `nbytes`.\"\"\" return text . encode ( \"utf-8\" )[: nbytes ] . decode ( \"utf-8\" , \"ignore\" ) . strip () text_remove_newlines ( text ) # Remove newlines. The name field serves as a displayable title. We remove newlines and leading and trailing whitespace. We also collapse consecutive spaces to single spaces. Parameters: Name Type Description Default text Text for newline removal required Returns: Type Description str Single line of text Source code in iscc_core\\code_meta.py def text_remove_newlines ( text ): # type: (str) -> str \"\"\" Remove newlines. The `name` field serves as a displayable title. We remove newlines and leading and trailing whitespace. We also collapse consecutive spaces to single spaces. :param text: Text for newline removal :return: Single line of text :rtype: str \"\"\" return \" \" . join ( text . split ()) text_clean ( text ) # Clean text for display. Normalize with NFKC normalization. Remove Control Characters (except newlines) Reduce multiple consecutive newlines to a maximum of two newlines Strip leading and trailing whitespace Source code in iscc_core\\code_meta.py def text_clean ( text ): # type: (str) -> str \"\"\" Clean text for display. - Normalize with NFKC normalization. - Remove Control Characters (except newlines) - Reduce multiple consecutive newlines to a maximum of two newlines - Strip leading and trailing whitespace \"\"\" # Unicode normalize text = unicodedata . normalize ( \"NFKC\" , text ) # Remove control characters text = \"\" . join ( ch for ch in text if unicodedata . category ( ch )[ 0 ] != \"C\" or ch in ic . core_opts . text_newlines ) # Collapse more than two consecutive newlines chars = [] newline_count = 0 for c in text : if c in ic . core_opts . text_newlines : if newline_count < 2 : chars . append ( \" \\n \" ) newline_count += 1 continue else : newline_count = 0 chars . append ( c ) text = \"\" . join ( chars ) return text . strip ()","title":"Meta-Code"},{"location":"units/code_meta/#iscc-meta-code","text":"A similarity preserving hash for digital asset metadata .","title":"ISCC - Meta-Code"},{"location":"units/code_meta/#purpose","text":"The Meta-Code is the first possible (optional) unit of an ISCC-CODE. It is calculated from the metadata of a digital asset. The primary purpose of the Meta-Code is to aid the discovery of digital assets with similar metadata and the detection of metadata anomalies. As a secondary function, Meta-Code processing also creates a secure Meta-Hash for cryptogrpahic binding purposes.","title":"Purpose"},{"location":"units/code_meta/#inputs","text":"The metadata supplied for Meta-Code calculation is called Seed-Metadata . Seed-Metadata has 3 possible elements: name (required): The name or title of the work manifested by the digital asset. description (optional): A disambiguating textual description of the digital asset. meta (optional): Industry-sector or use-case specific metadata, encoded as Data-URL ( RFC-2397 ). Note Due to the broad applicability of the ISCC we do not prescribe a particular schema for the supplied metadata . But we use the Data-URL format because it can encode and self-describe any conceivable metadata in a sufficently machine-interpretable form at any desired specificity. Data-URL Examples : Metadata is \"some\" JSON: data:application/json;base64,<data> Metadata is JSON-LD: data:application/ld+json;base64,<data> Metadata is \"some\" XML: data:application/xml;base64,<data> Metadata is MARC21 XML: data:application/marcxml+xml;base64,<data> Metadata is IPTC NewsML: data:application/vnd.iptc.g2.newsitem+xml;base64,<data> Data-URLs are also supported by all major internet browsers.","title":"Inputs"},{"location":"units/code_meta/#processing","text":"","title":"Processing"},{"location":"units/code_meta/#meta-code","text":"The first 32-bits of a Meta-Code are calculated as a simliarity hash from the name field. The second 32-bits are also calculated from the name field if no other input was supplied. If description is suplied but no metadata , the description will be used for the second 32-bits. If metadata is supplied it will be used in favour of description for the second 32-bits. flowchart LR B{name?} B -->|Yes| J[\"P1 = SH(name)\"] J --> D{meta?} D -->|Yes| F[\"Meta-Code = P1 + SH(meta)\"] D -->|No| G{description?} G -->|Yes| H[\"Meta-Code = P1 + SH(description)\"] G -->|No| I[\"Meta-Code = P1\"] B -->|No| E[Skip Meta-Code] Note To support automation and reproducibility, applications that generate ISCCs, should prioritize metadata that is automatically extracted from the digital asset. If embedded metadata is not available or known to be unreliable an application should rely on external metadata or explicitly ask users to supply at least the name -field. Applications should then first embed metadata into the asset before calculating the ISCC-CODE . This ensures that the embedded metadata is bound to the asset by the Instance-Code. If neither embedded nor external metadata is available, the application may resort to use the filename of the digital asset as value for the name -field. If no value can be determined for the name -field, an application shall skip generation of a Meta-Code and create an ISCC-CODE without a Meta-Code.","title":"Meta-Code"},{"location":"units/code_meta/#meta-hash","text":"In addition to the Meta-Code we also create a cryptographic hash (the Meta-Hash) of the supplied Seed-Metadata. It is used to securely bind metadata to the digital asset. flowchart LR N{name?} N -->|Yes| A{meta?} N -->|No| E[Skip Meta-Hash] A -->|Yes| H[\"Meta-Hash = H(meta)\"] A -->|No| B{description?} B -->|Yes| HND[\"Meta-Hash = H(name + description)\"] B -->|No| HN[\"Meta-Hash = H(name)\"]","title":"Meta-Hash"},{"location":"units/code_meta/#functions","text":"","title":"Functions"},{"location":"units/code_meta/#iscc_core.code_meta.gen_meta_code_v0","text":"Create an ISCC Meta-Code with the algorithm version 0. Note The input for the metadata field can be: Structured (JSON/JCS serializable) metadata Raw bytes from a file header Parameters: Name Type Description Default name str Name or title of the work manifested by the digital asset required description Optional[str] Optional description for disambiguation None meta Optional[Union[dict,str] Dict or Data-URL string with extended metadata None bits int Bit-length of resulting Meta-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with possible fields: iscc, name, description, metadata, metahash Source code in iscc_core\\code_meta.py def gen_meta_code_v0 ( name , description = None , meta = None , bits = ic . core_opts . meta_bits ): # type: (str, Optional[str], Optional[ic.Meta], int) -> dict \"\"\" Create an ISCC Meta-Code with the algorithm version 0. !!! note The input for the `metadata` field can be: - Structured (JSON/JCS serializable) metadata - Raw bytes from a file header :param str name: Name or title of the work manifested by the digital asset :param Optional[str] description: Optional description for disambiguation :param Optional[Union[dict,str] meta: Dict or Data-URL string with extended metadata :param int bits: Bit-length of resulting Meta-Code (multiple of 64) :return: ISCC object with possible fields: iscc, name, description, metadata, metahash :rtype: dict \"\"\" # 1. Normalize `name` name = \"\" if name is None else name name = text_clean ( name ) name = text_remove_newlines ( name ) name = text_trim ( name , ic . core_opts . meta_trim_name ) if not name : raise ValueError ( \"Meta-Code requires non-empty name element (after normalization)\" ) # 2. Normalize `description` description = \"\" if description is None else description description = text_clean ( description ) description = text_trim ( description , ic . core_opts . meta_trim_description ) # Calculate meta_code, metahash, and output metadata values for the different input cases if meta : if isinstance ( meta , str ): # Data-URL expected durl = meta payload = DataURL . from_url ( durl ) . data meta_code_digest = soft_hash_meta_v0 ( name , payload ) metahash = ic . multi_hash_blake3 ( payload ) metadata_value = durl elif isinstance ( meta , dict ): payload = jcs . canonicalize ( meta ) meta_code_digest = soft_hash_meta_v0 ( name , payload ) metahash = ic . multi_hash_blake3 ( payload ) media_type = \"application/ld+json\" if \"@context\" in meta else \"application/json\" durl_obj = DataURL . from_data ( media_type , base64_encode = True , data = payload ) metadata_value = durl_obj . url else : raise TypeError ( f \"metadata must be Data-URL string or dict not { type ( meta ) } \" ) else : payload = \" \" . join (( name , description )) . strip () . encode ( \"utf-8\" ) meta_code_digest = soft_hash_meta_v0 ( name , description ) metahash = ic . multi_hash_blake3 ( payload ) metadata_value = None meta_code = ic . encode_component ( mtype = ic . MT . META , stype = ic . ST . NONE , version = ic . VS . V0 , bit_length = bits , digest = meta_code_digest , ) iscc = \"ISCC:\" + meta_code # Build result result = { \"iscc\" : iscc } if name : result [ \"name\" ] = name if description : result [ \"description\" ] = description if metadata_value : result [ \"meta\" ] = metadata_value result [ \"metahash\" ] = metahash return result","title":"gen_meta_code_v0()"},{"location":"units/code_meta/#iscc_core.code_meta.soft_hash_meta_v0","text":"Calculate simmilarity preserving 256-bit hash digest from asset metadata. Textual input should be stripped of markup, normalized and trimmed before hashing. Bytes input can be any serialized metadata (JSON, XML, Image...). Metadata should be serialized in a canonical form (for example JCS for JSON) Note The processing algorithm depends on the type of the extra input. If the extra field is supplied and non-empty, we create separate hashes for name and extra and interleave them in 32-bit chunks: If the extra input is None or an empty str / bytes object the Meta-Hash will be generated from the name -field only. If the extra -input is a non-empty text string (str) the string is lower-cased and the processing units are utf-8 endoded characters (possibly multibyte). If the extra -input is a non-empty bytes object the processing is done bytewise. Parameters: Name Type Description Default name str Title of the work manifested in the digital asset required extra Union[str,bytes,None] Additional metadata for disambiguation None Returns: Type Description bytes 256-bit simhash digest for Meta-Code Source code in iscc_core\\code_meta.py def soft_hash_meta_v0 ( name , extra = None ): # type: (str, Union[str,bytes,None]) -> bytes \"\"\" Calculate simmilarity preserving 256-bit hash digest from asset metadata. Textual input should be stripped of markup, normalized and trimmed before hashing. Bytes input can be any serialized metadata (JSON, XML, Image...). Metadata should be serialized in a canonical form (for example [JCS](https://tools.ietf.org/id/draft-rundgren-json-canonicalization-scheme-00.html) for JSON) !!! note The processing algorithm depends on the type of the `extra` input. If the `extra` field is supplied and non-empty, we create separate hashes for `name` and `extra` and interleave them in 32-bit chunks: - If the `extra` input is `None` or an empty `str`/`bytes` object the Meta-Hash will be generated from the `name`-field only. - If the `extra`-input is a non-empty **text** string (str) the string is lower-cased and the processing units are utf-8 endoded characters (possibly multibyte). - If the `extra`-input is a non-empty **bytes** object the processing is done bytewise. :param str name: Title of the work manifested in the digital asset :param Union[str,bytes,None] extra: Additional metadata for disambiguation :return: 256-bit simhash digest for Meta-Code :rtype: bytes \"\"\" name = ic . text_collapse ( name ) name_n_grams = ic . sliding_window ( name , width = ic . core_opts . meta_ngram_size_text ) name_hash_digests = [ blake3 ( s . encode ( \"utf-8\" )) . digest () for s in name_n_grams ] simhash_digest = ic . alg_simhash ( name_hash_digests ) if extra in { None , \"\" , b \"\" }: return simhash_digest else : # Augment with interleaved hash for extra metadata if isinstance ( extra , bytes ): # Raw bytes are handled per byte extra_n_grams = ic . sliding_window ( extra , width = ic . core_opts . meta_ngram_size_bytes ) extra_hash_digests = [ blake3 ( ngram ) . digest () for ngram in extra_n_grams ] elif isinstance ( extra , str ): # Text is collapsed and handled per character (multibyte) extra = ic . text_collapse ( extra ) extra_n_grams = ic . sliding_window ( extra , width = ic . core_opts . meta_ngram_size_text ) extra_hash_digests = [ blake3 ( s . encode ( \"utf-8\" )) . digest () for s in extra_n_grams ] else : raise ValueError ( \"parameter `extra` must be of type str or bytes!\" ) extra_simhash_digest = ic . alg_simhash ( extra_hash_digests ) # Interleave first half of name and extra simhashes in 32-bit chunks chunks_simhash_digest = sliced ( simhash_digest [: 16 ], 4 ) chunks_extra_simhash_digest = sliced ( extra_simhash_digest [: 16 ], 4 ) interleaved = interleave ( chunks_simhash_digest , chunks_extra_simhash_digest ) simhash_digest = bytearray () for chunk in interleaved : simhash_digest += chunk simhash_digest = bytes ( simhash_digest ) return simhash_digest","title":"soft_hash_meta_v0()"},{"location":"units/code_meta/#iscc_core.code_meta.text_trim","text":"Trim text such that its utf-8 encoded size does not exceed nbytes . Source code in iscc_core\\code_meta.py def text_trim ( text , nbytes ): # type: (str, int) -> str \"\"\"Trim text such that its utf-8 encoded size does not exceed `nbytes`.\"\"\" return text . encode ( \"utf-8\" )[: nbytes ] . decode ( \"utf-8\" , \"ignore\" ) . strip ()","title":"text_trim()"},{"location":"units/code_meta/#iscc_core.code_meta.text_remove_newlines","text":"Remove newlines. The name field serves as a displayable title. We remove newlines and leading and trailing whitespace. We also collapse consecutive spaces to single spaces. Parameters: Name Type Description Default text Text for newline removal required Returns: Type Description str Single line of text Source code in iscc_core\\code_meta.py def text_remove_newlines ( text ): # type: (str) -> str \"\"\" Remove newlines. The `name` field serves as a displayable title. We remove newlines and leading and trailing whitespace. We also collapse consecutive spaces to single spaces. :param text: Text for newline removal :return: Single line of text :rtype: str \"\"\" return \" \" . join ( text . split ())","title":"text_remove_newlines()"},{"location":"units/code_meta/#iscc_core.code_meta.text_clean","text":"Clean text for display. Normalize with NFKC normalization. Remove Control Characters (except newlines) Reduce multiple consecutive newlines to a maximum of two newlines Strip leading and trailing whitespace Source code in iscc_core\\code_meta.py def text_clean ( text ): # type: (str) -> str \"\"\" Clean text for display. - Normalize with NFKC normalization. - Remove Control Characters (except newlines) - Reduce multiple consecutive newlines to a maximum of two newlines - Strip leading and trailing whitespace \"\"\" # Unicode normalize text = unicodedata . normalize ( \"NFKC\" , text ) # Remove control characters text = \"\" . join ( ch for ch in text if unicodedata . category ( ch )[ 0 ] != \"C\" or ch in ic . core_opts . text_newlines ) # Collapse more than two consecutive newlines chars = [] newline_count = 0 for c in text : if c in ic . core_opts . text_newlines : if newline_count < 2 : chars . append ( \" \\n \" ) newline_count += 1 continue else : newline_count = 0 chars . append ( c ) text = \"\" . join ( chars ) return text . strip ()","title":"text_clean()"},{"location":"units/content/","text":"ISCC - Content-Codes #","title":"ISCC - Content-Codes"},{"location":"units/content/#iscc-content-codes","text":"","title":"ISCC - Content-Codes"},{"location":"units/content/code_content_audio/","text":"ISCC - Audio-Code # A similarity preserving hash for audio content (soft hash). Creates an ISCC object that provides an iscc -field with an Audio-Code and a duration -field. The Content-Code Audio is generated from a Chromaprint fingerprint provided as a vector of 32-bit signed integers. Chromaprints are extracted with fpcalc 1.5.0 using the following command line parameters: $ fpcalc -raw -json -signed -length 0 myaudiofile.mp3 gen_audio_code ( cv , bits = 64 ) # Create an ISCC Content-Code Audio with the latest standard algorithm. Parameters: Name Type Description Default cv Iterable[int] Chromaprint vector required bits int Bit-length resulting Content-Code Audio (multiple of 64) 64 Returns: Type Description dict ISCC object with Content-Code Audio gen_audio_code_v0 ( cv , bits = 64 ) # Create an ISCC Content-Code Audio with algorithm v0. Parameters: Name Type Description Default cv Iterable[int] Chromaprint vector required bits int Bit-length resulting Content-Code Audio (multiple of 64) 64 Returns: Type Description dict ISCC object with Content-Code Audio soft_hash_audio_v0 ( cv ) # Create 256-bit audio similarity hash from a chromaprint vector. Parameters: Name Type Description Default cv Iterable[int] Chromaprint vector required Returns: Type Description bytes 256-bit Audio-Hash digest","title":"Audio-Code"},{"location":"units/content/code_content_audio/#iscc-audio-code","text":"A similarity preserving hash for audio content (soft hash). Creates an ISCC object that provides an iscc -field with an Audio-Code and a duration -field. The Content-Code Audio is generated from a Chromaprint fingerprint provided as a vector of 32-bit signed integers. Chromaprints are extracted with fpcalc 1.5.0 using the following command line parameters: $ fpcalc -raw -json -signed -length 0 myaudiofile.mp3","title":"ISCC - Audio-Code"},{"location":"units/content/code_content_audio/#iscc_core.code_content_audio.gen_audio_code","text":"Create an ISCC Content-Code Audio with the latest standard algorithm. Parameters: Name Type Description Default cv Iterable[int] Chromaprint vector required bits int Bit-length resulting Content-Code Audio (multiple of 64) 64 Returns: Type Description dict ISCC object with Content-Code Audio","title":"gen_audio_code()"},{"location":"units/content/code_content_audio/#iscc_core.code_content_audio.gen_audio_code_v0","text":"Create an ISCC Content-Code Audio with algorithm v0. Parameters: Name Type Description Default cv Iterable[int] Chromaprint vector required bits int Bit-length resulting Content-Code Audio (multiple of 64) 64 Returns: Type Description dict ISCC object with Content-Code Audio","title":"gen_audio_code_v0()"},{"location":"units/content/code_content_audio/#iscc_core.code_content_audio.soft_hash_audio_v0","text":"Create 256-bit audio similarity hash from a chromaprint vector. Parameters: Name Type Description Default cv Iterable[int] Chromaprint vector required Returns: Type Description bytes 256-bit Audio-Hash digest","title":"soft_hash_audio_v0()"},{"location":"units/content/code_content_image/","text":"ISCC - Image-Code # A similarity preserving perceptual hash for images. The ISCC Content-Code Image is created by calculating a discrete cosine transform on normalized image-pixels and comparing the values from the upper left area of the dct-matrix against their median values to set the hash-bits. Images must be normalized before using gen_image_code. Prepare images as follows: Transpose image according to EXIF Orientation Add white background to image if it has alpha transparency Crop empty borders of image Convert image to grayscale Resize image to 32x32 Flatten 32x32 matrix to an array of 1024 grayscale (uint8) pixel values gen_image_code ( pixels , bits = 64 ) # Create an ISCC Content-Code Image with the latest standard algorithm. Parameters: Name Type Description Default pixels Sequence[int] Normalized image pixels (32x32 flattened gray values). required bits int Bit-length of ISCC Content-Code Image (default 64). 64 Returns: Type Description ISCC ISCC object with Content-Code Image. gen_image_code_v0 ( pixels , bits = 64 ) # Create an ISCC Content-Code Image with algorithm v0. Parameters: Name Type Description Default pixels Sequence[int] Normalized image pixels (32x32 flattened gray values) required bits int Bit-length of ISCC Content-Code Image (default 64). 64 Returns: Type Description ISCC ISCC object with Content-Code Image. soft_hash_image_v0 ( pixels , bits = 64 ) # Calculate image hash from normalized grayscale pixel sequence of length 1024. Parameters: Name Type Description Default pixels Sequence[int] required bits int Bit-length of image hash (default 64). 64 Returns: Type Description bytes Similarity preserving Image-Hash digest.","title":"Image-Code"},{"location":"units/content/code_content_image/#iscc-image-code","text":"A similarity preserving perceptual hash for images. The ISCC Content-Code Image is created by calculating a discrete cosine transform on normalized image-pixels and comparing the values from the upper left area of the dct-matrix against their median values to set the hash-bits. Images must be normalized before using gen_image_code. Prepare images as follows: Transpose image according to EXIF Orientation Add white background to image if it has alpha transparency Crop empty borders of image Convert image to grayscale Resize image to 32x32 Flatten 32x32 matrix to an array of 1024 grayscale (uint8) pixel values","title":"ISCC - Image-Code"},{"location":"units/content/code_content_image/#iscc_core.code_content_image.gen_image_code","text":"Create an ISCC Content-Code Image with the latest standard algorithm. Parameters: Name Type Description Default pixels Sequence[int] Normalized image pixels (32x32 flattened gray values). required bits int Bit-length of ISCC Content-Code Image (default 64). 64 Returns: Type Description ISCC ISCC object with Content-Code Image.","title":"gen_image_code()"},{"location":"units/content/code_content_image/#iscc_core.code_content_image.gen_image_code_v0","text":"Create an ISCC Content-Code Image with algorithm v0. Parameters: Name Type Description Default pixels Sequence[int] Normalized image pixels (32x32 flattened gray values) required bits int Bit-length of ISCC Content-Code Image (default 64). 64 Returns: Type Description ISCC ISCC object with Content-Code Image.","title":"gen_image_code_v0()"},{"location":"units/content/code_content_image/#iscc_core.code_content_image.soft_hash_image_v0","text":"Calculate image hash from normalized grayscale pixel sequence of length 1024. Parameters: Name Type Description Default pixels Sequence[int] required bits int Bit-length of image hash (default 64). 64 Returns: Type Description bytes Similarity preserving Image-Hash digest.","title":"soft_hash_image_v0()"},{"location":"units/content/code_content_mixed/","text":"ISCC - Mixed Code # A similarity hash for mixed media content. Creates an ISCC object that provides a iscc -field a Mixed-Code and a parts -field that lists the input codes. Many digital assets embed multiple assets of different mediatypes in a single file. Text documents may include images, video includes audio in most cases. The ISCC Content-Code-Mixed encodes the similarity of a collection of assets of the same or different mediatypes that may occur in a multimedia asset. Applications that create mixed Content-Codes must be capable to extract embedded assets and create individual Content-Codes per asset. gen_mixed_code ( codes , bits = 64 ) # Create an ISCC Content-Code Mixed with the latest standard algorithm. Parameters: Name Type Description Default codes Iterable[str] a list of Content-Codes. required bits int Target bit-length of generated Content-Code-Mixed. 64 Returns: Type Description dict ISCC object with Content-Code Mixed. gen_mixed_code_v0 ( codes , bits = 64 ) # Create an ISCC Content-Code-Mixed with algorithm v0. If the provided codes are of mixed length they are stripped to bits length for calculation. Parameters: Name Type Description Default codes Iterable[str] a list of Content-Codes. required bits int Target bit-length of generated Content-Code-Mixed. 64 Returns: Type Description dict ISCC object with Content-Code Mixed. soft_hash_codes_v0 ( cc_digests , bits = 64 ) # Create a similarity hash from multiple Content-Code digests. The similarity hash is created from the bodies of the input codes with the first byte of the code-header prepended. All codes must be of main-type CONTENT and have a minimum length of bits . Parameters: Name Type Description Default cc_digests Sequence[bytes] a list of Content-Code digests. required bits int Target bit-length of generated Content-Code-Mixed. 64 Returns: Type Description bytes Similarity preserving byte hash.","title":"Mixed-Code"},{"location":"units/content/code_content_mixed/#iscc-mixed-code","text":"A similarity hash for mixed media content. Creates an ISCC object that provides a iscc -field a Mixed-Code and a parts -field that lists the input codes. Many digital assets embed multiple assets of different mediatypes in a single file. Text documents may include images, video includes audio in most cases. The ISCC Content-Code-Mixed encodes the similarity of a collection of assets of the same or different mediatypes that may occur in a multimedia asset. Applications that create mixed Content-Codes must be capable to extract embedded assets and create individual Content-Codes per asset.","title":"ISCC - Mixed Code"},{"location":"units/content/code_content_mixed/#iscc_core.code_content_mixed.gen_mixed_code","text":"Create an ISCC Content-Code Mixed with the latest standard algorithm. Parameters: Name Type Description Default codes Iterable[str] a list of Content-Codes. required bits int Target bit-length of generated Content-Code-Mixed. 64 Returns: Type Description dict ISCC object with Content-Code Mixed.","title":"gen_mixed_code()"},{"location":"units/content/code_content_mixed/#iscc_core.code_content_mixed.gen_mixed_code_v0","text":"Create an ISCC Content-Code-Mixed with algorithm v0. If the provided codes are of mixed length they are stripped to bits length for calculation. Parameters: Name Type Description Default codes Iterable[str] a list of Content-Codes. required bits int Target bit-length of generated Content-Code-Mixed. 64 Returns: Type Description dict ISCC object with Content-Code Mixed.","title":"gen_mixed_code_v0()"},{"location":"units/content/code_content_mixed/#iscc_core.code_content_mixed.soft_hash_codes_v0","text":"Create a similarity hash from multiple Content-Code digests. The similarity hash is created from the bodies of the input codes with the first byte of the code-header prepended. All codes must be of main-type CONTENT and have a minimum length of bits . Parameters: Name Type Description Default cc_digests Sequence[bytes] a list of Content-Code digests. required bits int Target bit-length of generated Content-Code-Mixed. 64 Returns: Type Description bytes Similarity preserving byte hash.","title":"soft_hash_codes_v0()"},{"location":"units/content/code_content_text/","text":"ISCC - Text Code # A similarity preserving hash for plain-text content (soft hash). The ISCC Text-Code is generated from plain-text that has been extracted from a media assets. Tip Plain-text extraction from documents in various formats (especially PDF) may yield very diffent results depending on the extraction tools being used. For reproducible Text-Code generation use Apache Tika v2.2.1 to extract text from your documents. Algorithm overview Apply text_collapse function to text input Count characters of collapsed text Apply soft_hash_text_v0 to collapsed text gen_text_code_v0 ( text , bits = 64 ) # Create an ISCC Text-Code with algorithm v0. Note Any markup (like HTML tags or markdown) should be removed from the plain-text before passing it to this function. Parameters: Name Type Description Default text str Text for Text-Code creation required bits int Bit-length of ISCC Code Hash (default 64) 64 Returns: Type Description dict ISCC schema instance with Text-Code and an aditional property characters Source code in iscc_core\\code_content_text.py def gen_text_code_v0 ( text , bits = ic . core_opts . text_bits ): # type: (str, int) -> dict \"\"\" Create an ISCC Text-Code with algorithm v0. !!! note Any markup (like HTML tags or markdown) should be removed from the plain-text before passing it to this function. :param str text: Text for Text-Code creation :param int bits: Bit-length of ISCC Code Hash (default 64) :return: ISCC schema instance with Text-Code and an aditional property `characters` :rtype: dict \"\"\" text = text_collapse ( text ) characters = len ( text ) digest = soft_hash_text_v0 ( text ) text_code = ic . encode_component ( mtype = ic . MT . CONTENT , stype = ic . ST_CC . TEXT , version = ic . VS . V0 , bit_length = bits , digest = digest , ) iscc = \"ISCC:\" + text_code return dict ( iscc = iscc , characters = characters ) soft_hash_text_v0 ( text ) # Creates a 256-bit similarity preserving hash for text input with algorithm v0. Slide over text with a text_ngram_size wide window and create xxh32 hashes Create a minhash_256 from the hashes generated in the previous step. Note Before passing text to this function it must be: stripped of markup normalized stripped of whitespace lowercased Parameters: Name Type Description Default text str Plain text to be hashed. required Returns: Type Description bytes 256-bit similarity preserving byte hash. Source code in iscc_core\\code_content_text.py def soft_hash_text_v0 ( text ): # type: (str) -> bytes \"\"\" Creates a 256-bit similarity preserving hash for text input with algorithm v0. - Slide over text with a [`text_ngram_size`][iscc_core.options.CoreOptions.text_ngram_size] wide window and create [`xxh32`](https://cyan4973.github.io/xxHash/) hashes - Create a [`minhash_256`][iscc_core.minhash.alg_minhash_256] from the hashes generated in the previous step. !!! note Before passing text to this function it must be: - stripped of markup - normalized - stripped of whitespace - lowercased :param str text: Plain text to be hashed. :return: 256-bit similarity preserving byte hash. :rtype: bytes \"\"\" ngrams = ic . sliding_window ( text , ic . core_opts . text_ngram_size ) features = [ xxhash . xxh32_intdigest ( s . encode ( \"utf-8\" )) for s in ngrams ] hash_digest = ic . alg_minhash_256 ( features ) return hash_digest text_collapse ( text ) # Normalize and simplify text for similarity hashing. Decompose with NFD normalization. Remove all whitespace characters and convert text to lower case Filter control characters, marks (diacritics), and punctuation Recombine with NFKC normalization. Note See: Unicode normalization . Parameters: Name Type Description Default text str Plain text to be collapsed. required Returns: Type Description str Collapsed plain text. Source code in iscc_core\\code_content_text.py def text_collapse ( text ): # type: (str) -> str \"\"\" Normalize and simplify text for similarity hashing. - Decompose with NFD normalization. - Remove all whitespace characters and convert text to lower case - Filter control characters, marks (diacritics), and punctuation - Recombine with NFKC normalization. !!! note See: [Unicode normalization](https://unicode.org/reports/tr15/). :param str text: Plain text to be collapsed. :return: Collapsed plain text. :rtype: str \"\"\" # Decompose with NFD text = unicodedata . normalize ( \"NFD\" , text ) # Remove all whitespace and convert text to lower case text = \"\" . join ( text . split ()) . lower () # Filter control characters, marks (diacritics), and punctuation text = \"\" . join ( ch for ch in text if unicodedata . category ( ch )[ 0 ] not in ic . core_opts . text_unicode_filter ) # Recombine text = unicodedata . normalize ( \"NFKC\" , text ) return text","title":"Text-Code"},{"location":"units/content/code_content_text/#iscc-text-code","text":"A similarity preserving hash for plain-text content (soft hash). The ISCC Text-Code is generated from plain-text that has been extracted from a media assets. Tip Plain-text extraction from documents in various formats (especially PDF) may yield very diffent results depending on the extraction tools being used. For reproducible Text-Code generation use Apache Tika v2.2.1 to extract text from your documents. Algorithm overview Apply text_collapse function to text input Count characters of collapsed text Apply soft_hash_text_v0 to collapsed text","title":"ISCC - Text Code"},{"location":"units/content/code_content_text/#iscc_core.code_content_text.gen_text_code_v0","text":"Create an ISCC Text-Code with algorithm v0. Note Any markup (like HTML tags or markdown) should be removed from the plain-text before passing it to this function. Parameters: Name Type Description Default text str Text for Text-Code creation required bits int Bit-length of ISCC Code Hash (default 64) 64 Returns: Type Description dict ISCC schema instance with Text-Code and an aditional property characters Source code in iscc_core\\code_content_text.py def gen_text_code_v0 ( text , bits = ic . core_opts . text_bits ): # type: (str, int) -> dict \"\"\" Create an ISCC Text-Code with algorithm v0. !!! note Any markup (like HTML tags or markdown) should be removed from the plain-text before passing it to this function. :param str text: Text for Text-Code creation :param int bits: Bit-length of ISCC Code Hash (default 64) :return: ISCC schema instance with Text-Code and an aditional property `characters` :rtype: dict \"\"\" text = text_collapse ( text ) characters = len ( text ) digest = soft_hash_text_v0 ( text ) text_code = ic . encode_component ( mtype = ic . MT . CONTENT , stype = ic . ST_CC . TEXT , version = ic . VS . V0 , bit_length = bits , digest = digest , ) iscc = \"ISCC:\" + text_code return dict ( iscc = iscc , characters = characters )","title":"gen_text_code_v0()"},{"location":"units/content/code_content_text/#iscc_core.code_content_text.soft_hash_text_v0","text":"Creates a 256-bit similarity preserving hash for text input with algorithm v0. Slide over text with a text_ngram_size wide window and create xxh32 hashes Create a minhash_256 from the hashes generated in the previous step. Note Before passing text to this function it must be: stripped of markup normalized stripped of whitespace lowercased Parameters: Name Type Description Default text str Plain text to be hashed. required Returns: Type Description bytes 256-bit similarity preserving byte hash. Source code in iscc_core\\code_content_text.py def soft_hash_text_v0 ( text ): # type: (str) -> bytes \"\"\" Creates a 256-bit similarity preserving hash for text input with algorithm v0. - Slide over text with a [`text_ngram_size`][iscc_core.options.CoreOptions.text_ngram_size] wide window and create [`xxh32`](https://cyan4973.github.io/xxHash/) hashes - Create a [`minhash_256`][iscc_core.minhash.alg_minhash_256] from the hashes generated in the previous step. !!! note Before passing text to this function it must be: - stripped of markup - normalized - stripped of whitespace - lowercased :param str text: Plain text to be hashed. :return: 256-bit similarity preserving byte hash. :rtype: bytes \"\"\" ngrams = ic . sliding_window ( text , ic . core_opts . text_ngram_size ) features = [ xxhash . xxh32_intdigest ( s . encode ( \"utf-8\" )) for s in ngrams ] hash_digest = ic . alg_minhash_256 ( features ) return hash_digest","title":"soft_hash_text_v0()"},{"location":"units/content/code_content_text/#iscc_core.code_content_text.text_collapse","text":"Normalize and simplify text for similarity hashing. Decompose with NFD normalization. Remove all whitespace characters and convert text to lower case Filter control characters, marks (diacritics), and punctuation Recombine with NFKC normalization. Note See: Unicode normalization . Parameters: Name Type Description Default text str Plain text to be collapsed. required Returns: Type Description str Collapsed plain text. Source code in iscc_core\\code_content_text.py def text_collapse ( text ): # type: (str) -> str \"\"\" Normalize and simplify text for similarity hashing. - Decompose with NFD normalization. - Remove all whitespace characters and convert text to lower case - Filter control characters, marks (diacritics), and punctuation - Recombine with NFKC normalization. !!! note See: [Unicode normalization](https://unicode.org/reports/tr15/). :param str text: Plain text to be collapsed. :return: Collapsed plain text. :rtype: str \"\"\" # Decompose with NFD text = unicodedata . normalize ( \"NFD\" , text ) # Remove all whitespace and convert text to lower case text = \"\" . join ( text . split ()) . lower () # Filter control characters, marks (diacritics), and punctuation text = \"\" . join ( ch for ch in text if unicodedata . category ( ch )[ 0 ] not in ic . core_opts . text_unicode_filter ) # Recombine text = unicodedata . normalize ( \"NFKC\" , text ) return text","title":"text_collapse()"},{"location":"units/content/code_content_video/","text":"ISCC - Video-Code # A similarity preserving hash for video content The Content-Code Video is generated from MPEG-7 Video Frame Signatures. Frame Signatures can be extracted with ffmpeg (see: https://www.ffmpeg.org/ ) using the following command line parameters: $ ffmpeg -i video.mpg -vf fps=fps=5,signature=format=xml:filename=sig.xml -f null - The relevant frame signatures can be parsed from the following elements in sig.xml: <FrameSignature>0 0 0 1 0 0 1 0 1 1 0 0 1 1 ...</FrameSignature> Tip It is also possible to extract the signatures in a more compact binary format. But the format requires a custom binary parser to decode the frame signaturs. gen_video_code ( frame_sigs , bits = 64 ) # Create an ISCC Video-Code with the latest standard algorithm. Parameters: Name Type Description Default frame_sigs ic.FrameSig Sequence of MP7 frame signatures required bits int Bit-length resulting Instance-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with Video-Code gen_video_code_v0 ( frame_sigs , bits = 64 ) # Create an ISCC Video-Code with algorithm v0. Parameters: Name Type Description Default frame_sigs ic.FrameSig Sequence of MP7 frame signatures required bits int Bit-length resulting Video-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with Video-Code soft_hash_video_v0 ( frame_sigs , bits = 64 ) # Compute video hash v0 from MP7 frame signatures. Parameters: Name Type Description Default frame_sigs ic.FrameSig 2D matrix of MP7 frame signatures required bits int Bit-length of resulting Video-Code (multiple of 64) 64","title":"Video-Code"},{"location":"units/content/code_content_video/#iscc-video-code","text":"A similarity preserving hash for video content The Content-Code Video is generated from MPEG-7 Video Frame Signatures. Frame Signatures can be extracted with ffmpeg (see: https://www.ffmpeg.org/ ) using the following command line parameters: $ ffmpeg -i video.mpg -vf fps=fps=5,signature=format=xml:filename=sig.xml -f null - The relevant frame signatures can be parsed from the following elements in sig.xml: <FrameSignature>0 0 0 1 0 0 1 0 1 1 0 0 1 1 ...</FrameSignature> Tip It is also possible to extract the signatures in a more compact binary format. But the format requires a custom binary parser to decode the frame signaturs.","title":"ISCC - Video-Code"},{"location":"units/content/code_content_video/#iscc_core.code_content_video.gen_video_code","text":"Create an ISCC Video-Code with the latest standard algorithm. Parameters: Name Type Description Default frame_sigs ic.FrameSig Sequence of MP7 frame signatures required bits int Bit-length resulting Instance-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with Video-Code","title":"gen_video_code()"},{"location":"units/content/code_content_video/#iscc_core.code_content_video.gen_video_code_v0","text":"Create an ISCC Video-Code with algorithm v0. Parameters: Name Type Description Default frame_sigs ic.FrameSig Sequence of MP7 frame signatures required bits int Bit-length resulting Video-Code (multiple of 64) 64 Returns: Type Description dict ISCC object with Video-Code","title":"gen_video_code_v0()"},{"location":"units/content/code_content_video/#iscc_core.code_content_video.soft_hash_video_v0","text":"Compute video hash v0 from MP7 frame signatures. Parameters: Name Type Description Default frame_sigs ic.FrameSig 2D matrix of MP7 frame signatures required bits int Bit-length of resulting Video-Code (multiple of 64) 64","title":"soft_hash_video_v0()"},{"location":"utilities/utils/","text":"ISCC - Utilities # json_canonical ( obj ) # Canonical, deterministic serialization of ISCC metadata. We serialize ISCC metadata in a deterministic/reproducible manner by using JCS (RFC 8785) canonicalization. Source code in iscc_core\\utils.py def json_canonical ( obj ): # type: (Any) -> bytes \"\"\" Canonical, deterministic serialization of ISCC metadata. We serialize ISCC metadata in a deterministic/reproducible manner by using [JCS (RFC 8785)](https://datatracker.ietf.org/doc/html/rfc8785) canonicalization. \"\"\" ser = jcs . canonicalize ( obj ) des = json . loads ( ser ) if des != obj : raise ValueError ( f \"Not canonicalizable { obj } round-trips to { des } \" ) return ser cidv1_hex ( stream ) # Create a IPFS CIDv1 hash for ISCC metadata in base16 (hexadecimal) representation. Learn more about IPFS CIDv1 at ProtoSchool We use the default CIDv1 with sha1-256 and chunksize 262144 as hashing algorithm for ISCC metadata. Attention We use the base16 (hexadecimal) representation for the CIDv1. This gives as stable, fixed-length CIDv1 header-prefix and allows us to use the CIDv1 as an ERC-721 / ERC-1155 uint256 Token-ID while also supporting ID-substitution for the metadata URI. For details see discussion at OpenZeppelin Forum Example >>> import io >>> import iscc_core as ic >>> ic . cidv1_hex ( io . BytesIO ( b 'hello world' )) 'f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9' The result might not look like a valid IPFS CIDv1, but it actually is: https://ipfs.io/ipfs/f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 With IPFS v0.11.0 this equals to: $ipfs add --cid-version = 1 <myfile> $ipfs cid format -b = base16 bafkreifzjut3te2nhyekklss27nh3k72ysco7y32koao5eei66wof36n5e f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 When using cidv1_to_token_id for this hash you get an uint256 that can be converted to a hex representation within a Smart Contract. The hex-representation can then be used for ID-Substitution. Use ipfs://f01551220{id} as template for the Metadata-URI. Parameters: Name Type Description Default stream Stream Data to be hashed (currently max 262144 bytes supported) required Returns: Type Description str A valid IPFS CIDv1 that can be used as token-id and metadata-uri Source code in iscc_core\\utils.py def cidv1_hex ( stream ): # type: (Union[Stream, bytes]) -> str \"\"\" Create a [IPFS CIDv1](https://specs.ipld.io/block-layer/CID.html#cids-version-1) hash for ISCC metadata in `base16` (hexadecimal) representation. Learn more about IPFS CIDv1 at [ProtoSchool](https://proto.school/anatomy-of-a-cid) We use the default `CIDv1` with `sha1-256` and chunksize `262144` as hashing algorithm for ISCC metadata. !!! attention We use the `base16` (hexadecimal) representation for the CIDv1. This gives as stable, fixed-length CIDv1 header-prefix and allows us to use the CIDv1 as an [ERC-721](https://eips.ethereum.org/EIPS/eip-721)/[ERC-1155](https://eips.ethereum.org/EIPS/eip-1155) `uint256` Token-ID while also supporting ID-substitution for the metadata URI. For details see discussion at [OpenZeppelin Forum](https://forum.openzeppelin.com/t/how-to-erc-1155-id-substitution-for-token-uri/3312/14) !!! example ```python >>> import io >>> import iscc_core as ic >>> ic.cidv1_hex(io.BytesIO(b'hello world')) 'f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9' ``` The result might not look like a valid IPFS CIDv1, but it actually is: https://ipfs.io/ipfs/f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 With IPFS v0.11.0 this equals to: ```bash $ipfs add --cid-version=1 <myfile> $ipfs cid format -b=base16 bafkreifzjut3te2nhyekklss27nh3k72ysco7y32koao5eei66wof36n5e f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 ``` When using `cidv1_to_token_id` for this hash you get an `uint256` that can be converted to a hex representation within a Smart Contract. The hex-representation can then be used for ID-Substitution. Use `ipfs://f01551220{id}` as template for the Metadata-URI. :param Stream stream: Data to be hashed (currently max 262144 bytes supported) :return: A valid IPFS CIDv1 that can be used as token-id and metadata-uri :rtype: str \"\"\" if isinstance ( stream , bytes ): stream = io . BytesIO ( stream ) ipfs_max_size = 262144 data = stream . read ( ipfs_max_size ) # fail if we have more data than ipfs_max_size if stream . read ( 1 ): raise ValueError ( f \"Data exceeds current max size { ipfs_max_size } for ipfs_hash: { len ( data ) } \" ) digest = sha256 ( data ) . digest () multibase_prefix = \"f\" multicodec_cidv1 = b \" \\x01 \" multicodec_content_type = b \" \\x55 \" # raw multicodec_mutihash_type = b \" \\x12 \" # sha2-256 multicodec_mutihash_len = uvarint . encode ( 32 ) # 28 byte length (varint encoded 0x1c) cid_v1_digest = b \"\" . join ( ( multicodec_cidv1 , multicodec_content_type , multicodec_mutihash_type , multicodec_mutihash_len , digest , ) ) cid_v1 = multibase_prefix + cid_v1_digest . hex () return cid_v1 cidv1_to_token_id ( cidv1 ) # Convert default IPFS CIDv1 to an uint256 Token-ID. To save storage space in Smart Contracts and to securely link an NFT Token-ID to its associated metadata we can convert a CIDv1 to an uint256 Token-ID and vice versa. Example >>> import io >>> import iscc_core as ic >>> ic . cidv1_to_token_id ( \"f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\" ) 83814198383102558219731078260892729932246618004265700685467928187377105751529 Parameters: Name Type Description Default cidv1 str An IPFS CIDv1 string base-16 (hex) encoded representation. required Returns: Type Description An uint256 derived from the CIDv1 Source code in iscc_core\\utils.py def cidv1_to_token_id ( cidv1 ): # type: (str) -> int \"\"\" Convert default IPFS CIDv1 to an uint256 Token-ID. To save storage space in Smart Contracts and to securely link an NFT Token-ID to its associated metadata we can convert a CIDv1 to an uint256 Token-ID and vice versa. !!! example ```python >>> import io >>> import iscc_core as ic >>> ic.cidv1_to_token_id(\"f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\") 83814198383102558219731078260892729932246618004265700685467928187377105751529 ``` :param str cidv1: An IPFS CIDv1 string base-16 (hex) encoded representation. :return int: An uint256 derived from the CIDv1 \"\"\" if not cidv1 . startswith ( \"f\" ): raise ValueError ( f \"Only base16 encoded CIDv1 supported. Got { cidv1 } \" ) nobase = cidv1 [ 1 :] decoded = bytes . fromhex ( nobase ) if not decoded . startswith ( b \" \\x01\\x55\\x12\\x20 \" ): raise ValueError ( f \"Only sha2-256 with raw leaves supported. Got { decoded . hex () } \" ) digest = decoded [ 4 :] if not len ( digest ) == 32 : raise ValueError ( f \"Illegal digest size { len ( digest ) } for sha2-256\" ) return int . from_bytes ( digest , \"big\" , signed = False ) cidv1_from_token_id ( token_id ) # Convert Token-ID to default IPFS CIDv1 (reverse of cidv1_to_token_id ). Example >>> import io >>> import iscc_core as ic >>> ic . cidv1_from_token_id ( 83814198383102558219731078260892729932246618004265700685467928187377105751529 ) 'f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9' Parameters: Name Type Description Default token_id An uint256 Token-ID derived from a CIDv1 required Returns: Type Description An IPFS CIDv1 string with default base32 encoding. Source code in iscc_core\\utils.py def cidv1_from_token_id ( token_id ): # type: (int) -> str \"\"\" Convert Token-ID to default IPFS CIDv1 (reverse of `cidv1_to_token_id`). !!! example ```python >>> import io >>> import iscc_core as ic >>> ic.cidv1_from_token_id(83814198383102558219731078260892729932246618004265700685467928187377105751529) 'f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9' ``` :param token_id: An uint256 Token-ID derived from a CIDv1 :return str: An IPFS CIDv1 string with default base32 encoding. \"\"\" digest = b \" \\x01\\x55\\x12\\x20 \" + int . to_bytes ( token_id , length = 32 , byteorder = \"big\" , signed = False ) return \"f\" + digest . hex () multi_hash_blake3 ( data ) # Create blake3 hash with multihash prefix. Parameters: Name Type Description Default data bytes Bytes to be hashed required Returns: Type Description str Multihash prefixed 256-bit blake3 hash as hex string Source code in iscc_core\\utils.py def multi_hash_blake3 ( data ): # type: (bytes) -> str \"\"\" Create blake3 hash with multihash prefix. :param bytes data: Bytes to be hashed :return: Multihash prefixed 256-bit blake3 hash as hex string :rtype: str \"\"\" return ( b \" \\x1e\\x20 \" + blake3 ( data ) . digest ()) . hex () sliding_window ( seq , width ) # Generate a sequence of equal \"width\" slices each advancing by one elemnt. All types that have a length and can be sliced are supported (list, tuple, str ...). The result type matches the type of the input sequence. Fragment slices smaller than the width at the end of the sequence are not produced. If \"witdh\" is smaller than the input sequence than one element will be returned that is shorter than the requested width. Parameters: Name Type Description Default seq Sequence Sequence of values to slide over required width int Width of sliding window in number of items required Returns: Type Description Union[Generat,] A generator of window sized items Source code in iscc_core\\utils.py def sliding_window ( seq , width ): # type: (Sequence, int) -> Generator \"\"\" Generate a sequence of equal \"width\" slices each advancing by one elemnt. All types that have a length and can be sliced are supported (list, tuple, str ...). The result type matches the type of the input sequence. Fragment slices smaller than the width at the end of the sequence are not produced. If \"witdh\" is smaller than the input sequence than one element will be returned that is shorter than the requested width. :param Sequence seq: Sequence of values to slide over :param int width: Width of sliding window in number of items :returns: A generator of window sized items :rtype: Generator \"\"\" if width < 2 : raise AssertionError ( \"Sliding window width must be 2 or bigger.\" ) idx = range ( max ( len ( seq ) - width + 1 , 1 )) return ( seq [ i : i + width ] for i in idx ) iscc_similarity ( a , b ) # Calculate similarity of ISCC codes as a percentage value (0-100). MainType, SubType, Version and Length of the codes must be the same. Parameters: Name Type Description Default a ISCC a required b ISCC b required Returns: Type Description int Similarity of ISCC a and b in percent (based on hamming distance) Source code in iscc_core\\utils.py def iscc_similarity ( a , b ): # type: (str, str) -> int \"\"\" Calculate similarity of ISCC codes as a percentage value (0-100). MainType, SubType, Version and Length of the codes must be the same. :param a: ISCC a :param b: ISCC b :return: Similarity of ISCC a and b in percent (based on hamming distance) :rtype: int \"\"\" a , b = iscc_pair_unpack ( a , b ) hdist = iscc_distance_bytes ( a , b ) nbits = len ( a ) * 8 sim = int ((( nbits - hdist ) / nbits ) * 100 ) return sim iscc_distance ( a , b ) # Calculate hamming distance of ISCC codes. MainType, SubType, Version and Length of the codes must be the same. Parameters: Name Type Description Default a ISCC a required b ISCC b required Returns: Type Description int Hamming distanced in number of bits. Source code in iscc_core\\utils.py def iscc_distance ( a , b ): # type: (str, str) -> int \"\"\" Calculate hamming distance of ISCC codes. MainType, SubType, Version and Length of the codes must be the same. :param a: ISCC a :param b: ISCC b :return: Hamming distanced in number of bits. :rtype: int \"\"\" a , b = iscc_pair_unpack ( a , b ) return iscc_distance_bytes ( a , b ) iscc_distance_bytes ( a , b ) # Calculate hamming distance for binary hash digests of equal length. Parameters: Name Type Description Default a bytes binary hash digest required b bytes binary hash digest required Returns: Type Description int Hamming distance in number of bits. Source code in iscc_core\\utils.py def iscc_distance_bytes ( a , b ): # type: (bytes, bytes) -> int \"\"\" Calculate hamming distance for binary hash digests of equal length. :param bytes a: binary hash digest :param bytes b: binary hash digest :return: Hamming distance in number of bits. :rtype: int \"\"\" if len ( a ) != len ( b ): raise AssertionError ( f \"Hash diggest of unequal length: { len ( a ) } vs { len ( b ) } \" ) ba , bb = bitarray (), bitarray () ba . frombytes ( a ) bb . frombytes ( b ) return count_xor ( ba , bb ) iscc_pair_unpack ( a , b ) # Unpack two ISCC codes and return their body hash digests if their headers match. Headers match if their MainType, SubType, and Version are identical. Parameters: Name Type Description Default a ISCC a required b ISCC b required Returns: Type Description Tuple[bytes, bytes] Tuple with hash digests of a and b Exceptions: Type Description ValueError If ISCC headers don\u00b4t match Source code in iscc_core\\utils.py def iscc_pair_unpack ( a , b ): # type: (str, str) -> Tuple[bytes, bytes] \"\"\" Unpack two ISCC codes and return their body hash digests if their headers match. Headers match if their MainType, SubType, and Version are identical. :param a: ISCC a :param b: ISCC b :return: Tuple with hash digests of a and b :rtype: Tuple[bytes, bytes] :raise ValueError: If ISCC headers don\u00b4t match \"\"\" a , b = ic . iscc_clean ( ic . iscc_normalize ( a )), ic . iscc_clean ( ic . iscc_normalize ( b )) a , b = ic . decode_base32 ( a ), ic . decode_base32 ( b ) a , b = ic . decode_header ( a ), ic . decode_header ( b ) if not a [: - 1 ] == b [: - 1 ]: raise ValueError ( f \"ISCC headers don\u00b4t match: { a } , { b } \" ) return a [ - 1 ], b [ - 1 ]","title":"Utilities"},{"location":"utilities/utils/#iscc-utilities","text":"","title":"ISCC - Utilities"},{"location":"utilities/utils/#iscc_core.utils.json_canonical","text":"Canonical, deterministic serialization of ISCC metadata. We serialize ISCC metadata in a deterministic/reproducible manner by using JCS (RFC 8785) canonicalization. Source code in iscc_core\\utils.py def json_canonical ( obj ): # type: (Any) -> bytes \"\"\" Canonical, deterministic serialization of ISCC metadata. We serialize ISCC metadata in a deterministic/reproducible manner by using [JCS (RFC 8785)](https://datatracker.ietf.org/doc/html/rfc8785) canonicalization. \"\"\" ser = jcs . canonicalize ( obj ) des = json . loads ( ser ) if des != obj : raise ValueError ( f \"Not canonicalizable { obj } round-trips to { des } \" ) return ser","title":"json_canonical()"},{"location":"utilities/utils/#iscc_core.utils.cidv1_hex","text":"Create a IPFS CIDv1 hash for ISCC metadata in base16 (hexadecimal) representation. Learn more about IPFS CIDv1 at ProtoSchool We use the default CIDv1 with sha1-256 and chunksize 262144 as hashing algorithm for ISCC metadata. Attention We use the base16 (hexadecimal) representation for the CIDv1. This gives as stable, fixed-length CIDv1 header-prefix and allows us to use the CIDv1 as an ERC-721 / ERC-1155 uint256 Token-ID while also supporting ID-substitution for the metadata URI. For details see discussion at OpenZeppelin Forum Example >>> import io >>> import iscc_core as ic >>> ic . cidv1_hex ( io . BytesIO ( b 'hello world' )) 'f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9' The result might not look like a valid IPFS CIDv1, but it actually is: https://ipfs.io/ipfs/f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 With IPFS v0.11.0 this equals to: $ipfs add --cid-version = 1 <myfile> $ipfs cid format -b = base16 bafkreifzjut3te2nhyekklss27nh3k72ysco7y32koao5eei66wof36n5e f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 When using cidv1_to_token_id for this hash you get an uint256 that can be converted to a hex representation within a Smart Contract. The hex-representation can then be used for ID-Substitution. Use ipfs://f01551220{id} as template for the Metadata-URI. Parameters: Name Type Description Default stream Stream Data to be hashed (currently max 262144 bytes supported) required Returns: Type Description str A valid IPFS CIDv1 that can be used as token-id and metadata-uri Source code in iscc_core\\utils.py def cidv1_hex ( stream ): # type: (Union[Stream, bytes]) -> str \"\"\" Create a [IPFS CIDv1](https://specs.ipld.io/block-layer/CID.html#cids-version-1) hash for ISCC metadata in `base16` (hexadecimal) representation. Learn more about IPFS CIDv1 at [ProtoSchool](https://proto.school/anatomy-of-a-cid) We use the default `CIDv1` with `sha1-256` and chunksize `262144` as hashing algorithm for ISCC metadata. !!! attention We use the `base16` (hexadecimal) representation for the CIDv1. This gives as stable, fixed-length CIDv1 header-prefix and allows us to use the CIDv1 as an [ERC-721](https://eips.ethereum.org/EIPS/eip-721)/[ERC-1155](https://eips.ethereum.org/EIPS/eip-1155) `uint256` Token-ID while also supporting ID-substitution for the metadata URI. For details see discussion at [OpenZeppelin Forum](https://forum.openzeppelin.com/t/how-to-erc-1155-id-substitution-for-token-uri/3312/14) !!! example ```python >>> import io >>> import iscc_core as ic >>> ic.cidv1_hex(io.BytesIO(b'hello world')) 'f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9' ``` The result might not look like a valid IPFS CIDv1, but it actually is: https://ipfs.io/ipfs/f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 With IPFS v0.11.0 this equals to: ```bash $ipfs add --cid-version=1 <myfile> $ipfs cid format -b=base16 bafkreifzjut3te2nhyekklss27nh3k72ysco7y32koao5eei66wof36n5e f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 ``` When using `cidv1_to_token_id` for this hash you get an `uint256` that can be converted to a hex representation within a Smart Contract. The hex-representation can then be used for ID-Substitution. Use `ipfs://f01551220{id}` as template for the Metadata-URI. :param Stream stream: Data to be hashed (currently max 262144 bytes supported) :return: A valid IPFS CIDv1 that can be used as token-id and metadata-uri :rtype: str \"\"\" if isinstance ( stream , bytes ): stream = io . BytesIO ( stream ) ipfs_max_size = 262144 data = stream . read ( ipfs_max_size ) # fail if we have more data than ipfs_max_size if stream . read ( 1 ): raise ValueError ( f \"Data exceeds current max size { ipfs_max_size } for ipfs_hash: { len ( data ) } \" ) digest = sha256 ( data ) . digest () multibase_prefix = \"f\" multicodec_cidv1 = b \" \\x01 \" multicodec_content_type = b \" \\x55 \" # raw multicodec_mutihash_type = b \" \\x12 \" # sha2-256 multicodec_mutihash_len = uvarint . encode ( 32 ) # 28 byte length (varint encoded 0x1c) cid_v1_digest = b \"\" . join ( ( multicodec_cidv1 , multicodec_content_type , multicodec_mutihash_type , multicodec_mutihash_len , digest , ) ) cid_v1 = multibase_prefix + cid_v1_digest . hex () return cid_v1","title":"cidv1_hex()"},{"location":"utilities/utils/#iscc_core.utils.cidv1_to_token_id","text":"Convert default IPFS CIDv1 to an uint256 Token-ID. To save storage space in Smart Contracts and to securely link an NFT Token-ID to its associated metadata we can convert a CIDv1 to an uint256 Token-ID and vice versa. Example >>> import io >>> import iscc_core as ic >>> ic . cidv1_to_token_id ( \"f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\" ) 83814198383102558219731078260892729932246618004265700685467928187377105751529 Parameters: Name Type Description Default cidv1 str An IPFS CIDv1 string base-16 (hex) encoded representation. required Returns: Type Description An uint256 derived from the CIDv1 Source code in iscc_core\\utils.py def cidv1_to_token_id ( cidv1 ): # type: (str) -> int \"\"\" Convert default IPFS CIDv1 to an uint256 Token-ID. To save storage space in Smart Contracts and to securely link an NFT Token-ID to its associated metadata we can convert a CIDv1 to an uint256 Token-ID and vice versa. !!! example ```python >>> import io >>> import iscc_core as ic >>> ic.cidv1_to_token_id(\"f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\") 83814198383102558219731078260892729932246618004265700685467928187377105751529 ``` :param str cidv1: An IPFS CIDv1 string base-16 (hex) encoded representation. :return int: An uint256 derived from the CIDv1 \"\"\" if not cidv1 . startswith ( \"f\" ): raise ValueError ( f \"Only base16 encoded CIDv1 supported. Got { cidv1 } \" ) nobase = cidv1 [ 1 :] decoded = bytes . fromhex ( nobase ) if not decoded . startswith ( b \" \\x01\\x55\\x12\\x20 \" ): raise ValueError ( f \"Only sha2-256 with raw leaves supported. Got { decoded . hex () } \" ) digest = decoded [ 4 :] if not len ( digest ) == 32 : raise ValueError ( f \"Illegal digest size { len ( digest ) } for sha2-256\" ) return int . from_bytes ( digest , \"big\" , signed = False )","title":"cidv1_to_token_id()"},{"location":"utilities/utils/#iscc_core.utils.cidv1_from_token_id","text":"Convert Token-ID to default IPFS CIDv1 (reverse of cidv1_to_token_id ). Example >>> import io >>> import iscc_core as ic >>> ic . cidv1_from_token_id ( 83814198383102558219731078260892729932246618004265700685467928187377105751529 ) 'f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9' Parameters: Name Type Description Default token_id An uint256 Token-ID derived from a CIDv1 required Returns: Type Description An IPFS CIDv1 string with default base32 encoding. Source code in iscc_core\\utils.py def cidv1_from_token_id ( token_id ): # type: (int) -> str \"\"\" Convert Token-ID to default IPFS CIDv1 (reverse of `cidv1_to_token_id`). !!! example ```python >>> import io >>> import iscc_core as ic >>> ic.cidv1_from_token_id(83814198383102558219731078260892729932246618004265700685467928187377105751529) 'f01551220b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9' ``` :param token_id: An uint256 Token-ID derived from a CIDv1 :return str: An IPFS CIDv1 string with default base32 encoding. \"\"\" digest = b \" \\x01\\x55\\x12\\x20 \" + int . to_bytes ( token_id , length = 32 , byteorder = \"big\" , signed = False ) return \"f\" + digest . hex ()","title":"cidv1_from_token_id()"},{"location":"utilities/utils/#iscc_core.utils.multi_hash_blake3","text":"Create blake3 hash with multihash prefix. Parameters: Name Type Description Default data bytes Bytes to be hashed required Returns: Type Description str Multihash prefixed 256-bit blake3 hash as hex string Source code in iscc_core\\utils.py def multi_hash_blake3 ( data ): # type: (bytes) -> str \"\"\" Create blake3 hash with multihash prefix. :param bytes data: Bytes to be hashed :return: Multihash prefixed 256-bit blake3 hash as hex string :rtype: str \"\"\" return ( b \" \\x1e\\x20 \" + blake3 ( data ) . digest ()) . hex ()","title":"multi_hash_blake3()"},{"location":"utilities/utils/#iscc_core.utils.sliding_window","text":"Generate a sequence of equal \"width\" slices each advancing by one elemnt. All types that have a length and can be sliced are supported (list, tuple, str ...). The result type matches the type of the input sequence. Fragment slices smaller than the width at the end of the sequence are not produced. If \"witdh\" is smaller than the input sequence than one element will be returned that is shorter than the requested width. Parameters: Name Type Description Default seq Sequence Sequence of values to slide over required width int Width of sliding window in number of items required Returns: Type Description Union[Generat,] A generator of window sized items Source code in iscc_core\\utils.py def sliding_window ( seq , width ): # type: (Sequence, int) -> Generator \"\"\" Generate a sequence of equal \"width\" slices each advancing by one elemnt. All types that have a length and can be sliced are supported (list, tuple, str ...). The result type matches the type of the input sequence. Fragment slices smaller than the width at the end of the sequence are not produced. If \"witdh\" is smaller than the input sequence than one element will be returned that is shorter than the requested width. :param Sequence seq: Sequence of values to slide over :param int width: Width of sliding window in number of items :returns: A generator of window sized items :rtype: Generator \"\"\" if width < 2 : raise AssertionError ( \"Sliding window width must be 2 or bigger.\" ) idx = range ( max ( len ( seq ) - width + 1 , 1 )) return ( seq [ i : i + width ] for i in idx )","title":"sliding_window()"},{"location":"utilities/utils/#iscc_core.utils.iscc_similarity","text":"Calculate similarity of ISCC codes as a percentage value (0-100). MainType, SubType, Version and Length of the codes must be the same. Parameters: Name Type Description Default a ISCC a required b ISCC b required Returns: Type Description int Similarity of ISCC a and b in percent (based on hamming distance) Source code in iscc_core\\utils.py def iscc_similarity ( a , b ): # type: (str, str) -> int \"\"\" Calculate similarity of ISCC codes as a percentage value (0-100). MainType, SubType, Version and Length of the codes must be the same. :param a: ISCC a :param b: ISCC b :return: Similarity of ISCC a and b in percent (based on hamming distance) :rtype: int \"\"\" a , b = iscc_pair_unpack ( a , b ) hdist = iscc_distance_bytes ( a , b ) nbits = len ( a ) * 8 sim = int ((( nbits - hdist ) / nbits ) * 100 ) return sim","title":"iscc_similarity()"},{"location":"utilities/utils/#iscc_core.utils.iscc_distance","text":"Calculate hamming distance of ISCC codes. MainType, SubType, Version and Length of the codes must be the same. Parameters: Name Type Description Default a ISCC a required b ISCC b required Returns: Type Description int Hamming distanced in number of bits. Source code in iscc_core\\utils.py def iscc_distance ( a , b ): # type: (str, str) -> int \"\"\" Calculate hamming distance of ISCC codes. MainType, SubType, Version and Length of the codes must be the same. :param a: ISCC a :param b: ISCC b :return: Hamming distanced in number of bits. :rtype: int \"\"\" a , b = iscc_pair_unpack ( a , b ) return iscc_distance_bytes ( a , b )","title":"iscc_distance()"},{"location":"utilities/utils/#iscc_core.utils.iscc_distance_bytes","text":"Calculate hamming distance for binary hash digests of equal length. Parameters: Name Type Description Default a bytes binary hash digest required b bytes binary hash digest required Returns: Type Description int Hamming distance in number of bits. Source code in iscc_core\\utils.py def iscc_distance_bytes ( a , b ): # type: (bytes, bytes) -> int \"\"\" Calculate hamming distance for binary hash digests of equal length. :param bytes a: binary hash digest :param bytes b: binary hash digest :return: Hamming distance in number of bits. :rtype: int \"\"\" if len ( a ) != len ( b ): raise AssertionError ( f \"Hash diggest of unequal length: { len ( a ) } vs { len ( b ) } \" ) ba , bb = bitarray (), bitarray () ba . frombytes ( a ) bb . frombytes ( b ) return count_xor ( ba , bb )","title":"iscc_distance_bytes()"},{"location":"utilities/utils/#iscc_core.utils.iscc_pair_unpack","text":"Unpack two ISCC codes and return their body hash digests if their headers match. Headers match if their MainType, SubType, and Version are identical. Parameters: Name Type Description Default a ISCC a required b ISCC b required Returns: Type Description Tuple[bytes, bytes] Tuple with hash digests of a and b Exceptions: Type Description ValueError If ISCC headers don\u00b4t match Source code in iscc_core\\utils.py def iscc_pair_unpack ( a , b ): # type: (str, str) -> Tuple[bytes, bytes] \"\"\" Unpack two ISCC codes and return their body hash digests if their headers match. Headers match if their MainType, SubType, and Version are identical. :param a: ISCC a :param b: ISCC b :return: Tuple with hash digests of a and b :rtype: Tuple[bytes, bytes] :raise ValueError: If ISCC headers don\u00b4t match \"\"\" a , b = ic . iscc_clean ( ic . iscc_normalize ( a )), ic . iscc_clean ( ic . iscc_normalize ( b )) a , b = ic . decode_base32 ( a ), ic . decode_base32 ( b ) a , b = ic . decode_header ( a ), ic . decode_header ( b ) if not a [: - 1 ] == b [: - 1 ]: raise ValueError ( f \"ISCC headers don\u00b4t match: { a } , { b } \" ) return a [ - 1 ], b [ - 1 ]","title":"iscc_pair_unpack()"}]}